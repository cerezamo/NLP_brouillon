{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOpoYHRKf+ge//4nAQsVk8l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "db2df4ffa43042cd9ead4f3ddbe40e0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bac49e098ad84fdb9c4acacdaa5dd714",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ba1adf374d2f4c8daa06aa8bb898b754",
              "IPY_MODEL_13323ff0ee834fe3b6cf8c5983e3a711"
            ]
          }
        },
        "bac49e098ad84fdb9c4acacdaa5dd714": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ba1adf374d2f4c8daa06aa8bb898b754": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f8bb4e2fa4eb44eeb79d5b066fe36c24",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 637,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 637,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b302dcaee3194a29bf8747d1a78dc308"
          }
        },
        "13323ff0ee834fe3b6cf8c5983e3a711": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4eab88806a8d41ea961f3021ef36192a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 637/637 [00:01&lt;00:00, 381B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6bdbc16aeb06408dacacd442778aefc4"
          }
        },
        "f8bb4e2fa4eb44eeb79d5b066fe36c24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b302dcaee3194a29bf8747d1a78dc308": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4eab88806a8d41ea961f3021ef36192a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6bdbc16aeb06408dacacd442778aefc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e114d982606d459a84a24a6a05c5cba5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ea63ad847a4c4abcbc456e9b9334433f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d4fd4544197f4c838721d84bcf1314db",
              "IPY_MODEL_54e62c7fceb145b8a46fc5b46bec48c7"
            ]
          }
        },
        "ea63ad847a4c4abcbc456e9b9334433f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d4fd4544197f4c838721d84bcf1314db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_206c41b2f1864a5facaea83da0b64dda",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 445032417,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 445032417,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ced5c813c5694e86a2b6f59210f6cfc8"
          }
        },
        "54e62c7fceb145b8a46fc5b46bec48c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_69d387a09c18451e8f1cd69363f11470",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 445M/445M [00:40&lt;00:00, 10.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_20b1b50a350f4ccdb893393d027e2ca4"
          }
        },
        "206c41b2f1864a5facaea83da0b64dda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ced5c813c5694e86a2b6f59210f6cfc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "69d387a09c18451e8f1cd69363f11470": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "20b1b50a350f4ccdb893393d027e2ca4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cerezamo/NLP_brouillon/blob/master/Camembert_clean.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcxLW3uyHTSN",
        "colab_type": "text"
      },
      "source": [
        "# BERT classification model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1JD-Tb0HdvN",
        "colab_type": "code",
        "outputId": "7a0073fb-5ff4-40e7-d0d8-84d0279b5704",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import spacy \n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import os \n",
        "os.getcwd()\n",
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bxA1IEgH-GI",
        "colab_type": "text"
      },
      "source": [
        "### Set up Colab GPU "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mF6Hs6yH2A5",
        "colab_type": "code",
        "outputId": "c82430e3-f051-46eb-be2b-76f142e55eb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# First you should go in 'Edit' -> 'Notebook settings' -> Add device GPU\n",
        "import tensorflow as tf\n",
        "\n",
        "# GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "device_name"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ_F6NV3IaCY",
        "colab_type": "text"
      },
      "source": [
        "Let's now tell torch that one GPU is available "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wr4fjemjIVoQ",
        "colab_type": "code",
        "outputId": "95ad456b-8b8a-445d-9378-1e5d4cf5025f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():  \n",
        "        \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGwjFzizIsMI",
        "colab_type": "text"
      },
      "source": [
        "Let's install the Hugging Face Library transformer package "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--g7cokfIrpT",
        "colab_type": "code",
        "outputId": "22ef4887-c271-43de-ef3f-9820f3e010f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "! pip install transformers "
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.27)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.27 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.27)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.27->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.27->boto3->transformers) (2.8.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4OKq8Z4JId9",
        "colab_type": "text"
      },
      "source": [
        "### Loading our corpus and preprocessing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOCVLtje9_Rs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "# Import medium_df_desq in \"files\"\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df=pd.read_csv('medium_df_deseq.csv',encoding='utf-8')\n",
        "\n",
        "# We replace the labels in a more normalized way : 0=men, 1=women \n",
        "df.sexe=df.sexe.replace(1,0)\n",
        "df.sexe=df.sexe.replace(2,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0FNej5emFx8",
        "colab_type": "text"
      },
      "source": [
        "**CHOOSE ONE OF THE OPTIONS BELOW**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGRDpDKe9_j-",
        "colab_type": "text"
      },
      "source": [
        "1. Unbalanced sample \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3Gl1QBWAlTn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#Shuffle the data \n",
        "df=df.sample(frac=1).reset_index()\n",
        "\n",
        "# Reduce to the variables we are interested in \n",
        "df=df[['Texte','sexe']]\n",
        "\n",
        "# Report the number of speeches in the corpus.\n",
        "print('Number of text in this corpus : {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "df.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrqgCPYFApFQ",
        "colab_type": "text"
      },
      "source": [
        "2. Balanced sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOIKxWaXHPVB",
        "colab_type": "code",
        "outputId": "8d539235-2a32-48b2-e53e-10fff8b678c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# Let's take a balanced sample (model classifying all in men otherwise)\n",
        "df_m = df.loc[df['sexe'] == 0]\n",
        "df_f = df.loc[df['sexe'] == 1] \n",
        "df_m = df_m[0:len(df_f)]\n",
        "df = df_f.append(df_m)\n",
        "\n",
        "#Shuffle the data \n",
        "df=df.sample(frac=1).reset_index()\n",
        "\n",
        "# Reduce to the variables we are interested in \n",
        "df=df[['Texte','sexe']]\n",
        "\n",
        "# Report the number of speeches in the corpus.\n",
        "print('Number of text in this corpus : {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "df.head(5)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of text in this corpus : 2,500\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Texte</th>\n",
              "      <th>sexe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mesdames, Messieurs,Après avoir salué une nouv...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>M. le président. L'ordre du jour appelle le dé...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Madame et messieurs les ministres,Mesdames, me...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>M. le président. L'ordre du jour appelle le dé...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Monsieur le maire, mon cher Gilbert,Monsieur ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Texte  sexe\n",
              "0  Mesdames, Messieurs,Après avoir salué une nouv...     0\n",
              "1  M. le président. L'ordre du jour appelle le dé...     0\n",
              "2  Madame et messieurs les ministres,Mesdames, me...     1\n",
              "3  M. le président. L'ordre du jour appelle le dé...     1\n",
              "4   Monsieur le maire, mon cher Gilbert,Monsieur ...     0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lNHgnNbAsoq",
        "colab_type": "text"
      },
      "source": [
        "3. Spliting texts in order to feed the model with all parts "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2JmisLKH2L8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "a037c92c-9e82-4a49-e288-c4bd12765748"
      },
      "source": [
        "from itertools import repeat\n",
        "n=2000\n",
        "chunks, label_split=[],[]\n",
        "j=0\n",
        "for text in df.Texte :\n",
        "    txt=[text[i:i+n] for i in range(0, len(text), n)]\n",
        "    chunks.append(txt)\n",
        "    label_split.extend(repeat(df.sexe[j], len(txt)))\n",
        "    j+=1\n",
        "\n",
        "chunks = [item for sublist in chunks for item in sublist]\n",
        "df=pd.DataFrame([chunks,label_split]).transpose()\n",
        "df.columns=['Texte','sexe']\n",
        "len(df)\n",
        "\n",
        "# Let's take a balanced sample (model classifying all in men otherwise)\n",
        "df_m = df.loc[df['sexe'] == 0]\n",
        "df_f = df.loc[df['sexe'] == 1] \n",
        "df_m = df_m[0:len(df_f)]\n",
        "df = df_f.append(df_m)\n",
        "\n",
        "#Shuffle the data \n",
        "df=df.sample(frac=0.5).reset_index()\n",
        "\n",
        "# Reduce to the variables we are interested in \n",
        "df=df[['Texte','sexe']]\n",
        "\n",
        "# Put as integer \n",
        "df['sexe'] = df['sexe'].astype(int)\n",
        "\n",
        "# Report the number of speeches in the corpus.\n",
        "print('Number of text in this corpus : {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "df.head(5)\n",
        "\n",
        "# In this case we will cut the sample \n"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of text in this corpus : 7,981\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Texte</th>\n",
              "      <th>sexe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>« Je tiens tout d'abord à vous dire que je sui...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>e synthèse nationale sera réalisée le 15 novem...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>en vigueur du nouveau traité donnera ainsi à l...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Monsieur le président, Mesdames et Messieurs l...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>'est précisément la raison pour laquelle ces m...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Texte  sexe\n",
              "0  « Je tiens tout d'abord à vous dire que je sui...     1\n",
              "1  e synthèse nationale sera réalisée le 15 novem...     1\n",
              "2  en vigueur du nouveau traité donnera ainsi à l...     0\n",
              "3  Monsieur le président, Mesdames et Messieurs l...     0\n",
              "4  'est précisément la raison pour laquelle ces m...     0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ressz8h6OHxn",
        "colab_type": "text"
      },
      "source": [
        "#### Tokenization of our text and preparing to feed CamemBERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntpzo9X5SSjA",
        "colab_type": "text"
      },
      "source": [
        "#### Loading the Camembert Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDafeOtBg9T5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "model, dev = train_test_split(df, test_size=0.02)\n",
        "\n",
        "df= model\n",
        "df_dev= dev"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gXJZbQHl9Is",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5cf337f0-7f1e-4233-9a10-e548a6ebe0a4"
      },
      "source": [
        "len(df_dev)"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "160"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zbgs39TYNqRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Camembert tokenizer\n",
        "from transformers import CamembertTokenizer\n",
        "# We choose a right padding side for the moment and we will test for a left padding side on a second stage\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-base', do_lower_case=False,padding_side='right') #left\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08yLt5edOhL3",
        "colab_type": "code",
        "outputId": "cdcc9695-e655-4c0b-faf5-08e4054c3ed4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# Print the original text.\n",
        "print(' Original: ', df.Texte[0])\n",
        "\n",
        "# Print the text split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(df.Texte[0]))\n",
        "\n",
        "# Print the text mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(df.Texte[0])))"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  « Je tiens tout d'abord à vous dire que je suis très heureuse de vous accueillir à Bercy à l'occasion de votre Assemblée Générale. Bercy est la maison commune de tous les professionnels, de tous les acteurs économiques de notre pays : vous êtes donc ici chez vous !Je suis honorée que vous m'ayez demandé d'ouvrir vos travaux et cela me permet de vous affirmer mon engagement, l'engagement du Gouvernement et du Président de la République, auprès des gardiens de la gastronomie française.* Une politique globale de soutien et de promotion de la gastronomieLe mot « gastronomie » a pris son essorgrâce à un poète français, Joseph Berchoux ! Ce n'est pas une anecdote, c'est tout un symbole : notre gastronomie est une véritable institution en France. C'est une image rayonnante de notre pays dans le monde, c'est notre marque de fabrique !La gastronomie française ne doit pas être considérée comme un acquis ; nous devons la promouvoir et lui donner la place qu'elle mérite.C'est pourquoi notre soutien doit être pluriel et global. Chaque levier d'action doit être complémentaire des autres et participer de la dynamique d'ensemble : le fait maison, le nouveau statut d'artisan pour les cuisiniers, le titre d'Etat de Maître-Restaurateur, la Fête de la Gastronomie et l'opération Goût de France/Good France.Le rôle de ce dispositif global est de mettre en avant les professionnels, de faire rayonner notre gastronomie dans le monde, de créer des moments conviviaux et fédérateurs pour que le plus grand nombre puissent goûter à cet art de vivre à la française, et enfin de valoriser des produits de terroirs et des savoir-faire traditionnels et innovants. Il y a donc une dimension sociale, économique, culturelle et territoriale dans ce dispositif.- Le Fait Maison a été rénové pour être plus simple et plus clair pour tous. Son double objectif est qu'il puisse mieux informer les consommateurs et mieux valoriser encore le travail des restaurateurs.- Le titre d'Etat de Maître-Restaurateur garantit \n",
            "Tokenized:  ['▁«', '▁Je', '▁tiens', '▁tout', '▁d', \"'\", 'abord', '▁à', '▁vous', '▁dire', '▁que', '▁je', '▁suis', '▁très', '▁heureuse', '▁de', '▁vous', '▁accueillir', '▁à', '▁Bercy', '▁à', '▁l', \"'\", 'occasion', '▁de', '▁votre', '▁Assemblée', '▁Générale', '.', '▁Bercy', '▁est', '▁la', '▁maison', '▁commune', '▁de', '▁tous', '▁les', '▁professionnels', ',', '▁de', '▁tous', '▁les', '▁acteurs', '▁économiques', '▁de', '▁notre', '▁pays', '▁:', '▁vous', '▁êtes', '▁donc', '▁ici', '▁chez', '▁vous', '▁!', 'Je', '▁suis', '▁honoré', 'e', '▁que', '▁vous', '▁m', \"'\", 'ayez', '▁demandé', '▁d', \"'\", 'ouvrir', '▁vos', '▁travaux', '▁et', '▁cela', '▁me', '▁permet', '▁de', '▁vous', '▁affirmer', '▁mon', '▁engagement', ',', '▁l', \"'\", 'engagement', '▁du', '▁Gouvernement', '▁et', '▁du', '▁Président', '▁de', '▁la', '▁République', ',', '▁auprès', '▁des', '▁gardiens', '▁de', '▁la', '▁gastronomie', '▁française', '.', '*', '▁Une', '▁politique', '▁globale', '▁de', '▁soutien', '▁et', '▁de', '▁promotion', '▁de', '▁la', '▁gastronomie', 'Le', '▁mot', '▁«', '▁gastronomie', '▁»', '▁a', '▁pris', '▁son', '▁essor', 'grâce', '▁à', '▁un', '▁poète', '▁français', ',', '▁Joseph', '▁Ber', 'cho', 'ux', '▁!', '▁Ce', '▁n', \"'\", 'est', '▁pas', '▁une', '▁', 'anecdote', ',', '▁c', \"'\", 'est', '▁tout', '▁un', '▁symbole', '▁:', '▁notre', '▁gastronomie', '▁est', '▁une', '▁véritable', '▁institution', '▁en', '▁France', '.', '▁C', \"'\", 'est', '▁une', '▁image', '▁rayonnant', 'e', '▁de', '▁notre', '▁pays', '▁dans', '▁le', '▁monde', ',', '▁c', \"'\", 'est', '▁notre', '▁marque', '▁de', '▁fabrique', '▁!', 'La', '▁gastronomie', '▁française', '▁ne', '▁doit', '▁pas', '▁être', '▁considérée', '▁comme', '▁un', '▁acquis', '▁;', '▁nous', '▁devons', '▁la', '▁promouvoir', '▁et', '▁lui', '▁donner', '▁la', '▁place', '▁qu', \"'\", 'elle', '▁mérite', '.', 'C', \"'\", 'est', '▁pourquoi', '▁notre', '▁soutien', '▁doit', '▁être', '▁pluriel', '▁et', '▁global', '.', '▁Chaque', '▁levier', '▁d', \"'\", 'action', '▁doit', '▁être', '▁complémentaire', '▁des', '▁autres', '▁et', '▁participer', '▁de', '▁la', '▁dynamique', '▁d', \"'\", 'ensemble', '▁:', '▁le', '▁fait', '▁maison', ',', '▁le', '▁nouveau', '▁statut', '▁d', \"'\", 'artisan', '▁pour', '▁les', '▁cuisinier', 's', ',', '▁le', '▁titre', '▁d', \"'\", 'Etat', '▁de', '▁Maître', '-', 'R', 'est', 'au', 'rateur', ',', '▁la', '▁Fête', '▁de', '▁la', '▁G', 'astronomie', '▁et', '▁l', \"'\", 'opération', '▁Goût', '▁de', '▁France', '/', 'G', 'ood', '▁France', '.', 'Le', '▁rôle', '▁de', '▁ce', '▁dispositif', '▁global', '▁est', '▁de', '▁mettre', '▁en', '▁avant', '▁les', '▁professionnels', ',', '▁de', '▁faire', '▁rayon', 'ner', '▁notre', '▁gastronomie', '▁dans', '▁le', '▁monde', ',', '▁de', '▁créer', '▁des', '▁moments', '▁con', 'viv', 'iaux', '▁et', '▁fé', 'dé', 'rateur', 's', '▁pour', '▁que', '▁le', '▁plus', '▁grand', '▁nombre', '▁puissent', '▁goûter', '▁à', '▁cet', '▁art', '▁de', '▁vivre', '▁à', '▁la', '▁française', ',', '▁et', '▁enfin', '▁de', '▁valoriser', '▁des', '▁produits', '▁de', '▁terroir', 's', '▁et', '▁des', '▁savoir', '-', 'faire', '▁traditionnels', '▁et', '▁innovants', '.', '▁Il', '▁y', '▁a', '▁donc', '▁une', '▁dimension', '▁sociale', ',', '▁économique', ',', '▁culturelle', '▁et', '▁territoriale', '▁dans', '▁ce', '▁dispositif', '.', '-', '▁Le', '▁Fait', '▁Maison', '▁a', '▁été', '▁rénové', '▁pour', '▁être', '▁plus', '▁simple', '▁et', '▁plus', '▁clair', '▁pour', '▁tous', '.', '▁Son', '▁double', '▁objectif', '▁est', '▁qu', \"'\", 'il', '▁puisse', '▁mieux', '▁informer', '▁les', '▁consommateurs', '▁et', '▁mieux', '▁valoriser', '▁encore', '▁le', '▁travail', '▁des', '▁restaurateur', 's', '.', '-', '▁Le', '▁titre', '▁d', \"'\", 'Etat', '▁de', '▁Maître', '-', 'R', 'est', 'au', 'rateur', '▁garantit']\n",
            "Token IDs:  [64, 100, 4069, 66, 18, 11, 803, 15, 39, 248, 27, 50, 146, 95, 4125, 8, 39, 3468, 15, 24644, 15, 17, 11, 690, 8, 75, 15129, 6600, 9, 24644, 30, 13, 269, 928, 8, 117, 19, 941, 7, 8, 117, 19, 1602, 2500, 8, 127, 256, 43, 39, 495, 145, 323, 222, 39, 83, 1684, 146, 22324, 35, 27, 39, 115, 11, 18652, 1650, 18, 11, 3213, 140, 703, 14, 207, 103, 288, 8, 39, 12266, 129, 3661, 7, 17, 11, 4687, 25, 6518, 14, 25, 1850, 8, 13, 1547, 7, 843, 20, 19380, 8, 13, 12380, 781, 9, 1363, 180, 462, 4141, 8, 1237, 14, 8, 2815, 8, 13, 12380, 990, 853, 64, 12380, 94, 33, 523, 58, 18772, 27455, 15, 23, 7661, 430, 7, 4950, 4954, 3621, 1129, 83, 148, 49, 11, 41, 34, 28, 21, 15559, 7, 60, 11, 41, 66, 23, 5375, 43, 127, 12380, 30, 28, 1095, 10048, 22, 184, 9, 84, 11, 41, 28, 1165, 27378, 35, 8, 127, 256, 29, 16, 164, 7, 60, 11, 41, 127, 587, 8, 7784, 83, 1003, 12380, 781, 45, 279, 34, 98, 7538, 79, 23, 4203, 167, 63, 4092, 13, 4807, 14, 111, 509, 13, 218, 46, 11, 144, 2705, 9, 228, 11, 41, 590, 127, 1237, 279, 98, 22271, 14, 5253, 9, 1541, 9266, 18, 11, 974, 279, 98, 5922, 20, 214, 14, 1562, 8, 13, 2444, 18, 11, 649, 43, 16, 82, 269, 7, 16, 281, 2443, 18, 11, 15071, 24, 19, 17896, 10, 7, 16, 565, 18, 11, 1184, 8, 4999, 26, 629, 41, 276, 7536, 7, 13, 7202, 8, 13, 361, 19828, 14, 17, 11, 3275, 25836, 8, 184, 122, 546, 12352, 184, 9, 990, 842, 8, 44, 2507, 5253, 30, 8, 328, 22, 178, 19, 941, 7, 8, 85, 4356, 944, 127, 12380, 29, 16, 164, 7, 8, 739, 20, 2059, 1113, 7188, 10100, 14, 6654, 958, 7536, 10, 24, 27, 16, 40, 221, 365, 4601, 7261, 15, 280, 2045, 8, 747, 15, 13, 781, 7, 14, 743, 8, 10886, 20, 336, 8, 9805, 10, 14, 20, 319, 26, 2821, 6618, 14, 14637, 9, 69, 102, 33, 145, 28, 3033, 1039, 7, 919, 7, 4015, 14, 9321, 29, 44, 2507, 9, 26, 54, 9447, 1265, 33, 101, 12683, 24, 98, 40, 445, 14, 40, 1630, 24, 117, 9, 685, 1080, 1739, 30, 46, 11, 62, 1516, 334, 6097, 19, 3697, 14, 334, 10886, 143, 16, 225, 20, 25236, 10, 9, 26, 54, 565, 18, 11, 1184, 8, 4999, 26, 629, 41, 276, 7536, 7220]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8yAtMsdR9HB",
        "colab_type": "text"
      },
      "source": [
        "#### Adding special tokens to the start and end of the text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXlKcUdlYetx",
        "colab_type": "text"
      },
      "source": [
        "Preprocessing steps : \n",
        "\n",
        "\n",
        "1.   **Add special tokens [CLS] [SEP]** \n",
        "\n",
        "According to the documentation we need to add special tokens to the start and end of the text Moreover, for camembert we should add a space between CLS and the first token (not sure here, we have to ask benjamin). \n",
        "\n",
        "2.   **Pad and truncate all texts to a single number**\n",
        "\n",
        "Pretrained transformes like Camembert only accept input of the same length. Our corpus contains large texts and we have to pad them in order to be able to feed Camembert. We will set the max length to a large number in order to get all information possible in the text. We choose a max length of 500 which is almost the maximum (512) \"sentence\" length  accepted. We are aware that this choice will impact a lot training speed.\n",
        "\n",
        "3.   **Construct an attention mask**\n",
        "\n",
        "Attention masks are just set to 1 when the token have to be analyzed and 0 otherwise (padded tokens). All our attention mask should be 1 with this corpus. \n",
        "\n",
        "\n",
        "\n",
        "For sake of simplicity and to avoid errors we will use the function encode_plus of the library which is really convenient. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XKNZMJvSb2w",
        "colab_type": "text"
      },
      "source": [
        "#### Length and attention mask "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HF89V-xSgGF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts = df.Texte.values\n",
        "labels = df.sexe.values\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "num_truncated_tokens =[]\n",
        "# Apply function to our corpus\n",
        "for text in texts:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        text,                      # text\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 500,           # We choose for now a max length of 500.\n",
        "                        pad_to_max_length = True,    # Pad text to max (marche pas en pad left ?)\n",
        "                        return_attention_mask = True,   # Construct attention masks\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                        return_overflowing_tokens =True, # return overflowing token information\n",
        "                   )\n",
        "    \n",
        "    # Map tokens to their id in the dictionnary \n",
        "    # We add this to our list    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        " \n",
        "    #num_truncated_tokens.append(encoded_dict['num_truncated_tokens'])\n",
        "    \n",
        "    # 3. Attention masks\n",
        "    attention_masks.append(encoded_dict['attention_mask'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIQMcNAgekhx",
        "colab_type": "code",
        "outputId": "1a01db91-507d-44e8-edab-676d0031ad0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 904
        }
      },
      "source": [
        "# We convert all this into tensors in order to be able to make it work on GPU \n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Original text and transformed tensor print \n",
        "print('Original: ', texts[0])\n",
        "print('IDs:', input_ids[0])"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  pations démocratiques en fournissant aux citoyens toute l'information dont ils ont besoin pour prendre des décisions éclairées. 4. Et je crois que cette 7eme édition du Rapport sur l'état de l'environnement va pleinement dans ce sens. Les « focus thématiques » permettent d'aborder des points précis, qui intéressent nos concitoyens avec la transversalité nécessaire, comme le lien environnement santé. L'introduction d'une grille de lecture inédite par les « limites planétaires » me semble également essentielle. Connaître l'impact de la France vis-à-vis de ces différentes limites, son empreinte : c'est indispensable pour conduire la transition écologique. Et je vois que nos concitoyens y sont de plus en plus sensibles. Car cette conscience de la finitude des ressources, des seuils à ne pas dépasser : elle questionne notre responsabilité collective. 5. Mais le contenu seul ne suffit pas. A l'ère de l'immédiateté de l'information, il est important que ces données ne soient pas diffusées uniquement une fois tous les 4 ans. Et c'est bien le projet de cette 7ème édition qui lance en même temps un site dédié. Dédié… et actualisé, en continu, avec les dernières données. Disons-le : c'est une petite révolution dans ce ministère. Ce site, ce sont des « portes ouvertes », chaque jour, à tous, pour s'emparer des données. Et avec elles des sujets. Pour trouver l'information la plus fraîche, sans devoir cliquer mille fois ni compiler 50 rapports. Et je souhaite que cette plateforme web puisse devenir pour vous un réflexe, lorsque vous aurez besoin d'une information objective sur l'état de notre environnement. Un lien de confiance, direct, entre mon ministère et vous, les usagers de la donnée. Entre nos politiques publiques et nos concitoyens.   Mesdames et messieurs, ce travail remarquable : il est le vôtre. Il est le fruit d'enquêtes, de collectes, de traitements, de valorisation des données. Il est le fruit du travail de centaines de personne, au sein de mon ministère et des étab\n",
            "IDs: tensor([    5,   387,  2770,  4510,    10,    22, 21270,    68,  2654,   194,\n",
            "           17,    11,  1070,   174,   220,    96,   394,    24,   313,    20,\n",
            "         3505, 21259,    10,     9,   181,     9,   139,    50,  1115,    27,\n",
            "           78,   333,  3141,  1533,    25,  8187,    32,    17,    11,  1215,\n",
            "            8,    17,    11,  1623,   198,  4198,    29,    44,   437,     9,\n",
            "           74,    64, 23613,  7381,    94,  1270,    18,    11, 14204,    20,\n",
            "          725,  2680,     7,    31, 21322,   166, 22089,    42,    13, 31440,\n",
            "          948,   885,     7,    79,    16,   818,  1898,   561,     9,    71,\n",
            "           11,  9123,    18,    11,    70,  5715,     8,  1147, 12802,    37,\n",
            "           19,    64,  3311, 11917,    94,   103,   630,   200,  5626,     9,\n",
            "        30159,    17,    11,  4266,     8,    13,   184,  1245,    26,   169,\n",
            "           26,  1647,     8,   119,   678,  3311,     7,    58, 16008,    43,\n",
            "           60,    11,    41,  2762,    24,  4013,    13,  4427,  5001,     9,\n",
            "          139,    50,  1460,    27,   166, 22089,   102,    56,     8,    40,\n",
            "           22,    40,  6793,     9,   733,    78,  1582,     8,    13,   259,\n",
            "        11854,    20,  1388,     7,    20,  6677,    10,    15,    45,    34,\n",
            "         5581,    43,   109,   397,   324,   127,  1717,  4155,     9,   205,\n",
            "            9,   159,    16,  1180,   428,    45,  1373,    34,     9,   114,\n",
            "           17,    11,  1135,     8,    17,    11, 23651,    35,   728,     8,\n",
            "           17,    11,  1070,     7,    51,    30,   693,    27,   119,   416,\n",
            "           45,  1053,    34,  9143,    10,  1333,    28,   151,   117,    19,\n",
            "          181,   134,     9,   139,    60,    11,    41,    72,    16,   327,\n",
            "            8,    78,   333,   544,  1533,    31,  2661,    22,    93,   125,\n",
            "           23,   132,  3375,     9,  1198,  1060,   141,    57,    14, 23284,\n",
            "            7,    22,  4983,     7,    42,    19,  1194,   416,     9, 19245,\n",
            "           26,   185,    43,    60,    11,    41,    28,   354,  3177,    29,\n",
            "           44,  2011,     9,   148,   132,     7,    44,    56,    20,    64,\n",
            "         1905,  6710,   311,   251,   209,     7,    15,   117,     7,    24,\n",
            "           52,    11, 22081,    20,   416,     9,   139,    42,   582,    20,\n",
            "         2234,     9,   123,   356,    17,    11,  1070,    13,    40,  8623,\n",
            "            7,   112,  2308,  6907,  2720,   151,   382, 28061,    81,   712,\n",
            "         2631,     9,   139,    50,  1282,    27,    78,  2577,   939,  1516,\n",
            "         1090,    24,    39,    23, 11945,     7,   613,    39,  2222,   394,\n",
            "           18,    11,    70,  2322, 13684,    32,    17,    11,  1215,     8,\n",
            "          127,  1898,     9,   153,   818,     8,  1074,     7,  1528,     7,\n",
            "          128,   129,  2011,    14,    39,     7,    19,  7936,     8,    13,\n",
            "         3405,     9,  2149,   166,  1204,  2761,    14,   166, 22089,     9,\n",
            "        23605,    14, 15867,     7,    44,   225,  4946,    43,    51,    30,\n",
            "           16, 12063,     9,    69,    30,    16,  3735,    18,    11,  3466,\n",
            "           10,     7,     8,  4947,    10,     7,     8,  5857,     7,     8,\n",
            "         9534,    20,   416,     9,    69,    30,    16,  3735,    25,   225,\n",
            "            8,  3201,     8,   314,     7,    36,   731,     8,   129,  2011,\n",
            "           14,    20, 15331,   442,     6,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OPWOx2-FG7g",
        "colab_type": "code",
        "outputId": "0a3faf8d-7726-4e27-d8ad-277064dd48dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "labels"
      ],
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 0,  ..., 0, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vs6YDmQsgljf",
        "colab_type": "text"
      },
      "source": [
        "5 and 6 seem to be the [CLS] and [SEP] special tokens \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFc6MW5df566",
        "colab_type": "text"
      },
      "source": [
        "#### Train and validation dataset construction \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Y3MT9B-gAHU",
        "colab_type": "code",
        "outputId": "62bc56dc-49ab-42e2-ca40-d0e7fab80112",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine all above\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Let's create a 80-20 train / validation dataset \n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_set, val_set = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('We have {} training samples'.format(train_size))\n",
        "print('We have {} validation samples'.format(val_size))"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We have 6256 training samples\n",
            "We have 1565 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JF9rj3AWgynY",
        "colab_type": "text"
      },
      "source": [
        "In order to save on memory we use the convenient DataLoader of pytorch.utils "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dr-fhDIQgAFW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# We set the size of the batch lower than what is usually set (16 of 32)\n",
        "batch_size = 4\n",
        "\n",
        "# We create data loaders for the train and validation dataset. \n",
        "train_dataloader = DataLoader(\n",
        "            train_set,  # The training samples.\n",
        "            sampler = RandomSampler(train_set), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "val_dataloader = DataLoader(\n",
        "            val_set, # The validation samples.\n",
        "            sampler = SequentialSampler(val_set), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poTTEJX1hoUK",
        "colab_type": "text"
      },
      "source": [
        "### CamemBERT Sequence Classification model tuning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NN1VeJI0lDwf",
        "colab_type": "text"
      },
      "source": [
        "#### Loading the model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99MPOVB7iRcl",
        "colab_type": "text"
      },
      "source": [
        "We will finally build up our model. We will use the  CamemBERT model for sequence classification which includes a special top layer designed for this task. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRHhHzjKgAC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing from transformers\n",
        "from transformers import CamembertForSequenceClassification, CamembertConfig"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHMdM-QqgAAX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "db2df4ffa43042cd9ead4f3ddbe40e0f",
            "bac49e098ad84fdb9c4acacdaa5dd714",
            "ba1adf374d2f4c8daa06aa8bb898b754",
            "13323ff0ee834fe3b6cf8c5983e3a711",
            "f8bb4e2fa4eb44eeb79d5b066fe36c24",
            "b302dcaee3194a29bf8747d1a78dc308",
            "4eab88806a8d41ea961f3021ef36192a",
            "6bdbc16aeb06408dacacd442778aefc4",
            "e114d982606d459a84a24a6a05c5cba5",
            "ea63ad847a4c4abcbc456e9b9334433f",
            "d4fd4544197f4c838721d84bcf1314db",
            "54e62c7fceb145b8a46fc5b46bec48c7",
            "206c41b2f1864a5facaea83da0b64dda",
            "ced5c813c5694e86a2b6f59210f6cfc8",
            "69d387a09c18451e8f1cd69363f11470",
            "20b1b50a350f4ccdb893393d027e2ca4"
          ]
        },
        "outputId": "bd06c767-26cb-4e8a-ed71-10f8a270e318"
      },
      "source": [
        "# Loading the model\n",
        "# Ici je ne suis pas sure pour le 'cased' ou pas (je crois que oui)\n",
        "gender_model1 = CamembertForSequenceClassification.from_pretrained(\n",
        "    \"camembert-base\", \n",
        "    num_labels = 2, # We have two different labels Women = 1 and Men =0   \n",
        "    output_attentions = False, \n",
        "    output_hidden_states = False, \n",
        ")"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "db2df4ffa43042cd9ead4f3ddbe40e0f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=637, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e114d982606d459a84a24a6a05c5cba5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=445032417, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUKynoykf_9y",
        "colab_type": "code",
        "outputId": "e59bba2e-d2a0-4aef-b3fd-e130f8ec8579",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# We run the model on the colab GPU \n",
        "gender_model1.cuda()"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CamembertForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWyHWg5xlBck",
        "colab_type": "text"
      },
      "source": [
        "Optimizers and Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "go-uY70Mloqv",
        "colab_type": "text"
      },
      "source": [
        "We will choose the AdamW optimizer and set for this first model the learning rate and the epsilon to default. At the batch is little we might want to increase the learning rate a bit from what is usually used. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLyP0__vf_7d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from transformers import AdamW\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "#Implements Adam algorithm with weight decay fix.\n",
        "optimizer = AdamW(gender_model1.parameters(),\n",
        "                  lr = 5e-5, # Adaptative (yes i think)\n",
        "                  eps = 1e-8 # prevent division by 0 \n",
        "                )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYr-iTzVmXZu",
        "colab_type": "text"
      },
      "source": [
        "We fiw the number of epochs to 4\n",
        "We also configure the learning rate "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQ1ymlmqf_4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# set number of epochs\n",
        "epochs = 2\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "# Create a schedule with a learning rate that decreases linearly after linearly increasing during a warmup period (0 here)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgwmHirxnEie",
        "colab_type": "text"
      },
      "source": [
        "### Constructing the training and validation loop \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7J6rIz4UnLwq",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZDt2ZElwcJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import f1_score \n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbZt12wxqh7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQxSQsQxm6mv",
        "colab_type": "code",
        "outputId": "e36bd323-a87f-465b-bfc2-5b5093f92c7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "# https://github.com/huggingface/transformers \n",
        "# https://github.com/chambliss/Multilingual_NER/blob/master/python/utils/main_utils.py#L404  \n",
        "# https://mccormickml.com/2019/07/22/BERT-fine-tuning/#4-train-our-classification-model\n",
        "\n",
        "import random\n",
        "# Let's put a seed to make this result reproducible \n",
        "seed=2020\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "# We want to evaluate the training phase \n",
        "training_stats = []\n",
        "\n",
        "for ep in range(0, epochs):\n",
        "  print('===========Starting Epoch {} / {} =============='.format(ep+1,epochs))\n",
        "  print('Training starts')\n",
        "\n",
        "  \n",
        "\n",
        "  ################################### TRAINING ################################\n",
        "\n",
        "  # Set the train loss for the epoch to 0 \n",
        "  total_train_loss = 0\n",
        "\n",
        "  #Put the model in training \n",
        "  gender_model1.train()\n",
        "\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    # Cpy the 3 batch to GPU \n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "\n",
        "    # Clear gradients \n",
        "    gender_model1.zero_grad() \n",
        "    \n",
        "    #return loss and logits\n",
        "    loss, logits = gender_model1(b_input_ids, \n",
        "                         token_type_ids=None, \n",
        "                         attention_mask=b_input_mask, \n",
        "                         labels=b_labels) \n",
        "    \n",
        "    # Accumulate training loss for all batches \n",
        "    total_train_loss += loss.item()\n",
        "\n",
        "    # Backward to calculate gradients \n",
        "    loss.backward()\n",
        "\n",
        "    # Prevent exploding gradients problem \n",
        "    torch.nn.utils.clip_grad_norm_(gender_model1.parameters(), 1.0)\n",
        "\n",
        "    # Update parameters \n",
        "    optimizer.step()\n",
        "\n",
        "    # Update learning rate schedule\n",
        "    scheduler.step()\n",
        "\n",
        "  #Calculate the average training loss over all batches  \n",
        "  avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "  print(\"\")\n",
        "  print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "  print('')\n",
        "  print('And now, validation STARTS')\n",
        "\n",
        "  ###################### VALIDATION #############################\n",
        "\n",
        "  # Put model in evaluation mode \n",
        "  gender_model1.eval()\n",
        "\n",
        "  # Set statistics to 0\n",
        "  total_eval_accuracy = 0\n",
        "  total_eval_loss = 0\n",
        "  nb_eval_steps = 0\n",
        "\n",
        "  # Confusion matrix ?\n",
        "  predictions, true_labels = [], []\n",
        "\n",
        "  for batch in val_dataloader:\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "     \n",
        "     # We don't care about gradients for eval\n",
        "    with torch.no_grad(): \n",
        "      (loss, logits) = gender_model1(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "    total_eval_loss += loss.item()\n",
        "\n",
        "      # Move logits and labels to CPU \n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    # Confusion matrix ?\n",
        "    val_batch_preds = np.argmax(logits, axis=1)\n",
        "    val_batch_labels = label_ids\n",
        "    predictions.extend(val_batch_preds)\n",
        "    true_labels.extend(val_batch_labels)\n",
        "\n",
        "    # Accumulation accuracy for all batch\n",
        "    total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "    \n",
        "    #Final accuracy on all batch\n",
        "  avg_val_accuracy = total_eval_accuracy / len(val_dataloader)\n",
        "  print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    #Final loss over all batch\n",
        "  avg_val_loss = total_eval_loss / len(val_dataloader)\n",
        "  print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "\n",
        "  # confusion matrix ? \n",
        "  pred_tags = [i for i in predictions]\n",
        "  valid_tags = [i for i in true_labels]\n",
        "\n",
        "  # f1 score \n",
        "  F1_score_val = f1_score(valid_tags,pred_tags)\n",
        "\n",
        "\n",
        "  training_stats.append(\n",
        "        {\n",
        "            'epoch': ep + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Valid F1_score' : F1_score_val\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Done !\")"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===========Starting Epoch 1 / 3 ==============\n",
            "Training starts\n",
            "\n",
            "  Average training loss: 0.49\n",
            "\n",
            "And now, validation STARTS\n",
            "  Accuracy: 0.76\n",
            "  Validation Loss: 0.64\n",
            "===========Starting Epoch 2 / 3 ==============\n",
            "Training starts\n",
            "\n",
            "  Average training loss: 0.43\n",
            "\n",
            "And now, validation STARTS\n",
            "  Accuracy: 0.77\n",
            "  Validation Loss: 0.82\n",
            "===========Starting Epoch 3 / 3 ==============\n",
            "Training starts\n",
            "\n",
            "  Average training loss: 0.23\n",
            "\n",
            "And now, validation STARTS\n",
            "  Accuracy: 0.80\n",
            "  Validation Loss: 0.97\n",
            "\n",
            "Done !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnqfBkNDKVxW",
        "colab_type": "code",
        "outputId": "9a61d589-8fa6-4d56-fedb-f3fa4b59707c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Confusion matrix sur le dernier epoch (à insérer pour avoir les trois ? )\n",
        "confusion_matrix(valid_tags, pred_tags)"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[650, 129],\n",
              "       [193, 625]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKUBFeBAJTOK",
        "colab_type": "code",
        "outputId": "3114daf1-04dd-41d9-f5a1-440b721f5aca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        }
      },
      "source": [
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "conf_mat = confusion_matrix(valid_tags, pred_tags)\n",
        "\n",
        "df_cm = pd.DataFrame(conf_mat)\n",
        "plt.figure(figsize = (10,7))\n",
        "sn.heatmap(df_cm, annot=True)\n",
        "plt.show()"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAGmCAYAAACUbzs0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEAABAADjEAABAADjEAABAADj/D/3++axbPp9JAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KceMm2E-0dF1",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "We can't look at accuracy with confidence. Indeed, our sample is really unbalanced and thus classifying all text as male would already give a 0.75 accuracy. This is exactly what happens here\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PviHO7vHm65o",
        "colab_type": "code",
        "outputId": "a4823322-0d65-4ba9-f8a5-91ac046df747",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "df_stats"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.488155</td>\n",
              "      <td>0.644946</td>\n",
              "      <td>0.755625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.426781</td>\n",
              "      <td>0.817257</td>\n",
              "      <td>0.773125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.226125</td>\n",
              "      <td>0.969664</td>\n",
              "      <td>0.798750</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur.\n",
              "epoch                                           \n",
              "1           0.488155     0.644946       0.755625\n",
              "2           0.426781     0.817257       0.773125\n",
              "3           0.226125     0.969664       0.798750"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhJY9ZzP2JwK",
        "colab_type": "code",
        "outputId": "e383121b-cf32-4879-fdcb-fd24af6b5395",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4, 5])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAusAAAGaCAYAAAC2bw3EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCuM7GlhsZyg",
        "colab_type": "text"
      },
      "source": [
        "Our model is completely over fitting after 2 epochs !"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QXyz5wUidkY",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNnQ2WrXicsx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fd6d735e-b597-4eeb-c5aa-10365e6186c9"
      },
      "source": [
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df_dev.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "texts = df_dev.Texte.values\n",
        "labels = df_dev.sexe.values\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "num_truncated_tokens =[]\n",
        "# Apply function to our corpus\n",
        "for text in texts:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        text,                      # text\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 500,           # We choose for now a max length of 500.\n",
        "                        pad_to_max_length = True,    # Pad text to max (marche pas en pad left ?)\n",
        "                        return_attention_mask = True,   # Construct attention masks\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                        return_overflowing_tokens =True, # return overflowing token information\n",
        "                   )\n",
        "    \n",
        "    # Map tokens to their id in the dictionnary \n",
        "    # We add this to our list    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        " \n",
        "    #num_truncated_tokens.append(encoded_dict['num_truncated_tokens'])\n",
        "    \n",
        "    # 3. Attention masks\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 8  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test sentences: 160\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXSH_9xVjA6H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "606694f6-5248-475a-c9d3-4a446e17a341"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "gender_model1.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = gender_model1(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  #predictions.append(logits)\n",
        "  #true_labels.append(label_ids)\n",
        "  val_batch_preds = np.argmax(logits, axis=1)\n",
        "  val_batch_labels = label_ids\n",
        "  predictions.extend(val_batch_preds)\n",
        "  true_labels.extend(val_batch_labels)\n",
        "\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 160 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhpJRYTPjJ-i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XP9p0dsbptCx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_tags = [i for i in predictions]\n",
        "true_tags = [i for i in true_labels]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrjnt2WUqaDT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZW4IKLjjMMC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "37f0f4dd-1c88-4429-a1e6-208b100d3718"
      },
      "source": [
        "f1_score(true_tags,pred_tags)"
      ],
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9273743016759777"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 238
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4crdydWqx6A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dda7d7df-3b8c-41cf-a8fe-6b194ff6d54f"
      },
      "source": [
        "accuracy_score(true_tags, pred_tags)"
      ],
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.91875"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 239
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrKoHdGWrXtJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_true_pred=pd.DataFrame([true_tags,pred_tags]).transpose()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBpl6xQtrvQj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_true_pred.columns=['true_tags','pred_tags']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8G2vJn0ryWV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "5a10c86d-0587-446b-cced-87913e04257c"
      },
      "source": [
        "df_true_pred[df_true_pred['true_tags']!=df_true_pred['pred_tags']]"
      ],
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>true_tags</th>\n",
              "      <th>pred_tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     true_tags  pred_tags\n",
              "14           1          0\n",
              "15           0          1\n",
              "29           1          0\n",
              "49           1          0\n",
              "54           0          1\n",
              "60           1          0\n",
              "63           1          0\n",
              "86           0          1\n",
              "105          1          0\n",
              "114          0          1\n",
              "137          0          1\n",
              "147          1          0\n",
              "151          0          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 248
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR! Session/line number was not unique in database. History logging moved to new session 68\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcGOO8vm3jwL",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdmReVji0KF5",
        "colab_type": "text"
      },
      "source": [
        "RESTE A FAIRE A VOIR AVEC MELCHIOR \n",
        "A discuter : \n",
        "- optimizer\n",
        "- number of batch / sample / epochs (low) \n",
        "- change criterion \n",
        "- More analysis ? what to add ? \n",
        "\n",
        "\n",
        "RESTE A FAIRE MORGANE : \n",
        "- improve loop ? \n",
        "- Analyse test set (which one were not well predicted)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2heoobpm69S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5oSWe6nm63Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqcRkgeSm60n",
        "colab_type": "code",
        "outputId": "103fcb28-f464-4e65-8b5f-41bb710cac79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "@article{Wolf2019HuggingFacesTS,\n",
        "  title={HuggingFace's Transformers: State-of-the-art Natural Language Processing},\n",
        "  author={Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and R'emi Louf and Morgan Funtowicz and Jamie Brew},\n",
        "  journal={ArXiv},\n",
        "  year={2019},\n",
        "  volume={abs/1910.03771}\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-26-c848a20e4352>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    @article{Wolf2019HuggingFacesTS,\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2xLw0mY6tzP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}