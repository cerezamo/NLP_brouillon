{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Camembert_v2.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cerezamo/NLP_brouillon/blob/master/Camembert_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcxLW3uyHTSN",
        "colab_type": "text"
      },
      "source": [
        "# CamemBERT classification model \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1JD-Tb0HdvN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f21e29e-4a4d-48a7-823f-a78d4cc17fbd"
      },
      "source": [
        "import spacy \n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import os \n",
        "os.getcwd()\n",
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bxA1IEgH-GI",
        "colab_type": "text"
      },
      "source": [
        "## Set up Colab GPU "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mF6Hs6yH2A5",
        "colab_type": "code",
        "outputId": "4f2648c9-7287-489f-e523-e834985de296",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#%tensorflow_version 1.x\n",
        "# First you should go in 'Edit' -> 'Notebook settings' -> Add device GPU\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "# GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "device_name"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ_F6NV3IaCY",
        "colab_type": "text"
      },
      "source": [
        "Let's now tell torch that one GPU is available "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wr4fjemjIVoQ",
        "colab_type": "code",
        "outputId": "66348da5-159d-4909-821c-eef6597bda0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():  \n",
        "        \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LcRSHffJyZm",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Please check GPU capacity that you were given. You might want to reduce the batch size further in the code. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGwjFzizIsMI",
        "colab_type": "text"
      },
      "source": [
        "Let's install the Hugging Face Library transformer package "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--g7cokfIrpT",
        "colab_type": "code",
        "outputId": "bda26544-a963-4414-8dff-eb12bc5e103d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "! pip install transformers "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.31)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.31 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.31)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.31->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.31->boto3->transformers) (2.8.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4OKq8Z4JId9",
        "colab_type": "text"
      },
      "source": [
        "## Loading our corpus and preparing samples "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aGxDbDU4_BQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We keep the same seed value all along this notebook in order to be able to replicate the results \n",
        "seed_val = 2020 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOCVLtje9_Rs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import medium_df_desq in \"files\" (on the left) => ICI prendre du github ??\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df=pd.read_csv('medium_df_deseq.xls',encoding='utf-8')\n",
        "# Shuffle the date\n",
        "df=df.sample(frac=1,random_state=seed_val).reset_index(drop=True)\n",
        "# Some of the speeches are interviews (wrongly classified in the website) we try to delte them here \n",
        "df=df[~df.Texte.str.startswith(\"Q-\")]\n",
        "df=df[~df.Texte.str.startswith(\"R-\")]\n",
        "\n",
        "# We replace the labels in a more normalized way : 0=men, 1=women \n",
        "df.sexe=df.sexe.replace(1,0)\n",
        "df.sexe=df.sexe.replace(2,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nn1jaLDV6VIq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We keep only variables of interest \n",
        "df=df[['Id','Titre','Theme','Prenom','Nom','Date','Tags','Texte','sexe']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvTn5dA-CwBd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "859b36e1-0fb9-4f49-95a4-af6bc61b2677"
      },
      "source": [
        "# This is a sample of our dataset\n",
        "df.head(5)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Titre</th>\n",
              "      <th>Theme</th>\n",
              "      <th>Prenom</th>\n",
              "      <th>Nom</th>\n",
              "      <th>Date</th>\n",
              "      <th>Tags</th>\n",
              "      <th>Texte</th>\n",
              "      <th>sexe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>168124</td>\n",
              "      <td>Déclaration de M. François Huwart, secrétaire ...</td>\n",
              "      <td>International</td>\n",
              "      <td>François</td>\n",
              "      <td>Huwart</td>\n",
              "      <td>2000-12-06T12:00:00Z</td>\n",
              "      <td>Relations internationales,Relations bilatérale...</td>\n",
              "      <td>Mesdames et Messieurs les parlementaires, Mesd...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>185036</td>\n",
              "      <td>Déclaration de M. François Hollande, sur le se...</td>\n",
              "      <td>Institutions</td>\n",
              "      <td>François</td>\n",
              "      <td>Hollande</td>\n",
              "      <td>2012-05-06T12:00:00Z</td>\n",
              "      <td>Citoyenneté - Elections,Election présidentielle</td>\n",
              "      <td>Mes amis, vous êtes une foule immense sur la p...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>128165</td>\n",
              "      <td>Déclaration de M. Michel Sapin, ministre de la...</td>\n",
              "      <td>Institutions</td>\n",
              "      <td>Michel</td>\n",
              "      <td>Sapin</td>\n",
              "      <td>2002-02-06T12:00:00Z</td>\n",
              "      <td>Administration - Réforme de l'Etat,Réforme de ...</td>\n",
              "      <td>Ce n'est pas nouveau : la droite accorde, en p...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>164040</td>\n",
              "      <td>Déclaration de M. Jacques Chirac, Président de...</td>\n",
              "      <td>International</td>\n",
              "      <td>Jacques</td>\n",
              "      <td>Chirac</td>\n",
              "      <td>2006-11-07T12:00:00Z</td>\n",
              "      <td>Défense,Armement</td>\n",
              "      <td>Madame la Ministre, Mon Général, Monsieur le D...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>133799</td>\n",
              "      <td>Déclaration de M. Luc Guyau, président de la F...</td>\n",
              "      <td>Société</td>\n",
              "      <td>Luc</td>\n",
              "      <td>Guyau</td>\n",
              "      <td>2000-05-29T12:00:00Z</td>\n",
              "      <td>Environnement,Eau</td>\n",
              "      <td>Mesdames, Messieurs,Chers amis,Si la professio...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Id  ... sexe\n",
              "0  168124  ...    0\n",
              "1  185036  ...    0\n",
              "2  128165  ...    0\n",
              "3  164040  ...    0\n",
              "4  133799  ...    0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48nemL1W3XKK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For the cleaning part we will just remove urls from the text \n",
        "import re\n",
        "def remove_urls (text):\n",
        "    text = re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', '', text, flags=re.MULTILINE)\n",
        "    return text \n",
        "\n",
        "df['Texte']=df.Texte.apply(remove_urls)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTKQ0QnAZ_wu",
        "colab_type": "text"
      },
      "source": [
        "**We propose 3 samples to train our model :**\n",
        "\n",
        "\n",
        "1.   **Unbalanced sample**\n",
        "\n",
        "We take the raw data without any further treatment.\n",
        "\n",
        "2.   **Balanced sample**\n",
        "\n",
        "The second option consist in deleting randomly part of male speeches in order to get a balanced sample. Indeed, in the case of unbalanced sample our model could decide to classify all speakers in the male category which would lead to a 0.75 accuracy in our case study. In order to avoid this we feed the model with the same proportions of male and female speakers. Other kind of treatments exist to deal with unbalanced sample. This one is the simpliest one and we could argue that there is a possibility that the deleted sample contains important information that we therefore miss. However we believe that in our case this is not a big issue. Our unbalanced sample is quite large for both female and male.\n",
        "\n",
        "3. **Balanced and splitted sample**\n",
        "\n",
        "The third option is a response to the max length constraint of BERT models. Our text samples are big and contain much more tokens than the 512 limit. In the first two options we decide to just feed the model with the 512 first tokens and thus delete the rest of them. In this third option we cut the text into x parts containing 500 tokens each. All parts of the speech will serve to feed the model. By this technique we do not loose potential important informations at the end of the text. A lot of other techniques have been employed (see ref !!! PUT). We decide to stick to this one in this project. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ae8ICVGvUBLv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unbalanced_preprocess(df,seed_val,frac_val):\n",
        "\n",
        "  from sklearn.model_selection import train_test_split\n",
        "\n",
        "  #Shuffle the data \n",
        "  #df_unbalanced=df.sample(frac=frac_val).reset_index()\n",
        "  df_unbalanced=df\n",
        "\n",
        "  # Report the number of speeches in the corpus.\n",
        "  print('Number of text in the unbalanced corpus : {:,}\\n'.format(df_unbalanced.shape[0]))\n",
        "  prop = (len(df_unbalanced[df_unbalanced.sexe==1])/len(df_unbalanced))*100\n",
        "  print('Proportions of women in the unbalanced corpus : {}\\n'.format(prop))\n",
        "\n",
        "  return df_unbalanced"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IdYJSSRUdD0",
        "colab_type": "code",
        "outputId": "df424e9c-56c8-4b84-d0f1-6e8dc6110113",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "df_unbalanced = unbalanced_preprocess(df,seed_val,frac_val=1) "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of text in the unbalanced corpus : 4,998\n",
            "\n",
            "Proportions of women in the unbalanced corpus : 25.010004001600638\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd4SCY6LUuwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def balanced_preprocess(df,seed_val,frac_val):\n",
        "  from sklearn.model_selection import train_test_split\n",
        "\n",
        "  # Let's take a balanced sample \n",
        "  df_m = df.loc[df['sexe'] == 0]\n",
        "  df_f = df.loc[df['sexe'] == 1] \n",
        "  df_m = df_m[0:len(df_f)]\n",
        "  df = df_f.append(df_m)\n",
        "\n",
        "  #Shuffle the data and taking half of the sample in order not to have to many data compared to the other samples \n",
        "  df_balanced=df.sample(frac=frac_val,random_state=seed_val).reset_index()\n",
        "\n",
        "  # Report the number of speeches in the corpus.\n",
        "  print('Number of text in this corpus : {:,}\\n'.format(df_balanced.shape[0]))\n",
        "  prop = (len(df_balanced[df_balanced.sexe==1])/len(df_balanced))*100\n",
        "  print('Proportions of women in the balanced corpus : {}\\n'.format(prop))\n",
        "\n",
        "  return df_balanced\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeQif_N0X4uW",
        "colab_type": "code",
        "outputId": "1ef3dc84-b142-4237-abdb-a75317f1a00e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "df_balanced = balanced_preprocess(df,seed_val,frac_val=1)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of text in this corpus : 2,500\n",
            "\n",
            "Proportions of women in the balanced corpus : 50.0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgxCphDnCiPQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "def sent_detector_mano(x):\n",
        "    \"\"\"\n",
        "        Détection de phrase à la main.\n",
        "        Input : document\n",
        "        Output : liste de phrases\n",
        "        Problème avec les phrases finissant par : entrainant souvent une liste. \n",
        "        De même avec ;. Tentative réalisée\n",
        "        \n",
        "    \"\"\"\n",
        "    lst =[]\n",
        "    phrase = []\n",
        "    i = 0\n",
        "    for caractere in x: \n",
        "        if not (caractere == ' ' and len(phrase) == 0) :\n",
        "            phrase.append(caractere)\n",
        "        if caractere in '?!.:;':\n",
        "            if caractere == ':':\n",
        "                if x[i+1].isupper() or x[i+2].isupper() or x[i+1] == '-' or x[i+2] == '-':\n",
        "                    lst.append(''.join(phrase))\n",
        "                    phrase = []\n",
        "            if caractere == ';':\n",
        "                if x[i+1].isupper() or x[i+2].isupper() or x[i+1] == '-' or x[i+2] == '-':\n",
        "                    lst.append(''.join(phrase))\n",
        "                    phrase = []\n",
        "            elif phrase != '.' or phrase != '?' or phrase != '!':\n",
        "                lst.append(''.join(phrase))\n",
        "                phrase = []\n",
        "        i+=1\n",
        "    return lst\n",
        "def split_document_to_limit(MAX_TOKENS,df):\n",
        "  lst= []\n",
        "  for index,row in df.iterrows():\n",
        "    identifiant = row.Id\n",
        "    label = row.sexe\n",
        "    phrase = []\n",
        "    for token in row.Texte.split(' '):\n",
        "      if len(phrase) < MAX_TOKENS:\n",
        "        phrase.append(token)\n",
        "      else:\n",
        "        lst += [(identifiant,label,' '.join(phrase),len(phrase))]\n",
        "        phrase = []\n",
        "    if len(phrase)>1:\n",
        "      lst += [(identifiant,label,' '.join(phrase),len(phrase))]\n",
        "  return pd.DataFrame(lst,columns=['index_df','sexe','Texte','Length'])\n",
        "def split_document_to_limit_phrases(MAX_TOKENS,df):\n",
        "  lst= []\n",
        "  for index,row in df.iterrows():\n",
        "    identifiant = row.Id\n",
        "    label = row.sexe\n",
        "    phrase = ''\n",
        "    for phrases in sent_detector_mano(row.Texte):\n",
        "      if len(phrase.split(' ')) + len(phrases.split(' ')) < MAX_TOKENS:\n",
        "        phrase+= \" \" + phrases\n",
        "      else:\n",
        "        lst += [(identifiant,label,phrase,len(phrase.split(' ')))]\n",
        "        phrase = ''\n",
        "    lst += [(identifiant,label,phrase,len(phrase.split(' ')))]\n",
        "    phrase = ''\n",
        "  return pd.DataFrame(lst,columns=['index_df','sexe','Texte','Length'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3qnfTDXCwF9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def  balanced_splitted(df,seed_val,frac_val,max_tokens):\n",
        "  # Let's take a balanced sample \n",
        "  df_m = df.loc[df['sexe'] == 0]\n",
        "  df_f = df.loc[df['sexe'] == 1] \n",
        "  df_m = df_m[0:len(df_f)]\n",
        "  df = df_f.append(df_m)\n",
        "\n",
        "  df=split_document_to_limit(max_tokens,df)\n",
        "\n",
        "  df_balanced_split=df.sample(frac=frac_val,random_state=seed_val).reset_index()\n",
        "\n",
        "  # Report the number of speeches in the corpus.\n",
        "  print('Number of text in this balanced splitted corpus : {:,}\\n'.format(df_balanced_split.shape[0]))\n",
        "  prop = (len(df_balanced_split[df_balanced_split.sexe==1])/len(df_balanced_split))*100\n",
        "  print('Proportions of women in the balanced splitted corpus : {}\\n'.format(prop))\n",
        "\n",
        "  return df_balanced_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEpbT1JYf5-",
        "colab_type": "code",
        "outputId": "a3bd5c58-17e4-4bea-cd49-07132ea6e6c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "df_balanced_split = balanced_splitted(df,seed_val,frac_val=0.5,max_tokens=450)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of text in this balanced splitted corpus : 5,616\n",
            "\n",
            "Proportions of women in the balanced splitted corpus : 50.69444444444444\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ressz8h6OHxn",
        "colab_type": "text"
      },
      "source": [
        "## Tokenization and preparing to feed CamemBERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntpzo9X5SSjA",
        "colab_type": "text"
      },
      "source": [
        "### Loading the Camembert Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mggkz5R9g8dD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Camembert tokenizer\n",
        "from transformers import CamembertTokenizer\n",
        "# We choose a right padding side for the moment and we will test for a left padding side on a second stage\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-base', do_lower_case=False,padding_side='right') #left"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoaZUUBChM_J",
        "colab_type": "code",
        "outputId": "8ed8df00-aaea-4c5a-b255-92e0dad8712c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# Print the original text.\n",
        "print(' Original: ', df.Texte[0])\n",
        "\n",
        "# Print the text split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(df.Texte[0]))\n",
        "\n",
        "# Print the text mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(df.Texte[0])))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  Mesdames et Messieurs les parlementaires, Mesdames et Messieurs les ambassadrices et ambassadeurs, Mesdames, Messieurs,Je voudrais tout d'abord remercier chaleureusement Charles Josselin, mon collègue chargé de la coopération et de la francophonie, ainsi qu'Ariane Obolenski, présidente du Centre français du commerce extérieur, qui organisent ce séminaire consacré à l'Afrique. Tous ceux qui font vivre au quotidien notre partenariat avec le continent africain sont d'ailleurs présents ce matin.Ce n'est bien sûr pas un hasard si les acteurs du commerce et du développement rencontrent aujourd'hui les entreprises.Des évolutions profondes sont en effet à l'uvre depuis quelques temps. Elles touchent à la réorientation des stratégies d'aide vers le développement durable, ou à l'annulation de la dette des pays les plus pauvres et les plus endettés. Ces changements de mentalité, on les retrouve également dans la sphère commerciale. Seattle aura été une étape décisive : les pays en développement ont élevé la voix pour se faire entendre dans le concert multilatéral. Ils ont tout simplement signifié leur refus d'une mondialisation dont ils ne seraient pas des acteurs de plein droit.L'Afrique subsaharienne a besoin de l'OMC pour bénéficier de perspectives de développement Face aux interactions de l'économie globale, il n'est plus possible de cloisonner les questions liées au commerce, au développement, à l'environnement ou aux normes, qu'elles soient sanitaires ou sociales. Cela exige de chacun un réel effort d'ouverture aux logiques des autres. Cela exige aussi un renforcement de l'expertise technique pour faire face à des problématiques souvent très complexes.Mais, au delà des questions techniques, ne perdons jamais de vue ce qui importe vraiment. En Afrique subsaharienne, près de la moitié de la population vit dans le dénuement. Et par dénuement, je veux dire simplement vivre avec moins de un dollar par jour Dans les 48 pays les moins avancés, un tiers seulement des enfants fréquente régulièrement une école. Voilà la situation actuelle. Il n'est malheureusement pas certain que les choses évoluent naturellement dans le bon sens. Sur la décennie écoulée, on a recensé entre 70 et 80 millions de \" nouveaux \" pauvres en Afrique sub-saharienne. Une autre tendance statistique saute aux yeux : c'est celle de la place des PMA dans le commerce mondial. Ces 48 pays les plus pauvres, essentiellement africains, représentent aujourd'hui un demi pour cent du total des exportations. Le développement accéléré des échanges - + 14 % sur les 9 premiers mois de l'an 2000 - est l'aspect le plus spectaculaire de la mondialisation. Il doit donc offrir des perspectives de développement à tous les pays, et en particulier aux PMA. Voici pourquoi je suis convaincu qu'aujourd'hui, l'Afrique a besoin de l'OMC. Et je vous dirai dans un instant pourquoi l'OMC a besoin de l'Afrique. Prise de conscience mondiale : concilier justice et réalisme vers un nouveau cycle de l'OMC Pourquoi, me direz-vous, cette prise de conscience, cet intérêt soudain de la part des pays industrialisés pour un monde en développement qui représente une part réduite du commerce mondial ? Je vous répondrai que cette prise de conscience ne date pas d'hier. Mais il est vrai mais que sa cristallisation récente autour de thèmes forts comme le commerce ou la dette s'explique par la volonté des pays en développement de faire entendre leur voix. Cette prise de conscience a été précipitée par l'évolution-même du monde, par la formidable accélération du progrès technologique et des échanges.Pour aborder ces questions difficiles, nous devons concilier justice et réalisme. Justice, car personne ne comprendrait par exemple qu'une organisation internationale dont la double ambition est de libéraliser et d'encadrer les échanges de biens et de services, n'écoute et n'entende que la voix des plus forts. Mike Moore, son directeur général, a vu dans le sommet Afrique-OMC de Libreville un \" symbole fort \". C'était en effet, la première conférence sur le commerce, entre Africains et en Afrique ; l'OMC a bel et bien aussi besoin de l'Afrique. Les pays africains doivent s'affirmer rapidement comme des acteurs incontournables de cette instance. Tout le monde a bien compris désormais que le lancement, puis le succès d'un cycle large reposent sur la conviction de chacun des participants d'y avoir un véritable intérêt.Mais le réalisme économique et commercial nous commandent de considérer la grande diversité des situations et des rythmes de développement propres à chaque pays. Ne nous voilons pas la face : les écarts de richesses, de productivité, d'investissement sont considérables. Un pays comme la Malaisie accueille autant d'IDE que l'ensemble du continent africain. Et le risque existe que l'accélération technologique que j'évoquais ne fasse qu'accentuer ces déséquilibres. Je vois là une raison de plus pour refuser la loi de la jungle et fixer les règles du jeu commercial. Nous en sommes tous conscients, l'équation n'est pas simple à résoudre : comment ne pas décourager les plus dynamiques, sans désespérer les retardataires ? Comment faire que chacun progresse à son rythme en atténuant l'impact des crises ? Mon sentiment est que seul un cycle commercial global et élargi peut le permettre. Un accord général suppose des concessions réciproques, d'autant moins difficiles à obtenir que les thématiques sont larges, alors que des négociations partielles ou sectorielles, menées à la hâte pour des résultats à court terme, entraînent forcément crispations et blocages. Les récoltes trop précoces donnent parfois des fruits verts, au goût amer.C'est le sens du travail d'explication que nous menons avec Mike Moore, avec l'Union européenne et de nombreux pays en développement afin qu'un cycle redémarre sur des bases élargies, solides et qui inspirent confiance.Au-delà des règles commerciales Mais les règles commerciales ne suffisent pas : elles organisent un cadre et offrent des opportunités qui ne pourront être réalisées que si les économies en ont la capacité. Mais le commerce ne suffit pas. L'aide, qui passe par des transferts d'épargne, se doit d'apporter un filet de sécurité, mais aussi l'encouragement nécessaire, par la réalisation de projets exemplaires, car réussis et pérennes. Cette aide ne peut pas être seulement financière, elle suppose des logiques de partenariat, des transferts de savoir-faire et de technologie, bref, tout ce qui peut contribuer à créer plus de valeur ajoutée dans les pays en développement.Je veux toutefois souligner que l'aide bilatérale française qui est orientée directement vers le renforcement des capacités commerciales des pays africains est tout à fait substantielle. Sur la période 1995 - 2000, le volume global d'engagement de l'aide française sur des projets contribuant au renforcement des capacités exportatrices s'élève à près de 5,6 Milliards de francs, hors prêts d'ajustement structurel. Environ 60 % de cette aide est directement affectée à des projets de développement de la production exportée. 35 % de cette aide porte sur des projets d'infrastructures directement liés à l'amélioration du commerce extérieur africain, tels que les réseaux routiers, dont vous savez que la modernisation est cruciale pour une majorité de pays africains, les infrastructures portuaires et aéroportuaires. Enfin, le solde de cette coopération porte sur des actions de modernisation, administrative, juridique, institutionnelle, par exemple en matière douanière, en matière de propriété intellectuelle ou de droit des affaires, qui sont des facteurs déterminants pour l'insertion de l'Afrique dans les échanges mondiaux. Un système juridique efficace représente certes un coût pour les pays pauvres, mais constitue aussi un avantage comparatif dans la compétition mondiale.A ces actions de coopération en partenariat, s'ajoutent les initiatives commerciales visant à renforcer la capacité exportatrice des pays en développement les moins avancés ou, plus largement, des pays de la zone Afrique Caraïbes Pacifique.S'agissant des pays les moins avancés, nous travaillons activement au sein de l'Union afin d'offrir une entrée sans droits de douanes de tous leurs produits : c'est un projet important auquel nous tenons, même s'il n'a pas encore abouti.Enfin, comment ne pas signaler également les efforts de long terme consentis dans le cadre des diverses conventions dites de Lomé, qui se sont concrétisées une fois de plus à Cotonou début 2000 afin d'offrir un cadre particulièrement privilégié d'accès au marché européen pour les produits des Etats ACP.Tout cela doit permettre aux investisseurs étrangers et locaux de créer de la valeur ajoutée. Pour ce faire, la confiance, la transparence, la sécurité des personnes et des biens, constituent des paramètres critiques. C'est un domaine où l'exemple vient de haut, où il faut beaucoup de temps pour construire et si peu pour décourager les bonnes volontés. La communauté internationale, et l'Union européenne en particulier, travaillent sans relâche à créer un environnement stable. Les mesures prises à l'OCDE ou dans d'autres instances en vue d'atteindre une plus grande transparence financière des échanges internationaux vont dans ce sens, de même que l'ajustement structurel, tout particulièrement lorsqu'il accompagne des mesures d'annulations de créances des pays pauvres les plus endettés. Mais le dernier mot appartient forcément aux intéressés eux-mêmes. Dans de nombreux pays africains ou méditerranéens, l'environnement de l'activité économique peut encore être largement amélioré.Quel est alors le rôle des entreprises dans cet ensemble ?Un rôle essentiel, à l'évidence. Les entreprises s'adaptent à l'intégration économique mondiale. Elles sont donc les premières bénéficiaires de la multilatéralisation des règles du jeu des échanges, que le cadre soit planétaire ou régional.Nous attendons, en tant que pouvoirs publics, que grandes ou petites, elles nous fassent part, de façon structurée et précise, de leurs préoccupations, ou de leurs espoirs, vis à vis des projets de règles du jeu que nous élaborons avec nos collègues européens. Nous souhaitons bien sûr qu'elles intègrent les logiques de partenariat évoquées plus haut, non seulement vis-à-vis des entreprises des pays en développement, mais également en direction de leurs homologues européennes.Les financements d'aide au développement, qu'il s'agisse de ceux de l'Agence française de développement, dans la zone de solidarité prioritaire ou de ceux de la Direction des relations économiques extérieures, avec la réserve pays émergents, constituent un moyen classique et sûr de réaliser des projets. Comme vous le savez, la COFACE intervient également en Afrique lorsque la rentabilité d'un projet permet d'y adosser un schéma de garantie solide.D'autres procédures, comme cela vous a été exposé ce matin, permettent d'accompagner vos stratégies d'investissementQuelques exemples pour illustrer notre action. La COFACE couvre des opérations de court terme et de long terme, comme l'usine d'aluminium de Mozal au Mozambique, et s'est installée, avec l'aide de Proparco, en Côte d'Ivoire afin de couvrir les opérations de commerce régional. Le CFCE a développé un certain nombre de coopérations sur le continent. Au plan multilatéral, nous uvrons pour que les pays africains améliorent leur expertise vis à vis de l'OMC et disposent des moyens financiers pour participer effectivement aux discussions.En liaison avec le Ministère des affaires étrangères, nous avons mis au point un partenariat avec le CFCE pour développer le site Internet \" Investir en Zone Franc \", destiné à donner en ligne toutes les premières informations utiles. Une autre priorité de notre politique est de favoriser le développement de l'intégration régionale en Afrique. Et je suis persuadé que les entreprises sont les premières intéressées par cette évolution. L'absence de marché régional constitue certainement un frein à l'accueil d'investissements directs. Les accords de partenariats économiques régionaux (APER) prévus par la convention de Cotonou sont à mes yeux un vecteur puissant de cette dynamique qui conduit à un marché commun en Afrique de l'ouest et en Afrique centrale. Déjà le traité OHADA permet l'unification progressive du droit des affaires.Autant d'initiatives qui préparent l'avenir et doivent être poursuivies et amplifiées avec détermination. Mais tout cela n'est rien sans le relais des entreprises, sans leur volonté de créer de la richesse et de l'activité. C'est à vous, chefs d'entreprises, de tirer le meilleur parti possible de ces instruments à votre disposition.Conclusion Permettez-moi, pour conclure, de revenir à l'Afrique. Je me suis rendu à plusieurs reprises sur ce continent, plus, je crois, qu'aucun de mes prédécesseurs au commerce extérieur. Encore récemment, nous étions, avec Charles Josselin, à Libreville, afin d'apporter notre soutien à nos collègues ministres du commerce de l'ensemble du continent. Certes, la place de l'Afrique dans les échanges mondiaux ou les investissements directs étrangers est faible et certainement pas proportionnelle à sa démographie. Nous savons tous les efforts que nos amis africains se doivent d'accomplir dans de nombreux domaines pour modifier l'image et les réalités de ce continent.L'Europe, et tout particulièrement la France, ont largement fait la preuve de leur fidélité à l'Afrique. Je suis allé à Abidjan l'année dernière pour inaugurer l'exposition France Technologies : première manifestation d'une telle ampleur en Afrique de l'ouest. 300 entreprises françaises y étaient représentées : quelques grands groupes déjà bien implantés dans la région, mais aussi un grand nombre de PME-PMI représentant des secteurs d'activité très variés. J'avais puisé dans cette manifestation une force d'optimisme sur les grandes perspectives de développement durable et diversifié de la Côte d'Ivoire et de l'Afrique de l'ouest toute entière. Je suis bien sûr très peiné des événements les plus récents à Abidjan qui ont conduit à l'état d'urgence. Mais la période pénible qu'a connu la Côte d'Ivoire n'a pas découragé les entreprises. Elles sont restées, contre vents et marées, dans des conditions de travail parfois très difficiles et non sans conséquences financières, qu'il faudra d'ailleurs résoudre. Je tiens à les en remercier. Et je souhaite ardemment que la Côte d'Ivoire retrouve au plus vite la paix civile et le rôle de locomotive économique de l'Afrique de l'ouest qui doit être le sien.Mon collègue Guy-Alain Gauze, ici présent, ne me contredira pas si je vous dis qu'il faut persévérer. La persévérance, la patience et, disons-le, un peu de passion, sont des vertus cardinales pour réussir durablement. En Afrique peut-être plus qu'ailleurs. Je vous remercie. (source -exterieur.gouv.fr, le 11 décembre 2000\n",
            "Tokenized:  ['▁Mesdames', '▁et', '▁Messieurs', '▁les', '▁parlementaires', ',', '▁Mesdames', '▁et', '▁Messieurs', '▁les', '▁', 'ambassadrice', 's', '▁et', '▁', 'ambassadeur', 's', ',', '▁Mesdames', ',', '▁Messieurs', ',', 'Je', '▁voudrais', '▁tout', '▁d', \"'\", 'abord', '▁remercier', '▁chaleureusement', '▁Charles', '▁J', 'osse', 'lin', ',', '▁mon', '▁collègue', '▁chargé', '▁de', '▁la', '▁coopération', '▁et', '▁de', '▁la', '▁francophonie', ',', '▁ainsi', '▁qu', \"'\", 'Ar', 'iane', '▁O', 'bol', 'en', 'ski', ',', '▁présidente', '▁du', '▁Centre', '▁français', '▁du', '▁commerce', '▁extérieur', ',', '▁qui', '▁organisent', '▁ce', '▁séminaire', '▁consacré', '▁à', '▁l', \"'\", 'Afrique', '.', '▁Tous', '▁ceux', '▁qui', '▁font', '▁vivre', '▁au', '▁quotidien', '▁notre', '▁partenariat', '▁avec', '▁le', '▁continent', '▁africain', '▁sont', '▁d', \"'\", 'ailleurs', '▁présents', '▁ce', '▁matin', '.', 'Ce', '▁n', \"'\", 'est', '▁bien', '▁sûr', '▁pas', '▁un', '▁hasard', '▁si', '▁les', '▁acteurs', '▁du', '▁commerce', '▁et', '▁du', '▁développement', '▁rencontrent', '▁aujourd', \"'\", 'hui', '▁les', '▁entreprises', '.', 'Des', '▁évolutions', '▁profondes', '▁sont', '▁en', '▁effet', '▁à', '▁l', \"'\", 'uvre', '▁depuis', '▁quelques', '▁temps', '.', '▁Elles', '▁touchent', '▁à', '▁la', '▁ré', 'orientation', '▁des', '▁stratégies', '▁d', \"'\", 'aide', '▁vers', '▁le', '▁développement', '▁durable', ',', '▁ou', '▁à', '▁l', \"'\", 'annulation', '▁de', '▁la', '▁dette', '▁des', '▁pays', '▁les', '▁plus', '▁pauvres', '▁et', '▁les', '▁plus', '▁end', 'et', 'tés', '.', '▁Ces', '▁changements', '▁de', '▁mentalité', ',', '▁on', '▁les', '▁retrouve', '▁également', '▁dans', '▁la', '▁sphère', '▁commerciale', '.', '▁Seattle', '▁aura', '▁été', '▁une', '▁étape', '▁décisive', '▁:', '▁les', '▁pays', '▁en', '▁développement', '▁ont', '▁élevé', '▁la', '▁voix', '▁pour', '▁se', '▁faire', '▁entendre', '▁dans', '▁le', '▁concert', '▁multi', 'latéral', '.', '▁Ils', '▁ont', '▁tout', '▁simplement', '▁signifié', '▁leur', '▁refus', '▁d', \"'\", 'une', '▁mondialisation', '▁dont', '▁ils', '▁ne', '▁seraient', '▁pas', '▁des', '▁acteurs', '▁de', '▁plein', '▁droit', '.', 'L', \"'\", 'Afrique', '▁sub', 's', 'a', 'har', 'ienne', '▁a', '▁besoin', '▁de', '▁l', \"'\", 'OM', 'C', '▁pour', '▁bénéficier', '▁de', '▁perspectives', '▁de', '▁développement', '▁Face', '▁aux', '▁interactions', '▁de', '▁l', \"'\", 'économie', '▁globale', ',', '▁il', '▁n', \"'\", 'est', '▁plus', '▁possible', '▁de', '▁cloison', 'ner', '▁les', '▁questions', '▁liées', '▁au', '▁commerce', ',', '▁au', '▁développement', ',', '▁à', '▁l', \"'\", 'environnement', '▁ou', '▁aux', '▁normes', ',', '▁qu', \"'\", 'elles', '▁soient', '▁sanitaires', '▁ou', '▁sociales', '.', '▁Cela', '▁exige', '▁de', '▁chacun', '▁un', '▁réel', '▁effort', '▁d', \"'\", 'ouverture', '▁aux', '▁logique', 's', '▁des', '▁autres', '.', '▁Cela', '▁exige', '▁aussi', '▁un', '▁renforcement', '▁de', '▁l', \"'\", 'expertise', '▁technique', '▁pour', '▁faire', '▁face', '▁à', '▁des', '▁problématiques', '▁souvent', '▁très', '▁complexes', '.', 'Mais', ',', '▁au', '▁delà', '▁des', '▁questions', '▁techniques', ',', '▁ne', '▁perd', 'ons', '▁jamais', '▁de', '▁vue', '▁ce', '▁qui', '▁importe', '▁vraiment', '.', '▁En', '▁Afrique', '▁sub', 's', 'a', 'har', 'ienne', ',', '▁près', '▁de', '▁la', '▁moitié', '▁de', '▁la', '▁population', '▁vit', '▁dans', '▁le', '▁dé', 'nu', 'ement', '.', '▁Et', '▁par', '▁dé', 'nu', 'ement', ',', '▁je', '▁veux', '▁dire', '▁simplement', '▁vivre', '▁avec', '▁moins', '▁de', '▁un', '▁dollar', '▁par', '▁jour', '▁Dans', '▁les', '▁48', '▁pays', '▁les', '▁moins', '▁avancés', ',', '▁un', '▁tiers', '▁seulement', '▁des', '▁enfants', '▁fréquente', '▁régulièrement', '▁une', '▁école', '.', '▁Voilà', '▁la', '▁situation', '▁actuelle', '.', '▁Il', '▁n', \"'\", 'est', '▁malheureusement', '▁pas', '▁certain', '▁que', '▁les', '▁choses', '▁évoluent', '▁naturellement', '▁dans', '▁le', '▁bon', '▁sens', '.', '▁Sur', '▁la', '▁décennie', '▁écoulée', ',', '▁on', '▁a', '▁recensé', '▁entre', '▁70', '▁et', '▁80', '▁millions', '▁de', '▁\"', '▁nouveaux', '▁\"', '▁pauvres', '▁en', '▁Afrique', '▁sub', '-', 's', 'a', 'har', 'ienne', '.', '▁Une', '▁autre', '▁tendance', '▁statistique', '▁saute', '▁aux', '▁yeux', '▁:', '▁c', \"'\", 'est', '▁celle', '▁de', '▁la', '▁place', '▁des', '▁P', 'MA', '▁dans', '▁le', '▁commerce', '▁mondial', '.', '▁Ces', '▁48', '▁pays', '▁les', '▁plus', '▁pauvres', ',', '▁essentiellement', '▁africains', ',', '▁représentent', '▁aujourd', \"'\", 'hui', '▁un', '▁demi', '▁pour', '▁cent', '▁du', '▁total', '▁des', '▁exportations', '.', '▁Le', '▁développement', '▁accéléré', '▁des', '▁échanges', '▁-', '▁+', '▁14', '▁%', '▁sur', '▁les', '▁9', '▁premiers', '▁mois', '▁de', '▁l', \"'\", 'an', '▁2000', '▁-', '▁est', '▁l', \"'\", 'aspect', '▁le', '▁plus', '▁spectaculaire', '▁de', '▁la', '▁mondialisation', '.', '▁Il', '▁doit', '▁donc', '▁offrir', '▁des', '▁perspectives', '▁de', '▁développement', '▁à', '▁tous', '▁les', '▁pays', ',', '▁et', '▁en', '▁particulier', '▁aux', '▁P', 'MA', '.', '▁Voici', '▁pourquoi', '▁je', '▁suis', '▁convaincu', '▁qu', \"'\", 'aujourd', \"'\", 'hui', ',', '▁l', \"'\", 'Afrique', '▁a', '▁besoin', '▁de', '▁l', \"'\", 'OM', 'C', '.', '▁Et', '▁je', '▁vous', '▁dirai', '▁dans', '▁un', '▁instant', '▁pourquoi', '▁l', \"'\", 'OM', 'C', '▁a', '▁besoin', '▁de', '▁l', \"'\", 'Afrique', '.', '▁Prise', '▁de', '▁conscience', '▁mondiale', '▁:', '▁concilier', '▁justice', '▁et', '▁réalisme', '▁vers', '▁un', '▁nouveau', '▁cycle', '▁de', '▁l', \"'\", 'OM', 'C', '▁Pourquoi', ',', '▁me', '▁direz', '-', 'vous', ',', '▁cette', '▁prise', '▁de', '▁conscience', ',', '▁cet', '▁intérêt', '▁soudain', '▁de', '▁la', '▁part', '▁des', '▁pays', '▁industrial', 'isés', '▁pour', '▁un', '▁monde', '▁en', '▁développement', '▁qui', '▁représente', '▁une', '▁part', '▁réduite', '▁du', '▁commerce', '▁mondial', '▁?', '▁Je', '▁vous', '▁répondrai', '▁que', '▁cette', '▁prise', '▁de', '▁conscience', '▁ne', '▁date', '▁pas', '▁d', \"'\", 'hier', '.', '▁Mais', '▁il', '▁est', '▁vrai', '▁mais', '▁que', '▁sa', '▁cristal', 'lisation', '▁récente', '▁autour', '▁de', '▁thèmes', '▁forts', '▁comme', '▁le', '▁commerce', '▁ou', '▁la', '▁dette', '▁s', \"'\", 'explique', '▁par', '▁la', '▁volonté', '▁des', '▁pays', '▁en', '▁développement', '▁de', '▁faire', '▁entendre', '▁leur', '▁voix', '.', '▁Cette', '▁prise', '▁de', '▁conscience', '▁a', '▁été', '▁précipité', 'e', '▁par', '▁l', \"'\", 'évolution', '-', 'même', '▁du', '▁monde', ',', '▁par', '▁la', '▁formidable', '▁accélération', '▁du', '▁progrès', '▁technologique', '▁et', '▁des', '▁échanges', '.', 'Pour', '▁aborder', '▁ces', '▁questions', '▁difficiles', ',', '▁nous', '▁devons', '▁concilier', '▁justice', '▁et', '▁réalisme', '.', '▁Justice', ',', '▁car', '▁personne', '▁ne', '▁comprend', 'rait', '▁par', '▁exemple', '▁qu', \"'\", 'une', '▁organisation', '▁internationale', '▁dont', '▁la', '▁double', '▁ambition', '▁est', '▁de', '▁libéral', 'iser', '▁et', '▁d', \"'\", 'en', 'cadre', 'r', '▁les', '▁échanges', '▁de', '▁bien', 's', '▁et', '▁de', '▁services', ',', '▁n', \"'\", 'écoute', '▁et', '▁n', \"'\", 'entend', 'e', '▁que', '▁la', '▁voix', '▁des', '▁plus', '▁forts', '.', '▁Mike', '▁Moore', ',', '▁son', '▁directeur', '▁général', ',', '▁a', '▁vu', '▁dans', '▁le', '▁sommet', '▁Afrique', '-', 'OM', 'C', '▁de', '▁Libre', 'ville', '▁un', '▁\"', '▁symbole', '▁fort', '▁\"', '.', '▁C', \"'\", 'était', '▁en', '▁effet', ',', '▁la', '▁première', '▁conférence', '▁sur', '▁le', '▁commerce', ',', '▁entre', '▁Africains', '▁et', '▁en', '▁Afrique', '▁;', '▁l', \"'\", 'OM', 'C', '▁a', '▁bel', '▁et', '▁bien', '▁aussi', '▁besoin', '▁de', '▁l', \"'\", 'Afrique', '.', '▁Les', '▁pays', '▁africains', '▁doivent', '▁s', \"'\", 'affirmer', '▁rapidement', '▁comme', '▁des', '▁acteurs', '▁incontournables', '▁de', '▁cette', '▁instance', '.', '▁Tout', '▁le', '▁monde', '▁a', '▁bien', '▁compris', '▁désormais', '▁que', '▁le', '▁lancement', ',', '▁puis', '▁le', '▁succès', '▁d', \"'\", 'un', '▁cycle', '▁large', '▁reposent', '▁sur', '▁la', '▁conviction', '▁de', '▁chacun', '▁des', '▁participants', '▁d', \"'\", 'y', '▁avoir', '▁un', '▁véritable', '▁intérêt', '.', 'Mais', '▁le', '▁réalisme', '▁économique', '▁et', '▁commercial', '▁nous', '▁commande', 'nt', '▁de', '▁considérer', '▁la', '▁grande', '▁diversité', '▁des', '▁situations', '▁et', '▁des', '▁rythmes', '▁de', '▁développement', '▁propres', '▁à', '▁chaque', '▁pays', '.', '▁Ne', '▁nous', '▁voi', 'lons', '▁pas', '▁la', '▁face', '▁:', '▁les', '▁écarts', '▁de', '▁richesses', ',', '▁de', '▁productivité', ',', '▁d', \"'\", 'investissement', '▁sont', '▁considérable', 's', '.', '▁Un', '▁pays', '▁comme', '▁la', '▁Malaisie', '▁accueille', '▁autant', '▁d', \"'\", 'IDE', '▁que', '▁l', \"'\", 'ensemble', '▁du', '▁continent', '▁africain', '.', '▁Et', '▁le', '▁risque', '▁existe', '▁que', '▁l', \"'\", 'accélération', '▁technologique', '▁que', '▁j', \"'\", 'év', 'oqu', 'ais', '▁ne', '▁fasse', '▁qu', \"'\", 'accentuer', '▁ces', '▁déséquilibre', 's', '.', '▁Je', '▁vois', '▁là', '▁une', '▁raison', '▁de', '▁plus', '▁pour', '▁refuser', '▁la', '▁loi', '▁de', '▁la', '▁jungle', '▁et', '▁fixer', '▁les', '▁règles', '▁du', '▁jeu', '▁commercial', '.', '▁Nous', '▁en', '▁sommes', '▁tous', '▁conscients', ',', '▁l', \"'\", 'équation', '▁n', \"'\", 'est', '▁pas', '▁simple', '▁à', '▁résoudre', '▁:', '▁comment', '▁ne', '▁pas', '▁décourager', '▁les', '▁plus', '▁dynamiques', ',', '▁sans', '▁désespér', 'er', '▁les', '▁retard', 'a', 'taires', '▁?', '▁Comment', '▁faire', '▁que', '▁chacun', '▁progresse', '▁à', '▁son', '▁rythme', '▁en', '▁att', 'én', 'uant', '▁l', \"'\", 'impact', '▁des', '▁crises', '▁?', '▁Mon', '▁sentiment', '▁est', '▁que', '▁seul', '▁un', '▁cycle', '▁commercial', '▁global', '▁et', '▁élargi', '▁peut', '▁le', '▁permettre', '.', '▁Un', '▁accord', '▁général', '▁suppose', '▁des', '▁concessions', '▁réciproque', 's', ',', '▁d', \"'\", 'autant', '▁moins', '▁difficiles', '▁à', '▁obtenir', '▁que', '▁les', '▁thématiques', '▁sont', '▁larges', ',', '▁alors', '▁que', '▁des', '▁négociations', '▁partielle', 's', '▁ou', '▁sectorielle', 's', ',', '▁menées', '▁à', '▁la', '▁hâte', '▁pour', '▁des', '▁résultats', '▁à', '▁court', '▁terme', ',', '▁entraîne', 'nt', '▁forcément', '▁cris', 'p', 'ations', '▁et', '▁blocage', 's', '.', '▁Les', '▁récolte', 's', '▁trop', '▁précoce', 's', '▁donnent', '▁parfois', '▁des', '▁fruits', '▁verts', ',', '▁au', '▁goût', '▁a', 'mer', '.', 'C', \"'\", 'est', '▁le', '▁sens', '▁du', '▁travail', '▁d', \"'\", 'explication', '▁que', '▁nous', '▁me', 'nons', '▁avec', '▁Mike', '▁Moore', ',', '▁avec', '▁l', \"'\", 'Union', '▁européenne', '▁et', '▁de', '▁nombreux', '▁pays', '▁en', '▁développement', '▁afin', '▁qu', \"'\", 'un', '▁cycle', '▁redémarre', '▁sur', '▁des', '▁bases', '▁élargie', 's', ',', '▁solides', '▁et', '▁qui', '▁', 'inspirent', '▁confiance', '.', 'Au', '-', 'delà', '▁des', '▁règles', '▁commerciales', '▁Mais', '▁les', '▁règles', '▁commerciales', '▁ne', '▁suffisent', '▁pas', '▁:', '▁elles', '▁organisent', '▁un', '▁cadre', '▁et', '▁offrent', '▁des', '▁opportunités', '▁qui', '▁ne', '▁pourront', '▁être', '▁réalisées', '▁que', '▁si', '▁les', '▁économies', '▁en', '▁ont', '▁la', '▁capacité', '.', '▁Mais', '▁le', '▁commerce', '▁ne', '▁suffit', '▁pas', '.', '▁L', \"'\", 'aide', ',', '▁qui', '▁passe', '▁par', '▁des', '▁transferts', '▁d', \"'\", 'épargne', ',', '▁se', '▁doit', '▁d', \"'\", 'apporter', '▁un', '▁filet', '▁de', '▁sécurité', ',', '▁mais', '▁aussi', '▁l', \"'\", 'encouragement', '▁nécessaire', ',', '▁par', '▁la', '▁réalisation', '▁de', '▁projets', '▁exemplaires', ',', '▁car', '▁réussi', 's', '▁et', '▁pérenne', 's', '.', '▁Cette', '▁aide', '▁ne', '▁peut', '▁pas', '▁être', '▁seulement', '▁financière', ',', '▁elle', '▁suppose', '▁des', '▁logique', 's', '▁de', '▁partenariat', ',', '▁des', '▁transferts', '▁de', '▁savoir', '-', 'faire', '▁et', '▁de', '▁technologie', ',', '▁bref', ',', '▁tout', '▁ce', '▁qui', '▁peut', '▁contribuer', '▁à', '▁créer', '▁plus', '▁de', '▁valeur', '▁ajoutée', '▁dans', '▁les', '▁pays', '▁en', '▁développement', '.', 'Je', '▁veux', '▁toutefois', '▁souligner', '▁que', '▁l', \"'\", 'aide', '▁bilatérale', '▁française', '▁qui', '▁est', '▁orientée', '▁directement', '▁vers', '▁le', '▁renforcement', '▁des', '▁capacités', '▁commerciales', '▁des', '▁pays', '▁africains', '▁est', '▁tout', '▁à', '▁fait', '▁substantielle', '.', '▁Sur', '▁la', '▁période', '▁1995', '▁-', '▁2000,', '▁le', '▁volume', '▁global', '▁d', \"'\", 'engagement', '▁de', '▁l', \"'\", 'aide', '▁française', '▁sur', '▁des', '▁projets', '▁contribuant', '▁au', '▁renforcement', '▁des', '▁capacités', '▁export', 'atrices', '▁s', \"'\", 'élève', '▁à', '▁près', '▁de', '▁', '5,6', '▁Milli', 'ards', '▁de', '▁francs', ',', '▁hors', '▁prêts', '▁d', \"'\", 'ajustement', '▁structure', 'l', '.', '▁Environ', '▁60', '▁%', '▁de', '▁cette', '▁aide', '▁est', '▁directement', '▁affectée', '▁à', '▁des', '▁projets', '▁de', '▁développement', '▁de', '▁la', '▁production', '▁export', 'ée', '.', '▁35', '▁%', '▁de', '▁cette', '▁aide', '▁porte', '▁sur', '▁des', '▁projets', '▁d', \"'\", 'infrastructure', 's', '▁directement', '▁liés', '▁à', '▁l', \"'\", 'amélioration', '▁du', '▁commerce', '▁extérieur', '▁africain', ',', '▁tels', '▁que', '▁les', '▁réseaux', '▁routier', 's', ',', '▁dont', '▁vous', '▁savez', '▁que', '▁la', '▁modernisation', '▁est', '▁cruciale', '▁pour', '▁une', '▁majorité', '▁de', '▁pays', '▁africains', ',', '▁les', '▁infrastructures', '▁portuaire', 's', '▁et', '▁aéroport', 'uaire', 's', '.', '▁Enfin', ',', '▁le', '▁solde', '▁de', '▁cette', '▁coopération', '▁porte', '▁sur', '▁des', '▁actions', '▁de', '▁modernisation', ',', '▁administrative', ',', '▁juridique', ',', '▁', 'institutionnelle', ',', '▁par', '▁exemple', '▁en', '▁matière', '▁douanière', ',', '▁en', '▁matière', '▁de', '▁propriété', '▁intellectuelle', '▁ou', '▁de', '▁droit', '▁des', '▁affaires', ',', '▁qui', '▁sont', '▁des', '▁facteurs', '▁déterminant', 's', '▁pour', '▁l', \"'\", 'insertion', '▁de', '▁l', \"'\", 'Afrique', '▁dans', '▁les', '▁échanges', '▁mondiaux', '.', '▁Un', '▁système', '▁juridique', '▁efficace', '▁représente', '▁certes', '▁un', '▁coût', '▁pour', '▁les', '▁pays', '▁pauvres', ',', '▁mais', '▁constitue', '▁aussi', '▁un', '▁avantage', '▁comparatif', '▁dans', '▁la', '▁compétition', '▁mondiale', '.', 'A', '▁ces', '▁actions', '▁de', '▁coopération', '▁en', '▁partenariat', ',', '▁s', \"'\", 'ajoutent', '▁les', '▁initiatives', '▁commerciales', '▁visant', '▁à', '▁renforcer', '▁la', '▁capacité', '▁export', 'atrice', '▁des', '▁pays', '▁en', '▁développement', '▁les', '▁moins', '▁avancés', '▁ou', ',', '▁plus', '▁largement', ',', '▁des', '▁pays', '▁de', '▁la', '▁zone', '▁Afrique', '▁Caraïbes', '▁Pacifique', '.', 'S', \"'\", 'agissant', '▁des', '▁pays', '▁les', '▁moins', '▁avancés', ',', '▁nous', '▁travaillons', '▁activement', '▁au', '▁sein', '▁de', '▁l', \"'\", 'Union', '▁afin', '▁d', \"'\", 'offrir', '▁une', '▁entrée', '▁sans', '▁droits', '▁de', '▁douane', 's', '▁de', '▁tous', '▁leurs', '▁produits', '▁:', '▁c', \"'\", 'est', '▁un', '▁projet', '▁important', '▁auquel', '▁nous', '▁tenons', ',', '▁même', '▁s', \"'\", 'il', '▁n', \"'\", 'a', '▁pas', '▁encore', '▁abouti', '.', 'Enfin', ',', '▁comment', '▁ne', '▁pas', '▁signaler', '▁également', '▁les', '▁efforts', '▁de', '▁long', '▁terme', '▁consenti', 's', '▁dans', '▁le', '▁cadre', '▁des', '▁diverses', '▁conventions', '▁dites', '▁de', '▁Lomé', ',', '▁qui', '▁se', '▁sont', '▁concrétisé', 'es', '▁une', '▁fois', '▁de', '▁plus', '▁à', '▁Coton', 'ou', '▁début', '▁2000', '▁afin', '▁d', \"'\", 'offrir', '▁un', '▁cadre', '▁', 'particulièrement', '▁privilégié', '▁d', \"'\", 'accès', '▁au', '▁marché', '▁européen', '▁pour', '▁les', '▁produits', '▁des', '▁Etats', '▁A', 'CP', '.', 'Tout', '▁cela', '▁doit', '▁permettre', '▁aux', '▁investisseurs', '▁étrangers', '▁et', '▁locaux', '▁de', '▁créer', '▁de', '▁la', '▁valeur', '▁ajoutée', '.', '▁Pour', '▁ce', '▁faire', ',', '▁la', '▁confiance', ',', '▁la', '▁transparence', ',', '▁la', '▁sécurité', '▁des', '▁personnes', '▁et', '▁des', '▁bien', 's', ',', '▁constituent', '▁des', '▁paramètres', '▁critiques', '.', '▁C', \"'\", 'est', '▁un', '▁domaine', '▁où', '▁l', \"'\", 'exemple', '▁vient', '▁de', '▁haut', ',', '▁où', '▁il', '▁faut', '▁beaucoup', '▁de', '▁temps', '▁pour', '▁construire', '▁et', '▁si', '▁peu', '▁pour', '▁décourager', '▁les', '▁bonnes', '▁volonté', 's', '.', '▁La', '▁communauté', '▁internationale', ',', '▁et', '▁l', \"'\", 'Union', '▁européenne', '▁en', '▁particulier', ',', '▁travaillent', '▁sans', '▁relâche', '▁à', '▁créer', '▁un', '▁environnement', '▁stable', '.', '▁Les', '▁mesures', '▁prises', '▁à', '▁l', \"'\", 'OCDE', '▁ou', '▁dans', '▁d', \"'\", 'autres', '▁instances', '▁en', '▁vue', '▁d', \"'\", 'atteindre', '▁une', '▁plus', '▁grande', '▁transparence', '▁financière', '▁des', '▁échanges', '▁internationaux', '▁vont', '▁dans', '▁ce', '▁sens', ',', '▁de', '▁même', '▁que', '▁l', \"'\", 'ajustement', '▁structure', 'l', ',', '▁tout', '▁', 'particulièrement', '▁lorsqu', \"'\", 'il', '▁accompagne', '▁des', '▁mesures', '▁d', \"'\", 'annulation', 's', '▁de', '▁créance', 's', '▁des', '▁pays', '▁pauvres', '▁les', '▁plus', '▁end', 'et', 'tés', '.', '▁Mais', '▁le', '▁dernier', '▁mot', '▁appartient', '▁forcément', '▁aux', '▁intéressés', '▁eux', '-', 'mêmes', '.', '▁Dans', '▁de', '▁nombreux', '▁pays', '▁africains', '▁ou', '▁méditerranéen', 's', ',', '▁l', \"'\", 'environnement', '▁de', '▁l', \"'\", 'activité', '▁économique', '▁peut', '▁encore', '▁être', '▁largement', '▁amélioré', '.', 'Quel', '▁est', '▁alors', '▁le', '▁rôle', '▁des', '▁entreprises', '▁dans', '▁cet', '▁ensemble', '▁?', 'Un', '▁rôle', '▁essentiel', ',', '▁à', '▁l', \"'\", 'évidence', '.', '▁Les', '▁entreprises', '▁s', \"'\", 'adaptent', '▁à', '▁l', \"'\", 'intégration', '▁économique', '▁mondiale', '.', '▁Elles', '▁sont', '▁donc', '▁les', '▁premières', '▁bénéficiaires', '▁de', '▁la', '▁multi', 'latéral', 'isation', '▁des', '▁règles', '▁du', '▁jeu', '▁des', '▁échanges', ',', '▁que', '▁le', '▁cadre', '▁soit', '▁planétaire', '▁ou', '▁régional', '.', 'Nous', '▁attendons', ',', '▁en', '▁tant', '▁que', '▁pouvoirs', '▁publics', ',', '▁que', '▁grandes', '▁ou', '▁petites', ',', '▁elles', '▁nous', '▁fassent', '▁part', ',', '▁de', '▁façon', '▁structurée', '▁et', '▁précise', ',', '▁de', '▁leurs', '▁préoccupations', ',', '▁ou', '▁de', '▁leurs', '▁espoirs', ',', '▁vis', '▁à', '▁vis', '▁des', '▁projets', '▁de', '▁règles', '▁du', '▁jeu', '▁que', '▁nous', '▁é', 'labor', 'ons', '▁avec', '▁nos', '▁collègues', '▁européens', '.', '▁Nous', '▁souhaitons', '▁bien', '▁sûr', '▁qu', \"'\", 'elles', '▁intègre', 'nt', '▁les', '▁logique', 's', '▁de', '▁partenariat', '▁évoquée', 's', '▁plus', '▁haut', ',', '▁non', '▁seulement', '▁vis', '-', 'à', '-', 'vis', '▁des', '▁entreprises', '▁des', '▁pays', '▁en', '▁développement', ',', '▁mais', '▁également', '▁en', '▁direction', '▁de', '▁leurs', '▁homologue', 's', '▁européennes', '.', 'Les', '▁financements', '▁d', \"'\", 'aide', '▁au', '▁développement', ',', '▁qu', \"'\", 'il', '▁s', \"'\", 'agisse', '▁de', '▁ceux', '▁de', '▁l', \"'\", 'Agence', '▁française', '▁de', '▁développement', ',', '▁dans', '▁la', '▁zone', '▁de', '▁solidarité', '▁prioritaire', '▁ou', '▁de', '▁ceux', '▁de', '▁la', '▁Direction', '▁des', '▁relations', '▁économiques', '▁extérieures', ',', '▁avec', '▁la', '▁réserve', '▁pays', '▁émergent', 's', ',', '▁constituent', '▁un', '▁moyen', '▁classique', '▁et', '▁sûr', '▁de', '▁réaliser', '▁des', '▁projets', '.', '▁Comme', '▁vous', '▁le', '▁savez', ',', '▁la', '▁C', 'OF', 'ACE', '▁intervient', '▁également', '▁en', '▁Afrique', '▁lorsque', '▁la', '▁rentabilité', '▁d', \"'\", 'un', '▁projet', '▁permet', '▁d', \"'\", 'y', '▁a', 'dosser', '▁un', '▁schéma', '▁de', '▁garantie', '▁solide', '.', 'D', \"'\", 'autres', '▁procédures', ',', '▁comme', '▁cela', '▁vous', '▁a', '▁été', '▁exposé', '▁ce', '▁matin', ',', '▁permettent', '▁d', \"'\", 'accompagner', '▁vos', '▁stratégies', '▁d', \"'\", 'investissement', 'Quel', 'ques', '▁exemples', '▁pour', '▁illustrer', '▁notre', '▁action', '.', '▁La', '▁C', 'OF', 'ACE', '▁couvre', '▁des', '▁opérations', '▁de', '▁court', '▁terme', '▁et', '▁de', '▁long', '▁terme', ',', '▁comme', '▁l', \"'\", 'usine', '▁d', \"'\", 'aluminium', '▁de', '▁Mo', 'z', 'al', '▁au', '▁Mo', 'z', 'amb', 'ique', ',', '▁et', '▁s', \"'\", 'est', '▁installée', ',', '▁avec', '▁l', \"'\", 'aide', '▁de', '▁Pro', 'par', 'co', ',', '▁en', '▁Côte', '▁d', \"'\", 'Ivoire', '▁afin', '▁de', '▁couvrir', '▁les', '▁opérations', '▁de', '▁commerce', '▁régional', '.', '▁Le', '▁CF', 'CE', '▁a', '▁développé', '▁un', '▁certain', '▁nombre', '▁de', '▁coopération', 's', '▁sur', '▁le', '▁continent', '.', '▁Au', '▁plan', '▁multi', 'latéral', ',', '▁nous', '▁', 'uv', 'rons', '▁pour', '▁que', '▁les', '▁pays', '▁africains', '▁améliorent', '▁leur', '▁expertise', '▁vis', '▁à', '▁vis', '▁de', '▁l', \"'\", 'OM', 'C', '▁et', '▁disposent', '▁des', '▁moyens', '▁financiers', '▁pour', '▁participer', '▁effectivement', '▁aux', '▁discussions', '.', 'En', '▁liaison', '▁avec', '▁le', '▁Ministère', '▁des', '▁affaires', '▁étrangères', ',', '▁nous', '▁avons', '▁mis', '▁au', '▁point', '▁un', '▁partenariat', '▁avec', '▁le', '▁CF', 'CE', '▁pour', '▁développer', '▁le', '▁site', '▁Internet', '▁\"', '▁Investi', 'r', '▁en', '▁Zone', '▁Franc', '▁\"', ',', '▁destiné', '▁à', '▁donner', '▁en', '▁ligne', '▁toutes', '▁les', '▁premières', '▁informations', '▁utiles', '.', '▁Une', '▁autre', '▁priorité', '▁de', '▁notre', '▁politique', '▁est', '▁de', '▁favoriser', '▁le', '▁développement', '▁de', '▁l', \"'\", 'intégration', '▁régionale', '▁en', '▁Afrique', '.', '▁Et', '▁je', '▁suis', '▁persuadé', '▁que', '▁les', '▁entreprises', '▁sont', '▁les', '▁premières', '▁intéressées', '▁par', '▁cette', '▁évolution', '.', '▁L', \"'\", 'absence', '▁de', '▁marché', '▁régional', '▁constitue', '▁certainement', '▁un', '▁frein', '▁à', '▁l', \"'\", 'accueil', '▁d', \"'\", 'investissement', 's', '▁directs', '.', '▁Les', '▁accords', '▁de', '▁partenariats', '▁économiques', '▁régionaux', '▁(', 'A', 'PER', ')', '▁prévus', '▁par', '▁la', '▁convention', '▁de', '▁Coton', 'ou', '▁sont', '▁à', '▁mes', '▁yeux', '▁un', '▁vecteur', '▁puissant', '▁de', '▁cette', '▁dynamique', '▁qui', '▁conduit', '▁à', '▁un', '▁marché', '▁commun', '▁en', '▁Afrique', '▁de', '▁l', \"'\", 'ouest', '▁et', '▁en', '▁Afrique', '▁centrale', '.', '▁Déjà', '▁le', '▁traité', '▁', 'OH', 'ADA', '▁permet', '▁l', \"'\", 'un', 'ification', '▁progressive', '▁du', '▁droit', '▁des', '▁affaires', '.', 'Au', 'tant', '▁d', \"'\", 'initiative', 's', '▁qui', '▁préparent', '▁l', \"'\", 'avenir', '▁et', '▁doivent', '▁être', '▁poursuivie', 's', '▁et', '▁amplifié', 'es', '▁avec', '▁détermination', '.', '▁Mais', '▁tout', '▁cela', '▁n', \"'\", 'est', '▁rien', '▁sans', '▁le', '▁relais', '▁des', '▁entreprises', ',', '▁sans', '▁leur', '▁volonté', '▁de', '▁créer', '▁de', '▁la', '▁richesse', '▁et', '▁de', '▁l', \"'\", 'activité', '.', '▁C', \"'\", 'est', '▁à', '▁vous', ',', '▁chefs', '▁d', \"'\", 'entreprises', ',', '▁de', '▁tirer', '▁le', '▁meilleur', '▁parti', '▁possible', '▁de', '▁ces', '▁instruments', '▁à', '▁votre', '▁disposition', '.', 'Con', 'clusion', '▁Permet', 'tez', '-', 'moi', ',', '▁pour', '▁conclure', ',', '▁de', '▁revenir', '▁à', '▁l', \"'\", 'Afrique', '.', '▁Je', '▁me', '▁suis', '▁rendu', '▁à', '▁plusieurs', '▁reprises', '▁sur', '▁ce', '▁continent', ',', '▁plus', ',', '▁je', '▁crois', ',', '▁qu', \"'\", 'aucun', '▁de', '▁mes', '▁prédécesseur', 's', '▁au', '▁commerce', '▁extérieur', '.', '▁Encore', '▁récemment', ',', '▁nous', '▁étions', ',', '▁avec', '▁Charles', '▁J', 'osse', 'lin', ',', '▁à', '▁Libre', 'ville', ',', '▁afin', '▁d', \"'\", 'apporter', '▁notre', '▁soutien', '▁à', '▁nos', '▁collègues', '▁ministres', '▁du', '▁commerce', '▁de', '▁l', \"'\", 'ensemble', '▁du', '▁continent', '.', '▁Certes', ',', '▁la', '▁place', '▁de', '▁l', \"'\", 'Afrique', '▁dans', '▁les', '▁échanges', '▁mondiaux', '▁ou', '▁les', '▁investissements', '▁directs', '▁étrangers', '▁est', '▁faible', '▁et', '▁certainement', '▁pas', '▁proportionnelle', '▁à', '▁sa', '▁démographie', '.', '▁Nous', '▁savons', '▁tous', '▁les', '▁efforts', '▁que', '▁nos', '▁amis', '▁africains', '▁se', '▁doivent', '▁d', \"'\", 'accomplir', '▁dans', '▁de', '▁nombreux', '▁domaines', '▁pour', '▁modifier', '▁l', \"'\", 'image', '▁et', '▁les', '▁réalités', '▁de', '▁ce', '▁continent', '.', 'L', \"'\", 'Europe', ',', '▁et', '▁tout', '▁', 'particulièrement', '▁la', '▁France', ',', '▁ont', '▁largement', '▁fait', '▁la', '▁preuve', '▁de', '▁leur', '▁fidélité', '▁à', '▁l', \"'\", 'Afrique', '.', '▁Je', '▁suis', '▁allé', '▁à', '▁Abidjan', '▁l', \"'\", 'année', '▁dernière', '▁pour', '▁inaugure', 'r', '▁l', \"'\", 'exposition', '▁France', '▁Technologies', '▁:', '▁première', '▁manifestation', '▁d', \"'\", 'une', '▁telle', '▁ampleur', '▁en', '▁Afrique', '▁de', '▁l', \"'\", 'ouest', '.', '▁300', '▁entreprises', '▁françaises', '▁y', '▁étaient', '▁représentée', 's', '▁:', '▁quelques', '▁grands', '▁groupes', '▁déjà', '▁bien', '▁implanté', 's', '▁dans', '▁la', '▁région', ',', '▁mais', '▁aussi', '▁un', '▁grand', '▁nombre', '▁de', '▁PME', '-', 'P', 'MI', '▁représentant', '▁des', '▁secteurs', '▁d', \"'\", 'activité', '▁très', '▁variés', '.', '▁J', \"'\", 'avais', '▁puis', 'é', '▁dans', '▁cette', '▁manifestation', '▁une', '▁force', '▁d', \"'\", 'optimisme', '▁sur', '▁les', '▁grandes', '▁perspectives', '▁de', '▁développement', '▁durable', '▁et', '▁diversifié', '▁de', '▁la', '▁Côte', '▁d', \"'\", 'Ivoire', '▁et', '▁de', '▁l', \"'\", 'Afrique', '▁de', '▁l', \"'\", 'ouest', '▁toute', '▁entière', '.', '▁Je', '▁suis', '▁bien', '▁sûr', '▁très', '▁pein', 'é', '▁des', '▁événements', '▁les', '▁plus', '▁récents', '▁à', '▁Abidjan', '▁qui', '▁ont', '▁conduit', '▁à', '▁l', \"'\", 'état', '▁d', \"'\", 'urgence', '.', '▁Mais', '▁la', '▁période', '▁pénible', '▁qu', \"'\", 'a', '▁connu', '▁la', '▁Côte', '▁d', \"'\", 'Ivoire', '▁n', \"'\", 'a', '▁pas', '▁découragé', '▁les', '▁entreprises', '.', '▁Elles', '▁sont', '▁restée', 's', ',', '▁contre', '▁vents', '▁et', '▁marée', 's', ',', '▁dans', '▁des', '▁conditions', '▁de', '▁travail', '▁parfois', '▁très', '▁difficiles', '▁et', '▁non', '▁sans', '▁conséquences', '▁financières', ',', '▁qu', \"'\", 'il', '▁faudra', '▁d', \"'\", 'ailleurs', '▁résoudre', '.', '▁Je', '▁tiens', '▁à', '▁les', '▁en', '▁remercier', '.', '▁Et', '▁je', '▁souhaite', '▁', 'ard', 'emment', '▁que', '▁la', '▁Côte', '▁d', \"'\", 'Ivoire', '▁retrouve', '▁au', '▁plus', '▁vite', '▁la', '▁paix', '▁civile', '▁et', '▁le', '▁rôle', '▁de', '▁locomotive', '▁économique', '▁de', '▁l', \"'\", 'Afrique', '▁de', '▁l', \"'\", 'ouest', '▁qui', '▁doit', '▁être', '▁le', '▁sien', '.', 'Mon', '▁collègue', '▁Guy', '-', 'Alain', '▁Gau', 'ze', ',', '▁ici', '▁présent', ',', '▁ne', '▁me', '▁contre', 'dir', 'a', '▁pas', '▁si', '▁je', '▁vous', '▁dis', '▁qu', \"'\", 'il', '▁faut', '▁persévérer', '.', '▁La', '▁persévérance', ',', '▁la', '▁patience', '▁et', ',', '▁disons', '-', 'le', ',', '▁un', '▁peu', '▁de', '▁passion', ',', '▁sont', '▁des', '▁vertus', '▁cardinal', 'es', '▁pour', '▁réussir', '▁durablement', '.', '▁En', '▁Afrique', '▁peut', '-', 'être', '▁plus', '▁qu', \"'\", 'ailleurs', '.', '▁Je', '▁vous', '▁remercie', '.', '▁(', 'source', '▁-', 'ex', 'terie', 'ur', '.', 'gouv', '.', 'fr', ',', '▁le', '▁11', '▁décembre', '▁2000']\n",
            "Token IDs:  [23605, 14, 19923, 19, 12680, 7, 23605, 14, 19923, 19, 21, 30157, 10, 14, 21, 9645, 10, 7, 23605, 7, 19923, 7, 1684, 4318, 66, 18, 11, 803, 5559, 22642, 2662, 121, 7344, 1660, 7, 129, 8714, 2671, 8, 13, 3599, 14, 8, 13, 26638, 7, 163, 46, 11, 2843, 9090, 748, 9249, 90, 5812, 7, 8092, 25, 1418, 430, 25, 1599, 3069, 7, 31, 17028, 44, 9280, 4347, 15, 17, 11, 2582, 9, 1104, 320, 31, 504, 747, 36, 1302, 127, 2455, 42, 16, 5822, 10088, 56, 18, 11, 617, 2559, 44, 823, 9, 4425, 49, 11, 41, 72, 705, 34, 23, 2829, 86, 19, 1602, 25, 1599, 14, 25, 499, 14265, 405, 11, 265, 19, 699, 9, 8696, 8211, 11225, 56, 22, 340, 15, 17, 11, 7681, 176, 193, 125, 9, 1646, 14971, 15, 13, 425, 6001, 20, 6262, 18, 11, 761, 224, 16, 499, 2028, 7, 47, 15, 17, 11, 12311, 8, 13, 5270, 20, 256, 19, 40, 4759, 14, 19, 40, 7665, 231, 5034, 9, 515, 2495, 8, 13055, 7, 91, 19, 1281, 200, 29, 13, 8961, 4112, 9, 28880, 711, 101, 28, 2131, 16684, 43, 19, 256, 22, 499, 96, 2290, 13, 903, 24, 48, 85, 3002, 29, 16, 2191, 2133, 19856, 9, 436, 96, 66, 691, 29295, 97, 4496, 18, 11, 70, 13325, 174, 220, 45, 2936, 34, 20, 1602, 8, 658, 347, 9, 370, 11, 2582, 4322, 10, 55, 5525, 1972, 33, 394, 8, 17, 11, 4706, 228, 24, 2135, 8, 7699, 8, 499, 4805, 68, 13087, 8, 17, 11, 1803, 4141, 7, 51, 49, 11, 41, 40, 384, 8, 15214, 944, 19, 756, 3496, 36, 1599, 7, 36, 499, 7, 15, 17, 11, 1623, 47, 68, 2952, 7, 46, 11, 734, 1053, 8498, 47, 2201, 9, 683, 8705, 8, 789, 23, 1681, 5394, 18, 11, 1629, 68, 2393, 10, 20, 214, 9, 683, 8705, 99, 23, 7707, 8, 17, 11, 7238, 899, 24, 85, 461, 15, 20, 8945, 355, 95, 5577, 9, 6482, 7, 36, 10965, 20, 756, 1054, 7, 45, 2639, 273, 283, 8, 477, 44, 31, 3422, 302, 9, 107, 2971, 4322, 10, 55, 5525, 1972, 7, 478, 8, 13, 1993, 8, 13, 1133, 1682, 29, 16, 570, 3420, 857, 9, 139, 37, 570, 3420, 857, 7, 50, 920, 248, 691, 747, 42, 175, 8, 23, 15835, 37, 209, 211, 19, 3042, 256, 19, 175, 19659, 7, 23, 2235, 446, 20, 329, 11767, 1661, 28, 2391, 9, 2184, 13, 595, 2725, 9, 69, 49, 11, 41, 3125, 34, 1000, 27, 19, 541, 17492, 3522, 29, 16, 212, 437, 9, 545, 13, 14841, 23688, 7, 91, 33, 18352, 128, 1832, 14, 1554, 713, 8, 87, 704, 87, 4759, 22, 2971, 4322, 26, 10, 55, 5525, 1972, 9, 180, 238, 1367, 11356, 13600, 68, 605, 43, 60, 11, 41, 386, 8, 13, 218, 20, 275, 3654, 29, 16, 1599, 2316, 9, 515, 3042, 256, 19, 40, 4759, 7, 3580, 10026, 7, 4222, 405, 11, 265, 23, 1644, 24, 2947, 25, 1458, 20, 17818, 9, 54, 499, 17941, 20, 3299, 67, 597, 476, 453, 32, 19, 419, 1154, 250, 8, 17, 11, 364, 2477, 67, 30, 17, 11, 5247, 16, 40, 10120, 8, 13, 13325, 9, 69, 279, 145, 1880, 20, 7699, 8, 499, 15, 117, 19, 256, 7, 14, 22, 770, 68, 275, 3654, 9, 1119, 590, 50, 146, 6240, 46, 11, 3462, 11, 265, 7, 17, 11, 2582, 33, 394, 8, 17, 11, 4706, 228, 9, 139, 50, 39, 15091, 29, 23, 3334, 590, 17, 11, 4706, 228, 33, 394, 8, 17, 11, 2582, 9, 14691, 8, 1582, 1636, 43, 21560, 1746, 14, 15370, 224, 23, 281, 3178, 8, 17, 11, 4706, 228, 1635, 7, 103, 20577, 26, 315, 7, 78, 722, 8, 1582, 7, 280, 2534, 9497, 8, 13, 292, 20, 256, 26056, 5575, 24, 23, 164, 22, 499, 31, 1715, 28, 292, 6891, 25, 1599, 2316, 106, 100, 39, 28684, 27, 78, 722, 8, 1582, 45, 749, 34, 18, 11, 6357, 9, 159, 51, 30, 600, 65, 27, 77, 8641, 11592, 5230, 542, 8, 4136, 5646, 79, 16, 1599, 47, 13, 5270, 52, 11, 6521, 37, 13, 1511, 20, 256, 22, 499, 8, 85, 3002, 97, 903, 9, 232, 722, 8, 1582, 33, 101, 23307, 35, 37, 17, 11, 2010, 26, 512, 25, 164, 7, 37, 13, 5823, 22516, 25, 4067, 7417, 14, 20, 3299, 9, 5064, 9513, 119, 756, 4610, 7, 63, 4092, 21560, 1746, 14, 15370, 9, 8371, 7, 173, 314, 45, 1498, 1176, 37, 411, 46, 11, 70, 2413, 1578, 174, 13, 1080, 9546, 30, 8, 12717, 1864, 14, 18, 11, 90, 8412, 81, 19, 3299, 8, 72, 10, 14, 8, 440, 7, 49, 11, 2921, 14, 49, 11, 4296, 35, 27, 13, 903, 20, 40, 5646, 9, 14315, 24596, 7, 58, 1478, 606, 7, 33, 380, 29, 16, 3497, 2971, 26, 4706, 228, 8, 7150, 998, 23, 87, 5375, 735, 87, 9, 84, 11, 230, 22, 340, 7, 13, 272, 2343, 32, 16, 1599, 7, 128, 25513, 14, 22, 2971, 167, 17, 11, 4706, 228, 33, 2346, 14, 72, 99, 394, 8, 17, 11, 2582, 9, 74, 256, 10026, 750, 52, 11, 14366, 736, 79, 20, 1602, 14002, 8, 78, 10991, 9, 543, 16, 164, 33, 72, 827, 1085, 27, 16, 3864, 7, 264, 16, 1081, 18, 11, 59, 3178, 1071, 22944, 32, 13, 11134, 8, 789, 20, 2521, 18, 11, 105, 190, 23, 1095, 2534, 9, 6482, 16, 15370, 919, 14, 2589, 63, 1063, 113, 8, 5231, 13, 293, 3616, 20, 3107, 14, 20, 17823, 8, 499, 1570, 15, 251, 256, 9, 821, 63, 13803, 8151, 34, 13, 461, 43, 19, 21739, 8, 11226, 7, 8, 11040, 7, 18, 11, 3407, 56, 6063, 10, 9, 153, 256, 79, 13, 22336, 3707, 663, 18, 11, 10334, 27, 17, 11, 649, 25, 5822, 10088, 9, 139, 16, 812, 947, 27, 17, 11, 22217, 7417, 27, 76, 11, 5632, 17565, 480, 45, 3434, 46, 11, 25783, 119, 17630, 10, 9, 100, 1460, 241, 28, 539, 8, 40, 24, 6541, 13, 589, 8, 13, 13879, 14, 6132, 19, 1457, 25, 357, 2589, 9, 170, 22, 464, 117, 19531, 7, 17, 11, 12094, 49, 11, 41, 34, 445, 15, 4325, 43, 404, 45, 34, 27205, 19, 40, 11881, 7, 112, 28210, 108, 19, 2599, 55, 11518, 106, 841, 85, 27, 789, 15259, 15, 58, 2112, 22, 9270, 4853, 12132, 17, 11, 4266, 20, 10788, 106, 772, 2555, 30, 27, 428, 23, 3178, 2589, 5253, 14, 17380, 104, 16, 1027, 9, 153, 1909, 606, 6531, 20, 20812, 15171, 10, 7, 18, 11, 2118, 175, 4610, 15, 1207, 27, 19, 7381, 56, 9714, 7, 183, 27, 20, 6746, 9032, 10, 47, 31162, 10, 7, 9923, 15, 13, 6318, 24, 20, 820, 15, 1429, 788, 7, 6431, 113, 1963, 8443, 286, 2770, 14, 10680, 10, 9, 74, 7366, 10, 237, 11057, 10, 3214, 610, 20, 1778, 6708, 7, 36, 1435, 33, 1496, 9, 228, 11, 41, 16, 437, 25, 225, 18, 11, 11942, 27, 63, 103, 10730, 42, 14315, 24596, 7, 42, 17, 11, 1906, 1467, 14, 8, 490, 256, 22, 499, 289, 46, 11, 59, 3178, 24195, 32, 20, 4258, 24978, 10, 7, 9398, 14, 31, 21, 25728, 1074, 9, 3920, 26, 1942, 20, 1457, 6119, 159, 19, 1457, 6119, 45, 17500, 34, 43, 582, 17028, 23, 473, 14, 4405, 20, 9261, 31, 45, 2276, 98, 5786, 27, 86, 19, 5463, 22, 96, 13, 1381, 9, 159, 16, 1599, 45, 1373, 34, 9, 71, 11, 761, 7, 31, 507, 37, 20, 14753, 18, 11, 11164, 7, 48, 279, 18, 11, 6569, 23, 8123, 8, 548, 7, 65, 99, 17, 11, 25132, 885, 7, 37, 13, 1609, 8, 878, 8106, 7, 173, 1522, 10, 14, 24457, 10, 9, 232, 1338, 45, 104, 34, 98, 446, 2903, 7, 109, 6531, 20, 2393, 10, 8, 2455, 7, 20, 14753, 8, 319, 26, 2821, 14, 8, 1873, 7, 2469, 7, 66, 44, 31, 104, 4960, 15, 739, 40, 8, 810, 8160, 29, 19, 256, 22, 499, 9, 1684, 920, 2185, 8415, 27, 17, 11, 761, 27820, 781, 31, 30, 15341, 902, 224, 16, 7707, 20, 3339, 6119, 20, 256, 10026, 30, 66, 15, 82, 26394, 9, 545, 13, 782, 9030, 67, 9474, 16, 2441, 5253, 18, 11, 4687, 8, 17, 11, 761, 781, 32, 20, 878, 25329, 36, 7707, 20, 3339, 13056, 11789, 52, 11, 4449, 15, 478, 8, 21, 28624, 21596, 7609, 8, 7137, 7, 1152, 4248, 18, 11, 23966, 1579, 219, 9, 15332, 1257, 453, 8, 78, 1338, 30, 902, 17155, 15, 20, 878, 8, 499, 8, 13, 844, 13056, 422, 9, 1740, 453, 8, 78, 1338, 438, 32, 20, 878, 18, 11, 13471, 10, 902, 2313, 15, 17, 11, 4589, 25, 1599, 3069, 10088, 7, 1371, 27, 19, 1517, 9404, 10, 7, 174, 39, 2591, 27, 13, 15388, 30, 20690, 24, 28, 1651, 8, 256, 10026, 7, 19, 8308, 23541, 10, 14, 14248, 13895, 10, 9, 1078, 7, 16, 10855, 8, 78, 3599, 438, 32, 20, 1391, 8, 15388, 7, 6462, 7, 3261, 7, 21, 22152, 7, 37, 411, 22, 763, 28578, 7, 22, 763, 8, 1772, 4625, 47, 8, 347, 20, 1892, 7, 31, 56, 20, 4117, 9711, 10, 24, 17, 11, 8909, 8, 17, 11, 2582, 29, 19, 3299, 15335, 9, 153, 439, 3261, 1347, 1715, 3146, 23, 1984, 24, 19, 256, 4759, 7, 65, 2176, 99, 23, 4444, 10386, 29, 13, 3030, 1636, 9, 243, 119, 1391, 8, 3599, 22, 2455, 7, 52, 11, 16989, 19, 6918, 6119, 3556, 15, 3427, 13, 1381, 13056, 3059, 20, 256, 22, 499, 19, 175, 19659, 47, 7, 40, 2170, 7, 20, 256, 8, 13, 1121, 2971, 20010, 14400, 9, 229, 11, 12522, 20, 256, 19, 175, 19659, 7, 63, 13807, 11449, 36, 731, 8, 17, 11, 1906, 289, 18, 11, 4553, 28, 2377, 112, 873, 8, 13695, 10, 8, 117, 187, 336, 43, 60, 11, 41, 23, 327, 693, 3379, 63, 21792, 7, 93, 52, 11, 62, 49, 11, 55, 34, 143, 12065, 9, 28148, 7, 404, 45, 34, 7715, 200, 19, 2943, 8, 493, 788, 14699, 10, 29, 16, 473, 20, 1968, 12952, 4491, 8, 28121, 7, 31, 48, 56, 31325, 80, 28, 151, 8, 40, 15, 20151, 308, 479, 2477, 289, 18, 11, 4553, 23, 473, 21, 937, 9299, 18, 11, 1288, 36, 569, 2208, 24, 19, 336, 20, 1490, 114, 7078, 9, 9595, 207, 279, 1027, 68, 7619, 3674, 14, 1694, 8, 739, 8, 13, 810, 8160, 9, 123, 44, 85, 7, 13, 1074, 7, 13, 6809, 7, 13, 548, 20, 242, 14, 20, 72, 10, 7, 4538, 20, 5122, 4528, 9, 84, 11, 41, 23, 813, 147, 17, 11, 3733, 620, 8, 540, 7, 147, 51, 213, 217, 8, 125, 24, 2094, 14, 86, 126, 24, 27205, 19, 1491, 1511, 10, 9, 61, 1312, 1578, 7, 14, 17, 11, 1906, 1467, 22, 770, 7, 5863, 112, 12712, 15, 739, 23, 1898, 5367, 9, 74, 1546, 2270, 15, 17, 11, 22405, 47, 29, 18, 11, 266, 11075, 22, 477, 18, 11, 7877, 28, 40, 293, 6809, 2903, 20, 3299, 4854, 774, 29, 44, 437, 7, 8, 93, 27, 17, 11, 23966, 1579, 219, 7, 66, 21, 937, 961, 11, 62, 5480, 20, 1546, 18, 11, 12311, 10, 8, 16780, 10, 20, 256, 4759, 19, 40, 7665, 231, 5034, 9, 159, 16, 348, 853, 4751, 1963, 68, 9532, 474, 26, 2835, 9, 211, 8, 490, 256, 10026, 47, 18206, 10, 7, 17, 11, 1623, 8, 17, 11, 1303, 919, 104, 143, 98, 2170, 12871, 9, 20643, 30, 183, 16, 842, 20, 699, 29, 280, 760, 106, 3985, 842, 4095, 7, 15, 17, 11, 16874, 9, 74, 699, 52, 11, 25300, 15, 17, 11, 4378, 919, 1636, 9, 1646, 56, 145, 19, 1640, 12560, 8, 13, 2133, 19856, 1385, 20, 1457, 25, 357, 20, 3299, 7, 27, 16, 473, 191, 20159, 47, 4124, 9, 3975, 19379, 7, 22, 376, 27, 4014, 1825, 7, 27, 927, 47, 923, 7, 582, 63, 16671, 292, 7, 8, 429, 23804, 14, 1940, 7, 8, 187, 9445, 7, 47, 8, 187, 16891, 7, 1245, 15, 1245, 20, 878, 8, 1457, 25, 357, 27, 63, 1619, 12157, 273, 42, 166, 4412, 3980, 9, 170, 8616, 72, 705, 46, 11, 734, 6935, 113, 19, 2393, 10, 8, 2455, 20534, 10, 40, 540, 7, 165, 446, 1245, 26, 169, 26, 1647, 20, 699, 20, 256, 22, 499, 7, 65, 200, 22, 901, 8, 187, 13919, 10, 5165, 9, 1607, 19010, 18, 11, 761, 36, 499, 7, 46, 11, 62, 52, 11, 6526, 8, 320, 8, 17, 11, 6478, 781, 8, 499, 7, 29, 13, 1121, 8, 3834, 13814, 47, 8, 320, 8, 13, 5085, 20, 1404, 2500, 11412, 7, 42, 13, 1881, 256, 11931, 10, 7, 4538, 23, 694, 1584, 14, 705, 8, 975, 20, 878, 9, 554, 39, 16, 2591, 7, 13, 84, 12850, 15656, 6072, 200, 22, 2971, 613, 13, 13282, 18, 11, 59, 327, 288, 18, 11, 105, 33, 31193, 23, 7294, 8, 2196, 3423, 9, 342, 11, 266, 5762, 7, 79, 207, 39, 33, 101, 8088, 44, 823, 7, 1270, 18, 11, 9461, 140, 6262, 18, 11, 3407, 20643, 2145, 5223, 24, 18062, 127, 1703, 9, 61, 84, 12850, 15656, 5828, 20, 2697, 8, 1429, 788, 14, 8, 493, 788, 7, 79, 17, 11, 5123, 18, 11, 14642, 8, 1816, 138, 341, 36, 1816, 138, 6188, 1120, 7, 14, 52, 11, 41, 8311, 7, 42, 17, 11, 761, 8, 1092, 1244, 675, 7, 22, 3627, 18, 11, 8373, 289, 8, 6923, 19, 2697, 8, 1599, 4124, 9, 54, 15611, 3607, 33, 3433, 23, 1000, 365, 8, 3599, 10, 32, 16, 5822, 9, 277, 379, 2133, 19856, 7, 63, 21, 4253, 1628, 24, 27, 19, 256, 10026, 18876, 97, 5741, 1245, 15, 1245, 8, 17, 11, 4706, 228, 14, 7080, 20, 1149, 3663, 24, 1562, 2579, 68, 6128, 9, 1855, 5679, 42, 16, 5631, 20, 1892, 4856, 7, 63, 296, 467, 36, 299, 23, 2455, 42, 16, 15611, 3607, 24, 1523, 16, 132, 1272, 87, 25534, 81, 22, 10341, 8905, 87, 7, 3901, 15, 509, 22, 284, 208, 19, 1640, 592, 4326, 9, 180, 238, 4712, 8, 127, 462, 30, 8, 3902, 16, 499, 8, 17, 11, 4378, 5578, 22, 2971, 9, 139, 50, 146, 10464, 27, 19, 699, 56, 19, 1640, 22632, 37, 78, 3635, 9, 71, 11, 2593, 8, 569, 4124, 2176, 1975, 23, 7338, 15, 17, 11, 1585, 18, 11, 3407, 10, 16134, 9, 74, 7864, 8, 11503, 2500, 8457, 38, 243, 23055, 53, 8351, 37, 13, 4145, 8, 20151, 308, 56, 15, 249, 605, 23, 13656, 3413, 8, 78, 2444, 31, 2653, 15, 23, 569, 1330, 22, 2971, 8, 17, 11, 3415, 14, 22, 2971, 2405, 9, 5956, 16, 4263, 21, 23351, 20960, 288, 17, 11, 59, 2673, 12437, 25, 347, 20, 1892, 9, 3920, 1557, 18, 11, 4406, 10, 31, 19847, 17, 11, 2128, 14, 750, 98, 24189, 10, 14, 28250, 80, 42, 8742, 9, 159, 66, 207, 49, 11, 41, 254, 112, 16, 6542, 20, 699, 7, 112, 97, 1511, 8, 739, 8, 13, 4362, 14, 8, 17, 11, 1303, 9, 84, 11, 41, 15, 39, 7, 3871, 18, 11, 5513, 7, 8, 2912, 16, 528, 1100, 384, 8, 119, 6553, 15, 75, 1158, 9, 5338, 23424, 14378, 4731, 26, 2279, 7, 24, 7751, 7, 8, 1910, 15, 17, 11, 2582, 9, 100, 103, 146, 1736, 15, 247, 4315, 32, 44, 5822, 7, 40, 7, 50, 1115, 7, 46, 11, 6880, 8, 249, 14157, 10, 36, 1599, 3069, 9, 3392, 2296, 7, 63, 4707, 7, 42, 2662, 121, 7344, 1660, 7, 15, 7150, 998, 7, 289, 18, 11, 6569, 127, 1237, 15, 166, 4412, 7427, 25, 1599, 8, 17, 11, 649, 25, 5822, 9, 4914, 7, 13, 218, 8, 17, 11, 2582, 29, 19, 3299, 15335, 47, 19, 6231, 16134, 3674, 30, 1605, 14, 1975, 34, 21338, 15, 77, 29989, 9, 170, 6131, 117, 19, 2943, 27, 166, 784, 10026, 48, 750, 18, 11, 21703, 29, 8, 490, 2380, 24, 2411, 17, 11, 1106, 14, 19, 16427, 8, 44, 5822, 9, 370, 11, 1354, 7, 14, 66, 21, 937, 13, 184, 7, 96, 2170, 82, 13, 1842, 8, 97, 8056, 15, 17, 11, 2582, 9, 100, 146, 4332, 15, 22627, 17, 11, 520, 576, 24, 26050, 81, 17, 11, 2562, 184, 18994, 43, 272, 4517, 18, 11, 70, 1323, 18541, 22, 2971, 8, 17, 11, 3415, 9, 2293, 699, 3717, 102, 530, 10593, 10, 43, 193, 726, 1484, 235, 72, 14601, 10, 29, 13, 581, 7, 65, 99, 23, 221, 365, 8, 7070, 26, 406, 7392, 2975, 20, 3734, 18, 11, 1303, 95, 7546, 9, 121, 11, 524, 264, 141, 29, 78, 4517, 28, 794, 18, 11, 24865, 32, 19, 927, 7699, 8, 499, 2028, 14, 21494, 8, 13, 3627, 18, 11, 8373, 14, 8, 17, 11, 2582, 8, 17, 11, 3415, 194, 3149, 9, 100, 146, 72, 705, 95, 26932, 141, 20, 2271, 19, 40, 9966, 15, 22627, 31, 96, 2653, 15, 17, 11, 1215, 18, 11, 3292, 9, 159, 13, 782, 12345, 46, 11, 55, 1182, 13, 3627, 18, 11, 8373, 49, 11, 55, 34, 29890, 19, 699, 9, 1646, 56, 9343, 10, 7, 192, 14667, 14, 11847, 10, 7, 29, 20, 643, 8, 225, 610, 95, 4610, 14, 165, 112, 2633, 5645, 7, 46, 11, 62, 1971, 18, 11, 617, 4325, 9, 100, 4069, 15, 19, 22, 5559, 9, 139, 50, 1282, 21, 834, 9183, 27, 13, 3627, 18, 11, 8373, 1281, 36, 40, 715, 13, 1931, 2973, 14, 16, 842, 8, 27550, 919, 8, 17, 11, 2582, 8, 17, 11, 3415, 31, 279, 98, 16, 13706, 9, 9531, 8714, 5859, 26, 17470, 13573, 2663, 7, 323, 689, 7, 45, 103, 192, 8232, 55, 34, 86, 50, 39, 701, 46, 11, 62, 213, 31903, 9, 61, 21454, 7, 13, 6863, 14, 7, 10300, 26, 185, 7, 23, 126, 8, 1876, 7, 56, 20, 10657, 16408, 80, 24, 3333, 15909, 9, 107, 2971, 104, 26, 177, 40, 46, 11, 617, 9, 100, 39, 5291, 9, 38, 6694, 67, 850, 13355, 297, 9, 18690, 9, 427, 7, 16, 532, 753, 2477]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8yAtMsdR9HB",
        "colab_type": "text"
      },
      "source": [
        "### Preparing to feed the model : adding special tokens, attention masks and transform into tensors\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXlKcUdlYetx",
        "colab_type": "text"
      },
      "source": [
        "Preprocessing steps : \n",
        "\n",
        "\n",
        "1.   **Add special tokens [CLS] [SEP]** \n",
        "\n",
        "According to the documentation we need to add special tokens to the start and end of the text Moreover, for camembert we should add a space between CLS and the first token (not sure here, we have to ask benjamin). \n",
        "\n",
        "2.   **Pad and truncate all texts to a single number**\n",
        "\n",
        "Pretrained transformes like Camembert only accept input of the same length. Our corpus contains large texts and we have to pad them in order to be able to feed Camembert. We will set the max length to a large number in order to get all information possible in the text. We choose a max length of 500 which is almost the maximum (512) \"sentence\" length  accepted. We are aware that this choice will impact a lot training speed.\n",
        "\n",
        "3.   **Construct an attention mask**\n",
        "\n",
        "Attention masks are just set to 1 when the token have to be analyzed and 0 otherwise (padded tokens). All our attention mask should be 1 with this corpus. \n",
        "\n",
        "\n",
        "\n",
        "For sake of simplicity and to avoid errors we will use the function encode_plus of the library which is really convenient. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HF89V-xSgGF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###############################################################   NOOOT GOOOODD     ##################################\n",
        "def prepare_to_feed(df,length,batch_size_value,length_train):\n",
        "  from torch.utils.data import TensorDataset, random_split\n",
        "  from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "  texts = df.Texte.values\n",
        "  labels = df.sexe.values\n",
        "\n",
        "  # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "  num_truncated_tokens =[]\n",
        "  # Apply function to our corpus\n",
        "  for text in texts:\n",
        "      encoded_dict = tokenizer.encode_plus(\n",
        "                          text,                      # text\n",
        "                          add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                          max_length = length,           # We choose for now a max length of 500.\n",
        "                          pad_to_max_length = True,    # Pad text to max (marche pas en pad left ?)\n",
        "                          return_attention_mask = True,   # Construct attention masks\n",
        "                          return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                          return_overflowing_tokens =True, # return overflowing token information\n",
        "                    )\n",
        "      \n",
        "      # Map tokens to their id in the dictionnary \n",
        "      # We add this to our list    \n",
        "      input_ids.append(encoded_dict['input_ids'])\n",
        "  \n",
        "      #num_truncated_tokens.append(encoded_dict['num_truncated_tokens'])\n",
        "      \n",
        "      # 3. Attention masks\n",
        "      attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "  # We convert all this into tensors in order to be able to make it work on GPU \n",
        "  input_ids = torch.cat(input_ids, dim=0)\n",
        "  attention_masks = torch.cat(attention_masks, dim=0)\n",
        "  labels = torch.tensor(labels)\n",
        "\n",
        "  # Original text and transformed tensor print \n",
        "  print(\"Let's check for the first text indexes, attention masks and labels\")\n",
        "  print(\" \")\n",
        "  print('Original: ', texts[0][0:100])\n",
        "  print('IDs:', input_ids[0][0:100])\n",
        "  print('Attention masks:', attention_masks[0][0:100])\n",
        "  print('labels',labels[0])\n",
        "\n",
        "\n",
        "  # Combine all above\n",
        "  dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "  # Let's create a 80-20 train / validation dataset \n",
        "  train_size = int(length_train * len(dataset))\n",
        "  val_size = len(dataset) - train_size\n",
        "\n",
        "  train_set, val_set = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "\n",
        "  print(\"-------------------------------------------------\")\n",
        "  print(\" \")\n",
        "  print(\"How many texts do we have in the train and validation sample ? \")\n",
        "  print(\" \")\n",
        "  print('We have {} training texts'.format(train_size))\n",
        "  print('We have {} validation texts'.format(val_size))\n",
        "  print(\" \")\n",
        "  print(\"-------------------------------------------------\")\n",
        "\n",
        "  # We set the size of the batch ( usually set around 16 or 32), we will take the lower bound because of the large text length\n",
        "  batch_size = batch_size_value\n",
        "\n",
        "  # We create data loaders for the train and validation dataset. \n",
        "  train_dataloader = DataLoader(\n",
        "              train_set,  # The training samples.\n",
        "              sampler = RandomSampler(train_set), # Select batches randomly\n",
        "              batch_size = batch_size # Trains with this batch size.\n",
        "          )\n",
        "\n",
        "  val_dataloader = DataLoader(\n",
        "              val_set, # The validation samples.\n",
        "              sampler = SequentialSampler(val_set), # Pull out batches sequentially.\n",
        "              batch_size = batch_size # Evaluate with this batch size.\n",
        "          )\n",
        "  \n",
        "  print('Data loaders created for train [0] and val [1]')\n",
        "\n",
        "  return train_dataloader, val_dataloader "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0b_OFrL3mIBU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a4e97f50-2311-43c2-a51d-555c6424a168"
      },
      "source": [
        "print('############### Unbalanced sample ################')\n",
        "train_loader_unbalanced, val_loader_unbalanced = prepare_to_feed(df_unbalanced,length=500,batch_size_value=2,length_train=0.8)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "############### Unbalanced sample ################\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIQMcNAgekhx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('############### Balanced sample ################')\n",
        "train_loader_balanced, val_loader_balanced = prepare_to_feed(df_balanced,length=500,batch_size_value=2,length_train=0.8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sxjN5O5mMe5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('############### Balanced sample split ################')\n",
        "train_loader_balanced_split, val_loader_balanced_split = prepare_to_feed(df_balanced_split,length=500,batch_size_value=2,length_train=0.8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkbqtyqH6V_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###########################################################GOOOOD START HERE##############################\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "texts = df_unbalanced.Texte.values\n",
        "labels = df_unbalanced.sexe.values\n",
        "\n",
        "length = 500\n",
        "batch_size_value = 16\n",
        "length_train=0.8\n",
        "torch.manual_seed(2020)\n",
        "torch.cuda.manual_seed_all(2020)\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "num_truncated_tokens =[]\n",
        "# Apply function to our corpus\n",
        "for text in texts:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        text,                      # text\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = length,           # We choose for now a max length of 500.\n",
        "                        pad_to_max_length = True,    # Pad text to max (marche pas en pad left ?)\n",
        "                        return_attention_mask = True,   # Construct attention masks\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                        return_overflowing_tokens =True, # return overflowing token information\n",
        "                  )\n",
        "    \n",
        "    # Map tokens to their id in the dictionnary \n",
        "    # We add this to our list    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "    #num_truncated_tokens.append(encoded_dict['num_truncated_tokens'])\n",
        "    \n",
        "    # 3. Attention masks\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# We convert all this into tensors in order to be able to make it work on GPU \n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Original text and transformed tensor print \n",
        "print(\"Let's check for the first text indexes, attention masks and labels\")\n",
        "print(\" \")\n",
        "print('Original: ', texts[0][0:100])\n",
        "print('IDs:', input_ids[0][0:100])\n",
        "print('Attention masks:', attention_masks[0][0:100])\n",
        "print('labels',labels[0])\n",
        "\n",
        "\n",
        "# Combine all above\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Let's create a 80-20 train / validation dataset \n",
        "train_size = int(length_train * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_set, val_set = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "\n",
        "print(\"-------------------------------------------------\")\n",
        "print(\" \")\n",
        "print(\"How many texts do we have in the train and validation sample ? \")\n",
        "print(\" \")\n",
        "print('We have {} training texts'.format(train_size))\n",
        "print('We have {} validation texts'.format(val_size))\n",
        "print(\" \")\n",
        "print(\"-------------------------------------------------\")\n",
        "\n",
        "# We set the size of the batch ( usually set around 16 or 32), we will take the lower bound because of the large text length\n",
        "batch_size = batch_size_value\n",
        "\n",
        "# We create data loaders for the train and validation dataset. \n",
        "train_loader_unbalanced = DataLoader(\n",
        "            train_set,  # The training samples.\n",
        "            sampler = RandomSampler(train_set), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "val_loader_unbalanced = DataLoader(\n",
        "            val_set, # The validation samples.\n",
        "            sampler = SequentialSampler(val_set), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n",
        "\n",
        "print('Data loaders created for train [0] and val [1]')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnLKzstr6ghY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "texts = df_balanced.Texte.values\n",
        "labels = df_balanced.sexe.values\n",
        "length = 500\n",
        "batch_size_value = 16\n",
        "length_train=0.8\n",
        "torch.manual_seed(2020)\n",
        "torch.cuda.manual_seed_all(2020)\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "num_truncated_tokens =[]\n",
        "# Apply function to our corpus\n",
        "for text in texts:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        text,                      # text\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = length,           # We choose for now a max length of 500.\n",
        "                        pad_to_max_length = True,    # Pad text to max (marche pas en pad left ?)\n",
        "                        return_attention_mask = True,   # Construct attention masks\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                        return_overflowing_tokens =True, # return overflowing token information\n",
        "                  )\n",
        "    \n",
        "    # Map tokens to their id in the dictionnary \n",
        "    # We add this to our list    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "    #num_truncated_tokens.append(encoded_dict['num_truncated_tokens'])\n",
        "    \n",
        "    # 3. Attention masks\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# We convert all this into tensors in order to be able to make it work on GPU \n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Original text and transformed tensor print \n",
        "print(\"Let's check for the first text indexes, attention masks and labels\")\n",
        "print(\" \")\n",
        "print('Original: ', texts[0][0:100])\n",
        "print('IDs:', input_ids[0][0:100])\n",
        "print('Attention masks:', attention_masks[0][0:100])\n",
        "print('labels',labels[0])\n",
        "\n",
        "\n",
        "# Combine all above\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Let's create a 80-20 train / validation dataset \n",
        "train_size = int(length_train * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_set, val_set = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "\n",
        "print(\"-------------------------------------------------\")\n",
        "print(\" \")\n",
        "print(\"How many texts do we have in the train and validation sample ? \")\n",
        "print(\" \")\n",
        "print('We have {} training texts'.format(train_size))\n",
        "print('We have {} validation texts'.format(val_size))\n",
        "print(\" \")\n",
        "print(\"-------------------------------------------------\")\n",
        "\n",
        "# We set the size of the batch ( usually set around 16 or 32), we will take the lower bound because of the large text length\n",
        "batch_size = batch_size_value\n",
        "\n",
        "# We create data loaders for the train and validation dataset. \n",
        "train_loader_balanced = DataLoader(\n",
        "            train_set,  # The training samples.\n",
        "            sampler = RandomSampler(train_set), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "val_loader_balanced = DataLoader(\n",
        "            val_set, # The validation samples.\n",
        "            sampler = SequentialSampler(val_set), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n",
        "\n",
        "print('Data loaders created for train [0] and val [1]')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FBZvaQ969S0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "texts = df_balanced_split.Texte.values \n",
        "labels = df_balanced_split.sexe.values\n",
        "\n",
        "torch.manual_seed(2020)\n",
        "torch.cuda.manual_seed_all(2020)\n",
        "length = 500\n",
        "batch_size_value = 16\n",
        "length_train=0.8\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "num_truncated_tokens =[]\n",
        "# Apply function to our corpus\n",
        "for text in texts:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        text,                      # text\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = length,           # We choose for now a max length of 500.\n",
        "                        pad_to_max_length = True,    # Pad text to max (marche pas en pad left ?)\n",
        "                        return_attention_mask = True,   # Construct attention masks\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                        return_overflowing_tokens =True, # return overflowing token information\n",
        "                  )\n",
        "    \n",
        "    # Map tokens to their id in the dictionnary \n",
        "    # We add this to our list    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "    #num_truncated_tokens.append(encoded_dict['num_truncated_tokens'])\n",
        "    \n",
        "    # 3. Attention masks\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# We convert all this into tensors in order to be able to make it work on GPU \n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Original text and transformed tensor print \n",
        "print(\"Let's check for the first text indexes, attention masks and labels\")\n",
        "print(\" \")\n",
        "print('Original: ', texts[0][0:100])\n",
        "print('IDs:', input_ids[0][0:100])\n",
        "print('Attention masks:', attention_masks[0][0:100])\n",
        "print('labels',labels[0])\n",
        "\n",
        "# Combine all above\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Let's create a 80-20 train / validation dataset \n",
        "train_size = int(length_train * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_set, val_set = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "\n",
        "print(\"-------------------------------------------------\")\n",
        "print(\" \")\n",
        "print(\"How many texts do we have in the train and validation sample ? \")\n",
        "print(\" \")\n",
        "print('We have {} training texts'.format(train_size))\n",
        "print('We have {} validation texts'.format(val_size))\n",
        "print(\" \")\n",
        "print(\"-------------------------------------------------\")\n",
        "\n",
        "# We set the size of the batch ( usually set around 16 or 32), we will take the lower bound because of the large text length\n",
        "batch_size = batch_size_value\n",
        "\n",
        "# We create data loaders for the train and validation dataset. \n",
        "train_loader_balanced_split = DataLoader(\n",
        "            train_set,  # The training samples.\n",
        "            sampler = RandomSampler(train_set), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "val_loader_balanced_split = DataLoader(\n",
        "            val_set, # The validation samples.\n",
        "            sampler = SequentialSampler(val_set), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n",
        "\n",
        "print('Data loaders created for train [0] and val [1]')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vs6YDmQsgljf",
        "colab_type": "text"
      },
      "source": [
        "5 and 6 seem to be the [CLS] and [SEP] special tokens \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poTTEJX1hoUK",
        "colab_type": "text"
      },
      "source": [
        "## CamemBERT Sequence Classification model tuning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NN1VeJI0lDwf",
        "colab_type": "text"
      },
      "source": [
        "### Loading the model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99MPOVB7iRcl",
        "colab_type": "text"
      },
      "source": [
        "We will finally build up our model. We will use the  CamemBERT model for sequence classification which includes a special top layer designed for this task. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRHhHzjKgAC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing from transformers\n",
        "from transformers import CamembertForSequenceClassification, CamembertConfig"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHMdM-QqgAAX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading the model\n",
        "gender_model = CamembertForSequenceClassification.from_pretrained(\n",
        "    \"camembert-base\", \n",
        "    num_labels = 2, # We have two different labels Women = 1 and Men =0   \n",
        "    output_attentions = False, \n",
        "    output_hidden_states = False, \n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUKynoykf_9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We run the model on the colab GPU \n",
        "gender_model.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgwmHirxnEie",
        "colab_type": "text"
      },
      "source": [
        "### Constructing the training and validation loop \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZDt2ZElwcJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import f1_score \n",
        "\n",
        "def create_report(labels,preds) : \n",
        "  pred_flat= np.argmax(preds, axis=1).flatten()\n",
        "  labels_flat = labels.flatten()\n",
        "  F1_score = f1_score(labels_flat,pred_flat,zero_division=1)\n",
        "  Accuracy = np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "  return F1_score, Accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUB8c4k_t1UJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_val_gendermodel(train_loader, val_loader, epochs_val,seed_val,device,lr_value):\n",
        "\n",
        "  ############################  IMPORT MODEL ################################################\n",
        "  from transformers import CamembertForSequenceClassification\n",
        "  gender_model = CamembertForSequenceClassification.from_pretrained(\n",
        "    \"camembert-base\", \n",
        "    num_labels = 2, # We have two different labels Women = 1 and Men =0   \n",
        "    output_attentions = False, \n",
        "    output_hidden_states = False, )\n",
        "\n",
        "  model = gender_model\n",
        "  model.cuda()\n",
        "  \n",
        "  ############################## RANDOM SEED ##################################################\n",
        "\n",
        "  import random\n",
        " # Let's put a seed to make this result reproducible \n",
        "  seed=seed_val\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "  ############################### LEARNING RATE SCHEDULER #######################################\n",
        "\n",
        "  # https://huggingface.co/transformers/migration.html \n",
        "  # https://pytorch.org/docs/stable/optim.html (default values)\n",
        "\n",
        "  import torch.nn as nn\n",
        "  import torch.optim as optim\n",
        "  from transformers import AdamW\n",
        "  from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "  epochs = epochs_val # In order to fine tune our model we will first set the number of epochs to 4.\n",
        "\n",
        "  # We choose Binary cross enthropy with logits loss for the loss computation. It seems to be the most adapted loss to our problem. \n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "  #Implements Adam algorithm with weight decay fix.\n",
        "  opti = AdamW(model.parameters(),\n",
        "                    lr =lr_value, # learning rate (default = 1e-3)\n",
        "                    eps = 1e-8 # prevents division by 0 (default = 1e-8)\n",
        "                  )\n",
        "\n",
        "  num_training_steps = len(train_loader) * epochs\n",
        "  # Create a schedule with a learning rate that decreases linearly after linearly increasing during a warmup period (0 here)\n",
        "  scheduler = get_linear_schedule_with_warmup(opti, \n",
        "                                              num_warmup_steps = 0,\n",
        "                                              num_training_steps = num_training_steps)\n",
        "  \n",
        "  \n",
        "  # We want to evaluate the training phase \n",
        "  training_stats = []\n",
        "\n",
        "  for ep in range(0, epochs):\n",
        "    print('===========Starting Epoch {} / {} =============='.format(ep+1,epochs))\n",
        "    print('Training starts')\n",
        "\n",
        "    ################################### TRAINING ################################\n",
        "\n",
        "    #Put the model in training mode\n",
        "    model.train()\n",
        "\n",
        "    # Set the train loss for the epoch to 0 \n",
        "    total_train_loss = 0\n",
        "\n",
        "    for step, batch in enumerate(train_loader):\n",
        "      # Clear gradients \n",
        "      model.zero_grad() # (opti.zerograd ? )\n",
        "\n",
        "      # Cpy the 3 batch to GPU \n",
        "      b_input_ids = batch[0].to(device)\n",
        "      b_input_mask = batch[1].to(device)\n",
        "      b_labels = batch[2].to(device)\n",
        "      \n",
        "      #return loss and logits\n",
        "      loss, logits = model(b_input_ids, \n",
        "                          token_type_ids=None, \n",
        "                          attention_mask=b_input_mask, \n",
        "                          labels=b_labels) \n",
        "      \n",
        "      # Accumulate training loss for all batches \n",
        "      total_train_loss += loss.item()\n",
        "\n",
        "      #Backpropagating the gradients \n",
        "      loss.backward()\n",
        "\n",
        "      # Prevent exploding gradients problem  (forcing the gradients to be small, the parameter updates will not push the parameters too far from their previous values)\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "      # Update parameters \n",
        "      opti.step()\n",
        "\n",
        "      # Update learning rate schedule\n",
        "      scheduler.step()\n",
        "\n",
        "    #Calculate the average training loss over all batches  \n",
        "    avg_train_loss = total_train_loss / len(train_loader)\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print('')\n",
        "    print('Validation starts')\n",
        "\n",
        "    ###################### VALIDATION #############################\n",
        "\n",
        "    # Put model in evaluation mode \n",
        "    model.eval()\n",
        "\n",
        "    # Set statistics to 0\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "    total_eval_f1=0\n",
        "    total_roc_auc = 0 \n",
        "\n",
        "    # Confusion matrix ?\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    for batch in val_loader:\n",
        "      b_input_ids = batch[0].to(device)\n",
        "      b_input_mask = batch[1].to(device)\n",
        "      b_labels = batch[2].to(device)\n",
        "      \n",
        "      # We don't care about gradients for eval\n",
        "\n",
        "      with torch.no_grad(): \n",
        "        (loss, logits) = model(b_input_ids, \n",
        "                                  token_type_ids=None, \n",
        "                                  attention_mask=b_input_mask,\n",
        "                                  labels=b_labels)\n",
        "      total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU \n",
        "      logits = logits.detach().cpu().numpy()\n",
        "      label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "      F1_score, Accuracy = create_report(label_ids,logits)\n",
        "\n",
        "      # Accumulation accuracy for all batch\n",
        "      total_eval_accuracy += Accuracy\n",
        "\n",
        "      # Accumulation f1 for all batch\n",
        "      total_eval_f1 += F1_score\n",
        "\n",
        "      \n",
        "      #Final accuracy on all batch\n",
        "    avg_val_accuracy = total_eval_accuracy / len(val_loader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "      #Final f1 on all batch\n",
        "    avg_val_f1 = total_eval_f1 / len(val_loader)\n",
        "    print(\"  F1_score: {0:.2f}\".format(avg_val_f1))\n",
        "\n",
        "      #Final loss over all batch\n",
        "    avg_val_loss = total_eval_loss / len(val_loader)\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "\n",
        "    training_stats.append(\n",
        "          {\n",
        "              'epoch': ep + 1,\n",
        "              'Train Loss': avg_train_loss,\n",
        "              'Val Loss': avg_val_loss,\n",
        "              'Val Accur.': avg_val_accuracy,\n",
        "              'Val F1' : avg_val_f1,\n",
        "          }\n",
        "      )\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"Done !\")\n",
        "\n",
        "  return  training_stats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anria4-x6FHk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def report_model_1(results):\n",
        "  '''\n",
        "  Input : statistics of the model \n",
        "  Output : training and valid loss \n",
        "  ''' \n",
        "  df_stats = pd.DataFrame(data=results)\n",
        "  df_stats = df_stats.set_index('epoch')\n",
        "  print(df_stats)\n",
        "\n",
        "  import matplotlib.pyplot as plt\n",
        "  % matplotlib inline\n",
        "  import seaborn as sns\n",
        "\n",
        "  # Increase the plot size and font size.\n",
        "  sns.set(font_scale=1.5)\n",
        "  plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "  # Plot the learning curve.\n",
        "  plt.plot(df_stats['Train Loss'], 'b-o', label=\"Training\")\n",
        "  plt.plot(df_stats['Val Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "  # Label the plot.\n",
        "  plt.title(\"Training & Validation Loss\")\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.legend()\n",
        "  plt.xticks([1, 2, 3, 4, 5])\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqNRTJME5oHs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results_unbalanced = train_val_gendermodel(train_loader=train_loader_unbalanced, val_loader=val_loader_unbalanced, epochs_val=5,seed_val=2020,device=device,lr_value=5e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKu-O0c653tX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "report_model_1(results_unbalanced)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DH9QNCMXR0zc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results_balanced = train_val_gendermodel(train_loader=train_loader_balanced, val_loader=val_loader_balanced, epochs_val=5,seed_val=2020,device=device,lr_value=5e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0Pti-Dk59DT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "report_model_1(results_balanced)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hb6Ca8qmdT74",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results_balanced_split = train_val_gendermodel(train_loader=train_loader_balanced_split, val_loader=val_loader_balanced_split, epochs_val=5,seed_val=2020,device=device,lr_value=5e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJSzx-x35-jW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "report_model_1(results_balanced_split)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLxa4te3gzi-",
        "colab_type": "text"
      },
      "source": [
        "Analyse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKXUkXjfg0s2",
        "colab_type": "text"
      },
      "source": [
        "### Training the optimal model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1LLOEa3g2wL",
        "colab_type": "code",
        "outputId": "bcb5ae11-4d68-40f3-f133-bbc4ebebf4fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "df_eval= balanced_splitted(df,seed_val,frac_val=1,max_tokens=500)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of text in this balanced splitted corpus : 10,121\n",
            "\n",
            "Proportions of women in the balanced splitted corpus : 51.09178934887857\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fa_3vh-698n6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We prepare another sample which will be dedicated to further qualitative analysis"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cL1SsPWU98tz",
        "colab_type": "code",
        "outputId": "3883c70c-0ee7-4081-86fc-dc75520aaee3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "len_train = round(0.97*len(df_eval))\n",
        "df_balanced_split= df_eval[0:len_train]\n",
        "dev_balanced_split=df_eval[len_train:len(df_eval)]\n",
        "\n",
        "# Report the number of speeches in the corpus.\n",
        "print('Number of text in this balanced splitted corpus : {:,}\\n'.format(df_balanced_split.shape[0]))\n",
        "print('Number of text in the development sample : {:,}\\n'.format(dev_balanced_split.shape[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of text in this balanced splitted corpus : 9,817\n",
            "\n",
            "Number of text in the development sample : 304\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2CdFou898x8",
        "colab_type": "code",
        "outputId": "8b414af2-35ea-4665-9b07-d8615e20e4c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "train_loader_balanced_split, val_loader_balanced_split = prepare_to_feed(df_balanced_split,length=500,batch_size_value=16,length_train=0.9)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Let's check for the first text indexes, attention masks and labels\n",
            " \n",
            "Original:   Le protocole du 19 décembre 2018 a permis de décider d'une augmentation de salaire de plus de 100 e\n",
            "IDs: tensor([    5,    54,  5996,    25,   653,   753,   552,    33,   994,     8,\n",
            "         4708,    18,    11,    70,  3708,     8,  4360,     8,    40,     8,\n",
            "          779,   982,  2607,    10,    37,   250,    24,   166,  6436,     9,\n",
            "         2335,    17,    11,  1629,     8,    13,  8776,     7,    63,   296,\n",
            "         6267,  6132,    20,  1964, 11805,     8,  3508,    22,  3100,    25,\n",
            "         1625,    25,  2011,    14,    20,   643,     8,   225,     8,   166,\n",
            "         6436,     7,    22,   770,    52,    11, 12522,     8,    17,    11,\n",
            "         1563,    25,   125,     8,   225,     9, 16078,    68,  3708,    10,\n",
            "        16054,    10,     7,    63,   296,    19,  1149,    18,    11,  7877,\n",
            "           17,    11,  1960,    27,    63,    63,   464,  5499,     8, 14901])\n",
            "Attention masks: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1])\n",
            "labels tensor(0)\n",
            "-------------------------------------------------\n",
            " \n",
            "How many texts do we have in the train and validation sample ? \n",
            " \n",
            "We have 8835 training texts\n",
            "We have 982 validation texts\n",
            " \n",
            "-------------------------------------------------\n",
            "Data loaders created for train [0] and val [1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0p-TPR1CAOlh",
        "colab_type": "code",
        "outputId": "31c9bfab-cdea-47e1-897c-8abdbe0a5f20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "############################  IMPORT MODEL ################################################\n",
        "from transformers import CamembertForSequenceClassification\n",
        "gender_model = CamembertForSequenceClassification.from_pretrained(\"camembert-base\", \n",
        "                                                                  num_labels = 2, \n",
        "                                                                  output_attentions = False, \n",
        "                                                                  output_hidden_states = False, )\n",
        "\n",
        "gender_model.cuda()\n",
        "############################## RANDOM SEED ##################################################\n",
        "\n",
        "import random\n",
        "seed=seed_val\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "############################### LEARNING RATE SCHEDULER #######################################\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from transformers import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs = 3 \n",
        "\n",
        "#Implements Adam algorithm with weight decay fix.\n",
        "opti = AdamW(gender_model.parameters(),\n",
        "              lr =5e-5, # learning rate (default = 1e-3)\n",
        "              eps = 1e-8 # prevents division by 0 (default = 1e-8)\n",
        "            )\n",
        "\n",
        "num_training_steps = len(train_loader_balanced_split) * epochs\n",
        "\n",
        "# Create a schedule with a learning rate that decreases linearly after linearly increasing during a warmup period (0 here)\n",
        "scheduler = get_linear_schedule_with_warmup(opti, \n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = num_training_steps)\n",
        "\n",
        "\n",
        "for ep in range(0, epochs):\n",
        "  print('===========Starting Epoch {} / {} =============='.format(ep+1,epochs))\n",
        "  print('Training starts')\n",
        "\n",
        "  ################################### TRAINING ################################\n",
        "\n",
        "  #Put the model in training mode\n",
        "  gender_model.train()\n",
        "\n",
        "  # Set the train loss for the epoch to 0 \n",
        "  total_train_loss = 0\n",
        "\n",
        "  for step, batch in enumerate(train_loader_balanced_split):\n",
        "    # Clear gradients \n",
        "    gender_model.zero_grad() # (opti.zerograd ? )\n",
        "\n",
        "    # Cpy the 3 batch to GPU \n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "    \n",
        "    #return loss and logits\n",
        "    loss, logits = gender_model(b_input_ids, \n",
        "                                token_type_ids=None, \n",
        "                                attention_mask=b_input_mask, \n",
        "                                labels=b_labels) \n",
        "    \n",
        "    # Accumulate training loss for all batches \n",
        "    total_train_loss += loss.item()\n",
        "\n",
        "    #Backpropagating the gradients \n",
        "    loss.backward()\n",
        "\n",
        "    # Prevent exploding gradients problem  (forcing the gradients to be small, the parameter updates will not push the parameters too far from their previous values)\n",
        "    torch.nn.utils.clip_grad_norm_(gender_model.parameters(), 1.0)\n",
        "\n",
        "    # Update parameters \n",
        "    opti.step()\n",
        "\n",
        "    # Update learning rate schedule\n",
        "    scheduler.step()\n",
        "\n",
        "  #Calculate the average training loss over all batches  \n",
        "  avg_train_loss = total_train_loss / len(train_loader_balanced_split)\n",
        "  print(\"\")\n",
        "  print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===========Starting Epoch 1 / 3 ==============\n",
            "Training starts\n",
            "\n",
            "  Average training loss: 0.51\n",
            "===========Starting Epoch 2 / 3 ==============\n",
            "Training starts\n",
            "\n",
            "  Average training loss: 0.35\n",
            "===========Starting Epoch 3 / 3 ==============\n",
            "Training starts\n",
            "\n",
            "  Average training loss: 0.23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFpRse9-DAAy",
        "colab_type": "text"
      },
      "source": [
        "Let's compute some statistics on the performance of this final model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMAECbOYC_Rv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def evaluation_loop(model,eval_loader): \n",
        "  # Put model in evaluation mode \n",
        "  model.eval()\n",
        "  total_eval_loss,total_pred,total_label,total_logits=[],[],[],[]\n",
        "\n",
        "  for batch in eval_loader:\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "\n",
        "    with torch.no_grad(): \n",
        "      loss, logits = model(b_input_ids, \n",
        "                                token_type_ids=None, \n",
        "                                attention_mask=b_input_mask,\n",
        "                                labels=b_labels)\n",
        "    #total_eval_loss += loss.item()\n",
        "\n",
        "      # Move logits and labels to CPU \n",
        "      logits = logits.detach().cpu().numpy()\n",
        "      label_ids = b_labels.to('cpu').numpy()\n",
        "      pred= np.argmax(logits, axis=1).flatten()\n",
        "      labels_flat = label_ids.flatten()\n",
        "\n",
        "    # Accumulation accuracy for all batch\n",
        "      total_pred += pred.tolist()\n",
        "\n",
        "    # Accumulation f1 for all batch\n",
        "      total_label += labels_flat.tolist()\n",
        "\n",
        "      # Logits score on positive \n",
        "      total_logits += logits.tolist()\n",
        "\n",
        "  return total_pred,total_label,total_logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLPLUSq6mWgc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_pred,total_label,total_logits =evaluation_loop(gender_model,val_loader_balanced_split)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Of_IfZYuEyJG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_report(pred,label,logits):\n",
        "    \"\"\"\n",
        "        Input :\n",
        "            model : Algorithme de sklearn avec les paramètres choisit ou par défaut\n",
        "            X_train,X_test,y_train,y_test : dataset découpé à l'aide de train_test_split\n",
        "        Output : \n",
        "            Classification_report + Confusion_matrix + ROC_curve + (si possible feature importance)\n",
        "    \"\"\"\n",
        "    #from sklearn\n",
        "    import seaborn as sns\n",
        "    import matplotlib.pyplot as plt\n",
        "    from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_auc_score, roc_curve\n",
        "    logits = [el[1] for el in total_logits]\n",
        "    pred = [i for i in total_pred]\n",
        "    label = [i for i in total_label]\n",
        "    print (\"Classification report :\")\n",
        "    print(classification_report(label,pred))\n",
        "    print (\"Accuracy : \",accuracy_score(label,pred))\n",
        "    cm = confusion_matrix(label,pred)\n",
        "    ROC = roc_auc_score(label,pred) \n",
        "    print (\"AUC : \",ROC)\n",
        "    fpr,tpr,thresholds = roc_curve(label,logits)\n",
        "    plt.figure(figsize=(12,10))\n",
        "    plt.subplot(221)\n",
        "    sns.heatmap(cm/np.sum(cm), annot=True, \n",
        "            fmt='.2%', cmap='Blues').set_title('Matrice de confusion')\n",
        "    plt.subplot(222)\n",
        "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % ROC)\n",
        "    plt.plot([0,1],[0,1],color='red')\n",
        "    plt.title('Courbe ROC')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOvGlNbxOSPq",
        "colab_type": "code",
        "outputId": "978d09f0-aa89-42b3-970b-d5e8e1084d61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        }
      },
      "source": [
        "model_report(total_pred,total_label,logits)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification report :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.78      0.80       469\n",
            "           1       0.81      0.84      0.82       513\n",
            "\n",
            "    accuracy                           0.81       982\n",
            "   macro avg       0.81      0.81      0.81       982\n",
            "weighted avg       0.81      0.81      0.81       982\n",
            "\n",
            "Accuracy :  0.8126272912423625\n",
            "AUC :  0.8113359684451593\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAE0CAYAAADAGJ4EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nH1OtLHSlq4PFAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x720 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60t946KwdjJh",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation and qualitative analysis "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syd2rBrsSLro",
        "colab_type": "text"
      },
      "source": [
        "Preparing development sequence "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9-lOx5RR-6B",
        "colab_type": "text"
      },
      "source": [
        "We will use our development set we let outside of the analysis to make an attempt of qualitative analysis. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1GKZZKlSOZo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We prepare again the development sample for analysis \n",
        "def dev_prepare_to_feed(df,max_length_value,batch_size_value):\n",
        "  from torch.utils.data import TensorDataset, random_split\n",
        "  from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "  from transformers import CamembertTokenizer\n",
        "\n",
        "  texts = df.Texte.values\n",
        "  labels = df.sexe.values\n",
        "  tokenizer = CamembertTokenizer.from_pretrained('camembert-base', do_lower_case=False,padding_side='right')\n",
        "  \n",
        "  # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "  num_truncated_tokens =[]\n",
        "\n",
        "  for text in texts:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                          text,                      # text\n",
        "                          add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                          max_length = max_length_value,           # We choose for now a max length of 500.\n",
        "                          pad_to_max_length = True,    # Pad text to max (marche pas en pad left ?)\n",
        "                          return_attention_mask = True,   # Construct attention masks\n",
        "                          return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                          return_overflowing_tokens =True, # return overflowing token information\n",
        "                    )\n",
        "      \n",
        "      # Map tokens to their id in the dictionnary \n",
        "      # We add this to our list    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "      #num_truncated_tokens.append(encoded_dict['num_truncated_tokens'])\n",
        "      \n",
        "      # 3. Attention masks\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "  # We convert all this into tensors in order to be able to make it work on GPU \n",
        "  input_ids = torch.cat(input_ids, dim=0)\n",
        "  attention_masks = torch.cat(attention_masks, dim=0)\n",
        "  labels = torch.tensor(labels)\n",
        "\n",
        "  # Original text and transformed tensor print \n",
        "  print(\"Let's check for the first text indexes, attention masks and labels\")\n",
        "  print(\" \")\n",
        "  print('Original: ', texts[0][0:100])\n",
        "  print('IDs:', input_ids[0][0:100])\n",
        "  print('Attention masks:', attention_masks[0][0:100])\n",
        "  print('labels',labels[0])\n",
        "\n",
        "  # Combine all above\n",
        "  dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "  # We create data loaders for the train and validation dataset. \n",
        "  dev_dataloader = DataLoader(\n",
        "              dataset,  # The training samples.\n",
        "              batch_size = batch_size_value, # Trains with this batch size.\n",
        "              shuffle=False\n",
        "          )\n",
        "  return dev_dataloader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hd8v_Gb55BPT",
        "colab_type": "code",
        "outputId": "eeda6772-9f46-4fa5-ad37-6781b5aa115f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "dev_dataloader=dev_prepare_to_feed(dev_balanced_split,max_length_value=500,batch_size_value=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Let's check for the first text indexes, attention masks and labels\n",
            " \n",
            "Original:   J'ai plaisir à le souligner aujourd'hui devant vous tous, responsables des petites villes de France\n",
            "IDs: tensor([   5,  121,   11,   73,  593,   15,   16, 8415,  405,   11,  265,  466,\n",
            "          39,  117,    7, 2783,   20,  923, 1785,    8,  184,    9,    6,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1])\n",
            "Attention masks: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0])\n",
            "labels tensor(0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aX0AAe6J9uyi",
        "colab_type": "code",
        "outputId": "f6e89859-313e-4881-d926-d66edf21269a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "dev_balanced_split"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>index_df</th>\n",
              "      <th>sexe</th>\n",
              "      <th>Texte</th>\n",
              "      <th>Length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9817</th>\n",
              "      <td>7405</td>\n",
              "      <td>131006</td>\n",
              "      <td>0</td>\n",
              "      <td>J'ai plaisir à le souligner aujourd'hui devan...</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9818</th>\n",
              "      <td>3196</td>\n",
              "      <td>186921</td>\n",
              "      <td>1</td>\n",
              "      <td>J'ai demandé à la mission « musique » de cond...</td>\n",
              "      <td>421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9819</th>\n",
              "      <td>2956</td>\n",
              "      <td>150006</td>\n",
              "      <td>1</td>\n",
              "      <td>Le deuxième objectif que Michel Duffour et mo...</td>\n",
              "      <td>481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9820</th>\n",
              "      <td>4754</td>\n",
              "      <td>204874</td>\n",
              "      <td>1</td>\n",
              "      <td>Vous le savez, le Président de la République ...</td>\n",
              "      <td>492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9821</th>\n",
              "      <td>9831</td>\n",
              "      <td>207653</td>\n",
              "      <td>0</td>\n",
              "      <td>Dans l'attente des conclusions du groupe de t...</td>\n",
              "      <td>486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10116</th>\n",
              "      <td>3655</td>\n",
              "      <td>199244</td>\n",
              "      <td>1</td>\n",
              "      <td>Le débat que nous aurons demain sur les liens...</td>\n",
              "      <td>489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10117</th>\n",
              "      <td>1661</td>\n",
              "      <td>142593</td>\n",
              "      <td>1</td>\n",
              "      <td>Nous sommes conscients que la condamnation de...</td>\n",
              "      <td>444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10118</th>\n",
              "      <td>2139</td>\n",
              "      <td>175426</td>\n",
              "      <td>1</td>\n",
              "      <td>. . Ce n'est pas facile : la parité, la diver...</td>\n",
              "      <td>495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10119</th>\n",
              "      <td>7491</td>\n",
              "      <td>163460</td>\n",
              "      <td>0</td>\n",
              "      <td>Laïque, Démocratique et Sociale. Oui, tous un...</td>\n",
              "      <td>228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10120</th>\n",
              "      <td>9056</td>\n",
              "      <td>136731</td>\n",
              "      <td>0</td>\n",
              "      <td>J'ai d'ores et déjà demandé au PUCA d'inscrir...</td>\n",
              "      <td>491</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>304 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       index  ...  Length\n",
              "9817    7405  ...      16\n",
              "9818    3196  ...     421\n",
              "9819    2956  ...     481\n",
              "9820    4754  ...     492\n",
              "9821    9831  ...     486\n",
              "...      ...  ...     ...\n",
              "10116   3655  ...     489\n",
              "10117   1661  ...     444\n",
              "10118   2139  ...     495\n",
              "10119   7491  ...     228\n",
              "10120   9056  ...     491\n",
              "\n",
              "[304 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXVKl1flXbkz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_pred,total_labels,total_logits=evaluation_loop(gender_model,dev_dataloader)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvgZXct7YSpk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extract the score for label 1 \n",
        "one_score = [el[1] for el in total_logits]\n",
        "max_score = np.max(total_logits,axis=1)\n",
        "# Put everything inside a dataframe\n",
        "results_dev=pd.DataFrame([total_labels,total_pred,one_score,max_score]).transpose()\n",
        "results_dev.columns=['returned_labels','model_pred','one_score','max_score']\n",
        "results_dev['WF']=pd.DataFrame([results_dev['model_pred']==results_dev['returned_labels']]).transpose()\n",
        "# Merge back with the text\n",
        "frames = [dev_balanced_split[['Texte','sexe','index_df']].reset_index(), results_dev]\n",
        "result = pd.concat(frames,axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBhJ624rzOWG",
        "colab_type": "code",
        "outputId": "031baa79-bac4-46aa-f844-08011e724dbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "result"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Texte</th>\n",
              "      <th>sexe</th>\n",
              "      <th>index_df</th>\n",
              "      <th>returned_labels</th>\n",
              "      <th>model_pred</th>\n",
              "      <th>one_score</th>\n",
              "      <th>max_score</th>\n",
              "      <th>WF</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9817</td>\n",
              "      <td>J'ai plaisir à le souligner aujourd'hui devan...</td>\n",
              "      <td>0</td>\n",
              "      <td>131006</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.445413</td>\n",
              "      <td>0.445413</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9818</td>\n",
              "      <td>J'ai demandé à la mission « musique » de cond...</td>\n",
              "      <td>1</td>\n",
              "      <td>186921</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.487588</td>\n",
              "      <td>2.487588</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9819</td>\n",
              "      <td>Le deuxième objectif que Michel Duffour et mo...</td>\n",
              "      <td>1</td>\n",
              "      <td>150006</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.389463</td>\n",
              "      <td>1.389463</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9820</td>\n",
              "      <td>Vous le savez, le Président de la République ...</td>\n",
              "      <td>1</td>\n",
              "      <td>204874</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.933072</td>\n",
              "      <td>1.933072</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9821</td>\n",
              "      <td>Dans l'attente des conclusions du groupe de t...</td>\n",
              "      <td>0</td>\n",
              "      <td>207653</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.283976</td>\n",
              "      <td>2.283976</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>10116</td>\n",
              "      <td>Le débat que nous aurons demain sur les liens...</td>\n",
              "      <td>1</td>\n",
              "      <td>199244</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.160049</td>\n",
              "      <td>2.160049</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>10117</td>\n",
              "      <td>Nous sommes conscients que la condamnation de...</td>\n",
              "      <td>1</td>\n",
              "      <td>142593</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.154672</td>\n",
              "      <td>2.154672</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>10118</td>\n",
              "      <td>. . Ce n'est pas facile : la parité, la diver...</td>\n",
              "      <td>1</td>\n",
              "      <td>175426</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.490168</td>\n",
              "      <td>2.490168</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>10119</td>\n",
              "      <td>Laïque, Démocratique et Sociale. Oui, tous un...</td>\n",
              "      <td>0</td>\n",
              "      <td>163460</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.327210</td>\n",
              "      <td>2.504230</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>303</th>\n",
              "      <td>10120</td>\n",
              "      <td>J'ai d'ores et déjà demandé au PUCA d'inscrir...</td>\n",
              "      <td>0</td>\n",
              "      <td>136731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.920517</td>\n",
              "      <td>0.920517</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>304 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     index                                              Texte  ...  max_score     WF\n",
              "0     9817   J'ai plaisir à le souligner aujourd'hui devan...  ...   0.445413  False\n",
              "1     9818   J'ai demandé à la mission « musique » de cond...  ...   2.487588   True\n",
              "2     9819   Le deuxième objectif que Michel Duffour et mo...  ...   1.389463   True\n",
              "3     9820   Vous le savez, le Président de la République ...  ...   1.933072   True\n",
              "4     9821   Dans l'attente des conclusions du groupe de t...  ...   2.283976  False\n",
              "..     ...                                                ...  ...        ...    ...\n",
              "299  10116   Le débat que nous aurons demain sur les liens...  ...   2.160049   True\n",
              "300  10117   Nous sommes conscients que la condamnation de...  ...   2.154672   True\n",
              "301  10118   . . Ce n'est pas facile : la parité, la diver...  ...   2.490168   True\n",
              "302  10119   Laïque, Démocratique et Sociale. Oui, tous un...  ...   2.504230   True\n",
              "303  10120   J'ai d'ores et déjà demandé au PUCA d'inscrir...  ...   0.920517  False\n",
              "\n",
              "[304 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLF9aS31dH7M",
        "colab_type": "code",
        "outputId": "f02cb924-e70b-4f60-ca7e-a26d19c1027e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Which texts failed ? \n",
        "print('{0:.2f} percent of the development texts were not well classified by our model'.format(result[result.WF==False].WF.count()*100/len(result)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17.76 percent of the development texts were not well classified by our model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHTuqPbu1nti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We merge this dataframe to the information we had at the beginning\n",
        "merged_results=result[['index','index_df','returned_labels','model_pred','one_score','max_score','WF']].merge(df,how='left',left_on='index_df',right_on='Id')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtVSBuEp02VL",
        "colab_type": "text"
      },
      "source": [
        "Now we are going to take 3 texts well classified and 3 other wrongly classified. We will try to take the ones the model as really sure about in the good or bad side."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gy9_53i23Y2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "top_texts_true=merged_results[merged_results.WF==1].nlargest(3,'max_score')\n",
        "top_texts_false=merged_results[merged_results.WF==0].nlargest(3,'max_score')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mR8fnne6KHQH",
        "colab_type": "code",
        "outputId": "10d136f0-de9f-4e39-aabc-9a819c16fe7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "top_texts_true"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>index_df</th>\n",
              "      <th>returned_labels</th>\n",
              "      <th>model_pred</th>\n",
              "      <th>one_score</th>\n",
              "      <th>max_score</th>\n",
              "      <th>WF</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Id</th>\n",
              "      <th>Titre</th>\n",
              "      <th>Type</th>\n",
              "      <th>Theme</th>\n",
              "      <th>Prenom</th>\n",
              "      <th>Nom</th>\n",
              "      <th>Fonction</th>\n",
              "      <th>Date</th>\n",
              "      <th>Tags</th>\n",
              "      <th>Texte</th>\n",
              "      <th>Lien</th>\n",
              "      <th>PRENOM</th>\n",
              "      <th>preusuel</th>\n",
              "      <th>sexe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>9945</td>\n",
              "      <td>176000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.415498</td>\n",
              "      <td>2.580664</td>\n",
              "      <td>True</td>\n",
              "      <td>14889</td>\n",
              "      <td>176000</td>\n",
              "      <td>Déclaration de M. Bernard Kouchner, ministre d...</td>\n",
              "      <td>déclaration</td>\n",
              "      <td>Société</td>\n",
              "      <td>Bernard</td>\n",
              "      <td>Kouchner</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2009-07-16T12:00:00Z</td>\n",
              "      <td>Culture - Médias,Politique culturelle</td>\n",
              "      <td>Madame la Ministre,Monsieur le Directeur génér...</td>\n",
              "      <td>https://www.vie-publique.fr/discours/176000-de...</td>\n",
              "      <td>BERNARD</td>\n",
              "      <td>BERNARD</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>10076</td>\n",
              "      <td>162162</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.403018</td>\n",
              "      <td>2.578912</td>\n",
              "      <td>True</td>\n",
              "      <td>12107</td>\n",
              "      <td>162162</td>\n",
              "      <td>Déclaration de M. Nicolas Sarkozy, ministre de...</td>\n",
              "      <td>déclaration</td>\n",
              "      <td>Société</td>\n",
              "      <td>Nicolas</td>\n",
              "      <td>Sarkozy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2006-06-09T12:00:00Z</td>\n",
              "      <td>Sécurité,Délinquance,Ordre public</td>\n",
              "      <td>Mesdames, Messieurs,Je vous ai réunis aujourd'...</td>\n",
              "      <td>https://www.vie-publique.fr/discours/162162-de...</td>\n",
              "      <td>NICOLAS</td>\n",
              "      <td>NICOLAS</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>9969</td>\n",
              "      <td>179250</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.398858</td>\n",
              "      <td>2.573263</td>\n",
              "      <td>True</td>\n",
              "      <td>28704</td>\n",
              "      <td>179250</td>\n",
              "      <td>Déclaration de M. Brice Hortefeux, ministre de...</td>\n",
              "      <td>déclaration</td>\n",
              "      <td>Société</td>\n",
              "      <td>Brice</td>\n",
              "      <td>Hortefeux</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2010-06-12T12:00:00Z</td>\n",
              "      <td>Sécurité,Police</td>\n",
              "      <td>Monsieur le préfet,Monsieur le député,Monsieur...</td>\n",
              "      <td>https://www.vie-publique.fr/discours/179250-de...</td>\n",
              "      <td>BRICE</td>\n",
              "      <td>BRICE</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     index  index_df  returned_labels  ...   PRENOM  preusuel  sexe\n",
              "128   9945    176000              0.0  ...  BERNARD   BERNARD     0\n",
              "259  10076    162162              0.0  ...  NICOLAS   NICOLAS     0\n",
              "152   9969    179250              0.0  ...    BRICE     BRICE     0\n",
              "\n",
              "[3 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4MGbB9j3koA",
        "colab_type": "code",
        "outputId": "3c87353b-efd4-46e2-c009-5e833fcbddbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        }
      },
      "source": [
        "top_texts_false"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>index_df</th>\n",
              "      <th>returned_labels</th>\n",
              "      <th>model_pred</th>\n",
              "      <th>one_score</th>\n",
              "      <th>max_score</th>\n",
              "      <th>WF</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Id</th>\n",
              "      <th>Titre</th>\n",
              "      <th>Type</th>\n",
              "      <th>Theme</th>\n",
              "      <th>Prenom</th>\n",
              "      <th>Nom</th>\n",
              "      <th>Fonction</th>\n",
              "      <th>Date</th>\n",
              "      <th>Tags</th>\n",
              "      <th>Texte</th>\n",
              "      <th>Lien</th>\n",
              "      <th>PRENOM</th>\n",
              "      <th>preusuel</th>\n",
              "      <th>sexe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>9868</td>\n",
              "      <td>173030</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.252967</td>\n",
              "      <td>2.399928</td>\n",
              "      <td>False</td>\n",
              "      <td>29371</td>\n",
              "      <td>173030</td>\n",
              "      <td>Déclaration de Mme Rama Yade, secrétaire d'Eta...</td>\n",
              "      <td>déclaration</td>\n",
              "      <td>International</td>\n",
              "      <td>Rama</td>\n",
              "      <td>Yade</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2008-11-12T12:00:00Z</td>\n",
              "      <td>Relations internationales,Relations bilatérale...</td>\n",
              "      <td>Monsieur le Député, après douze jours d'inquié...</td>\n",
              "      <td>https://www.vie-publique.fr/discours/173030-de...</td>\n",
              "      <td>RAMA</td>\n",
              "      <td>RAMA</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9821</td>\n",
              "      <td>207653</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.283976</td>\n",
              "      <td>2.283976</td>\n",
              "      <td>False</td>\n",
              "      <td>15395</td>\n",
              "      <td>207653</td>\n",
              "      <td>Déclaration de M. Bernard Kouchner, ministre d...</td>\n",
              "      <td>déclaration</td>\n",
              "      <td>Société</td>\n",
              "      <td>Bernard</td>\n",
              "      <td>Kouchner</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2001-12-06T12:00:00Z</td>\n",
              "      <td>Santé - Protection sociale,Etablissement sanit...</td>\n",
              "      <td>Mesdames, Messieurs,Au printemps dernier, en p...</td>\n",
              "      <td>https://www.vie-publique.fr/discours/207653-de...</td>\n",
              "      <td>BERNARD</td>\n",
              "      <td>BERNARD</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>182</th>\n",
              "      <td>9999</td>\n",
              "      <td>206934</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.090272</td>\n",
              "      <td>2.090272</td>\n",
              "      <td>False</td>\n",
              "      <td>256</td>\n",
              "      <td>206934</td>\n",
              "      <td>Déclaration de M. Edouard Philippe, Premier mi...</td>\n",
              "      <td>déclaration</td>\n",
              "      <td>Société</td>\n",
              "      <td>Edouard</td>\n",
              "      <td>Philippe</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2018-10-15T12:00:00Z</td>\n",
              "      <td>Santé - Protection sociale,Politique sociale</td>\n",
              "      <td>Madame la Présidente de l'UNCCAS, chère Joëlle...</td>\n",
              "      <td>https://www.vie-publique.fr/discours/206934-de...</td>\n",
              "      <td>EDOUARD</td>\n",
              "      <td>EDOUARD</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     index  index_df  returned_labels  ...   PRENOM  preusuel  sexe\n",
              "51    9868    173030              1.0  ...     RAMA      RAMA     1\n",
              "4     9821    207653              0.0  ...  BERNARD   BERNARD     0\n",
              "182   9999    206934              0.0  ...  EDOUARD   EDOUARD     0\n",
              "\n",
              "[3 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Oi-Hk4Q4J36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjJlGCVmhlsW",
        "colab_type": "text"
      },
      "source": [
        "We want to dive a bit into the model and see how it makes a choice and why it fails on thos 38 sentences. Let's take one of them. We will redo point 4 of TD4 to see the score reached by each word. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQWuNom8MMcA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_document_to_limit(MAX_TOKENS,df):\n",
        "  lst= []\n",
        "  for index,row in df.iterrows():\n",
        "    identifiant = row.Id\n",
        "    label = row.sexe\n",
        "    phrase = []\n",
        "    for token in row.Texte.split(' '):\n",
        "      if len(phrase) < MAX_TOKENS:\n",
        "        phrase.append(token)\n",
        "      else:\n",
        "        lst += [(identifiant,label,' '.join(phrase),len(phrase))]\n",
        "        phrase = []\n",
        "    if len(phrase)>1:\n",
        "      lst += [(identifiant,label,' '.join(phrase),len(phrase))]\n",
        "  return pd.DataFrame(lst,columns=['index_df','sexe','Texte','Length'])\n",
        "def split_document_to_limit_phrases(MAX_TOKENS,df):\n",
        "  lst= []\n",
        "  for index,row in df.iterrows():\n",
        "    identifiant = row.Id\n",
        "    label = row.sexe\n",
        "    phrase = ''\n",
        "    for phrases in sent_detector_mano(row.Texte):\n",
        "      if len(phrase.split(' ')) + len(phrases.split(' ')) < MAX_TOKENS:\n",
        "        phrase+= \" \" + phrases\n",
        "      else:\n",
        "        lst += [(identifiant,label,phrase,len(phrase.split(' ')))]\n",
        "        phrase = ''\n",
        "    lst += [(identifiant,label,phrase,len(phrase.split(' ')))]\n",
        "    phrase = ''\n",
        "  return pd.DataFrame(lst,columns=['index_df','sexe','Texte','Length'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XKOwjLLh7u4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence_to_analyse = pd.concat([top_texts_false,top_texts_true]).reset_index(drop=True)\n",
        "sentence_to_analyse=split_document_to_limit_phrases(50,sentence_to_analyse)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3MVBt9Ym275",
        "colab_type": "code",
        "outputId": "a7a21428-84a0-4acb-a2af-deaab65f5030",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max(sentence_to_analyse.Length)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhu2c2MSkOmD",
        "colab_type": "code",
        "outputId": "764c037a-5ecb-4798-a733-ad5ae386def8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "dev_dataloader=dev_prepare_to_feed(sentence_to_analyse,max_length_value=55,batch_size_value=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Let's check for the first text indexes, attention masks and labels\n",
            " \n",
            "Original:   Monsieur le Député, après douze jours d'inquiétude, nos sept compatriotes et un ressortissant tunis\n",
            "IDs: tensor([    5,  2445,    16, 27891,     7,   182,  5972,   274,    18,    11,\n",
            "        16035,     7,   166,  2085, 16681,    10,    14,    23,  4008,  2914,\n",
            "        17773,     7,  3665,     8,    13,   426, 21530,     7,    56, 10540,\n",
            "           10,    44,   823,    25,  9834,   182,   190,   101, 10508,    10,\n",
            "            9,   121,    11,  1009,    15,    17,    11,  4220,     8, 28658,\n",
            "           24,    19,  3468,    42,     6])\n",
            "Attention masks: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1])\n",
            "labels tensor(1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzsoooGrlpdC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_pred,total_labels,total_logits =evaluation_loop(gender_model,dev_dataloader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX2fdfkm89C_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extract the score for label 1 \n",
        "one_score = [el[1] for el in total_logits]\n",
        "max_score = np.max(total_logits,axis=1)\n",
        "# Put everything inside a dataframe\n",
        "results_dev=pd.DataFrame([total_labels,total_pred,one_score,max_score]).transpose()\n",
        "results_dev.columns=['returned_labels','model_pred','one_score','max_score']\n",
        "results_dev['WF']=pd.DataFrame([results_dev['model_pred']==results_dev['returned_labels']]).transpose()\n",
        "# Merge back with the text\n",
        "frames = [sentence_to_analyse[['Texte','sexe','index_df']].reset_index(), results_dev]\n",
        "result = pd.concat(frames,axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTK50qJZngQW",
        "colab_type": "code",
        "outputId": "d8315d61-9e2d-4a2e-8829-b2565fea1dfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 932
        }
      },
      "source": [
        "result"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Texte</th>\n",
              "      <th>sexe</th>\n",
              "      <th>index_df</th>\n",
              "      <th>returned_labels</th>\n",
              "      <th>model_pred</th>\n",
              "      <th>one_score</th>\n",
              "      <th>max_score</th>\n",
              "      <th>WF</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Monsieur le Député, après douze jours d'inqui...</td>\n",
              "      <td>1</td>\n",
              "      <td>173030</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.061862</td>\n",
              "      <td>1.105137</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>C'est aussi, vous l'avez souligné Monsieur le...</td>\n",
              "      <td>1</td>\n",
              "      <td>173030</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.534817</td>\n",
              "      <td>0.521251</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>L'objectif était alors de les réconforter et ...</td>\n",
              "      <td>1</td>\n",
              "      <td>173030</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.292707</td>\n",
              "      <td>1.359186</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Je salue également les autorités nigérianes q...</td>\n",
              "      <td>1</td>\n",
              "      <td>173030</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.711271</td>\n",
              "      <td>1.846850</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Que ce soit dans le golfe de Guinée, dans les...</td>\n",
              "      <td>1</td>\n",
              "      <td>173030</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.268483</td>\n",
              "      <td>1.347814</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>266</th>\n",
              "      <td>266</td>\n",
              "      <td>(3) Je n'oublie pas non plus que, durant ces ...</td>\n",
              "      <td>0</td>\n",
              "      <td>179250</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.940289</td>\n",
              "      <td>0.940289</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>267</th>\n",
              "      <td>267</td>\n",
              "      <td>J'étais, hier, à Chamonix pour rendre hommage...</td>\n",
              "      <td>0</td>\n",
              "      <td>179250</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.797531</td>\n",
              "      <td>1.923270</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>268</th>\n",
              "      <td>268</td>\n",
              "      <td>Mesdames et Messieurs,Cette journée est une n...</td>\n",
              "      <td>0</td>\n",
              "      <td>179250</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.578052</td>\n",
              "      <td>0.578052</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>269</th>\n",
              "      <td>269</td>\n",
              "      <td>En incarnant la quintessence même des valeurs...</td>\n",
              "      <td>0</td>\n",
              "      <td>179250</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.544272</td>\n",
              "      <td>1.646882</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270</th>\n",
              "      <td>270</td>\n",
              "      <td>Le RAID fête son quart de siècle et peut envi...</td>\n",
              "      <td>0</td>\n",
              "      <td>179250</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.693378</td>\n",
              "      <td>1.818718</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>271 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     index                                              Texte  ...  max_score     WF\n",
              "0        0   Monsieur le Député, après douze jours d'inqui...  ...   1.105137  False\n",
              "1        1   C'est aussi, vous l'avez souligné Monsieur le...  ...   0.521251  False\n",
              "2        2   L'objectif était alors de les réconforter et ...  ...   1.359186  False\n",
              "3        3   Je salue également les autorités nigérianes q...  ...   1.846850  False\n",
              "4        4   Que ce soit dans le golfe de Guinée, dans les...  ...   1.347814  False\n",
              "..     ...                                                ...  ...        ...    ...\n",
              "266    266   (3) Je n'oublie pas non plus que, durant ces ...  ...   0.940289  False\n",
              "267    267   J'étais, hier, à Chamonix pour rendre hommage...  ...   1.923270   True\n",
              "268    268   Mesdames et Messieurs,Cette journée est une n...  ...   0.578052  False\n",
              "269    269   En incarnant la quintessence même des valeurs...  ...   1.646882   True\n",
              "270    270   Le RAID fête son quart de siècle et peut envi...  ...   1.818718   True\n",
              "\n",
              "[271 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4-NN0erngfv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "merged_results=result[['index','index_df','Texte','returned_labels','model_pred','one_score','max_score','WF']].merge(df[['Id','sexe']],how='left',left_on='index_df',right_on='Id')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKNslucdok9J",
        "colab_type": "code",
        "outputId": "261fc530-39ae-4127-c4d9-9de1339295da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Which texts failed ? \n",
        "print('{0:.2f} percent of the development texts were not well classified by our model'.format(result[result.WF==False].WF.count()*100/len(result)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "41.33 percent of the development texts were not well classified by our model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5MI09GF4yuR",
        "colab_type": "code",
        "outputId": "13ea02f6-dd5f-49a2-ca7e-f2875134cd7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "merged_results"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>index_df</th>\n",
              "      <th>Texte</th>\n",
              "      <th>returned_labels</th>\n",
              "      <th>model_pred</th>\n",
              "      <th>one_score</th>\n",
              "      <th>max_score</th>\n",
              "      <th>WF</th>\n",
              "      <th>Id</th>\n",
              "      <th>sexe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>173030</td>\n",
              "      <td>Monsieur le Député, après douze jours d'inqui...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.061862</td>\n",
              "      <td>1.105137</td>\n",
              "      <td>False</td>\n",
              "      <td>173030</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>173030</td>\n",
              "      <td>C'est aussi, vous l'avez souligné Monsieur le...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.534817</td>\n",
              "      <td>0.521251</td>\n",
              "      <td>False</td>\n",
              "      <td>173030</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>173030</td>\n",
              "      <td>L'objectif était alors de les réconforter et ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.292707</td>\n",
              "      <td>1.359186</td>\n",
              "      <td>False</td>\n",
              "      <td>173030</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>173030</td>\n",
              "      <td>Je salue également les autorités nigérianes q...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.711271</td>\n",
              "      <td>1.846850</td>\n",
              "      <td>False</td>\n",
              "      <td>173030</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>173030</td>\n",
              "      <td>Que ce soit dans le golfe de Guinée, dans les...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.268483</td>\n",
              "      <td>1.347814</td>\n",
              "      <td>False</td>\n",
              "      <td>173030</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>266</th>\n",
              "      <td>266</td>\n",
              "      <td>179250</td>\n",
              "      <td>(3) Je n'oublie pas non plus que, durant ces ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.940289</td>\n",
              "      <td>0.940289</td>\n",
              "      <td>False</td>\n",
              "      <td>179250</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>267</th>\n",
              "      <td>267</td>\n",
              "      <td>179250</td>\n",
              "      <td>J'étais, hier, à Chamonix pour rendre hommage...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.797531</td>\n",
              "      <td>1.923270</td>\n",
              "      <td>True</td>\n",
              "      <td>179250</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>268</th>\n",
              "      <td>268</td>\n",
              "      <td>179250</td>\n",
              "      <td>Mesdames et Messieurs,Cette journée est une n...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.578052</td>\n",
              "      <td>0.578052</td>\n",
              "      <td>False</td>\n",
              "      <td>179250</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>269</th>\n",
              "      <td>269</td>\n",
              "      <td>179250</td>\n",
              "      <td>En incarnant la quintessence même des valeurs...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.544272</td>\n",
              "      <td>1.646882</td>\n",
              "      <td>True</td>\n",
              "      <td>179250</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270</th>\n",
              "      <td>270</td>\n",
              "      <td>179250</td>\n",
              "      <td>Le RAID fête son quart de siècle et peut envi...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.693378</td>\n",
              "      <td>1.818718</td>\n",
              "      <td>True</td>\n",
              "      <td>179250</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>271 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     index  index_df  ...      Id  sexe\n",
              "0        0    173030  ...  173030     1\n",
              "1        1    173030  ...  173030     1\n",
              "2        2    173030  ...  173030     1\n",
              "3        3    173030  ...  173030     1\n",
              "4        4    173030  ...  173030     1\n",
              "..     ...       ...  ...     ...   ...\n",
              "266    266    179250  ...  179250     0\n",
              "267    267    179250  ...  179250     0\n",
              "268    268    179250  ...  179250     0\n",
              "269    269    179250  ...  179250     0\n",
              "270    270    179250  ...  179250     0\n",
              "\n",
              "[271 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4z2lKZyoYf4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "top_sentence_true=merged_results[merged_results.WF==1].nlargest(1,'max_score')\n",
        "top_sentence_false=merged_results[merged_results.WF==0].nlargest(1,'max_score')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpMkyg35qUnF",
        "colab_type": "code",
        "outputId": "850c51ae-8790-40b7-ede8-81fa5f06ade0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "top_sentence_false"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>index_df</th>\n",
              "      <th>Texte</th>\n",
              "      <th>returned_labels</th>\n",
              "      <th>model_pred</th>\n",
              "      <th>one_score</th>\n",
              "      <th>max_score</th>\n",
              "      <th>WF</th>\n",
              "      <th>Id</th>\n",
              "      <th>sexe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>32</td>\n",
              "      <td>207653</td>\n",
              "      <td>Je souhaite par ailleurs que vous soyez dorén...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.46695</td>\n",
              "      <td>2.46695</td>\n",
              "      <td>False</td>\n",
              "      <td>207653</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    index  index_df  ...      Id  sexe\n",
              "32     32    207653  ...  207653     0\n",
              "\n",
              "[1 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDqBRQHAqTog",
        "colab_type": "code",
        "outputId": "a74537d4-9d3f-4796-a5bf-42714f340d2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "top_sentence_true"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>index_df</th>\n",
              "      <th>Texte</th>\n",
              "      <th>returned_labels</th>\n",
              "      <th>model_pred</th>\n",
              "      <th>one_score</th>\n",
              "      <th>max_score</th>\n",
              "      <th>WF</th>\n",
              "      <th>Id</th>\n",
              "      <th>sexe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>93</td>\n",
              "      <td>176000</td>\n",
              "      <td>Ce sujet, qui est celui de la reconstruction ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.40031</td>\n",
              "      <td>2.571011</td>\n",
              "      <td>True</td>\n",
              "      <td>176000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    index  index_df  ...      Id  sexe\n",
              "93     93    176000  ...  176000     0\n",
              "\n",
              "[1 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOaXe4-K1GjQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WASb-HY_wewg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words_to_analyse = pd.concat([top_sentence_false,top_sentence_true]).reset_index(drop=True)\n",
        "words_to_analyse=split_document_to_limit(1,words_to_analyse)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBYBn5Ekay5F",
        "colab_type": "code",
        "outputId": "42276014-7f07-4597-b386-355c38b390ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "words_to_analyse"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index_df</th>\n",
              "      <th>sexe</th>\n",
              "      <th>Texte</th>\n",
              "      <th>Length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>207653</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>207653</td>\n",
              "      <td>0</td>\n",
              "      <td>souhaite</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>207653</td>\n",
              "      <td>0</td>\n",
              "      <td>ailleurs</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>207653</td>\n",
              "      <td>0</td>\n",
              "      <td>vous</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>207653</td>\n",
              "      <td>0</td>\n",
              "      <td>dorénavant</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>207653</td>\n",
              "      <td>0</td>\n",
              "      <td>sous</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>207653</td>\n",
              "      <td>0</td>\n",
              "      <td>des</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>207653</td>\n",
              "      <td>0</td>\n",
              "      <td>sages-femmes,</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>207653</td>\n",
              "      <td>0</td>\n",
              "      <td>chef</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>207653</td>\n",
              "      <td>0</td>\n",
              "      <td>service</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>207653</td>\n",
              "      <td>0</td>\n",
              "      <td>du</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>207653</td>\n",
              "      <td>0</td>\n",
              "      <td>de</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>207653</td>\n",
              "      <td>0</td>\n",
              "      <td>et</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>207653</td>\n",
              "      <td>0</td>\n",
              "      <td>la</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>207653</td>\n",
              "      <td>0</td>\n",
              "      <td>de</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>207653</td>\n",
              "      <td>0</td>\n",
              "      <td>profession</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>207653</td>\n",
              "      <td>0</td>\n",
              "      <td>assurée</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>207653</td>\n",
              "      <td>0</td>\n",
              "      <td>la</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>207653</td>\n",
              "      <td>0</td>\n",
              "      <td>des</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>207653</td>\n",
              "      <td>0</td>\n",
              "      <td>médicales</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>207653</td>\n",
              "      <td>0</td>\n",
              "      <td>l'établissement</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>176000</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>176000</td>\n",
              "      <td>0</td>\n",
              "      <td>sujet,</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>176000</td>\n",
              "      <td>0</td>\n",
              "      <td>est</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>176000</td>\n",
              "      <td>0</td>\n",
              "      <td>de</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>176000</td>\n",
              "      <td>0</td>\n",
              "      <td>reconstruction</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>176000</td>\n",
              "      <td>0</td>\n",
              "      <td>de</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>176000</td>\n",
              "      <td>0</td>\n",
              "      <td>gouvernance</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>176000</td>\n",
              "      <td>0</td>\n",
              "      <td>ces</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>176000</td>\n",
              "      <td>0</td>\n",
              "      <td>est</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>176000</td>\n",
              "      <td>0</td>\n",
              "      <td>sujet</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>176000</td>\n",
              "      <td>0</td>\n",
              "      <td>pour</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>176000</td>\n",
              "      <td>0</td>\n",
              "      <td>crédibilité</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>176000</td>\n",
              "      <td>0</td>\n",
              "      <td>notre</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>176000</td>\n",
              "      <td>0</td>\n",
              "      <td>Mesdames</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>176000</td>\n",
              "      <td>0</td>\n",
              "      <td>Messieurs,</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>176000</td>\n",
              "      <td>0</td>\n",
              "      <td>le</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>176000</td>\n",
              "      <td>0</td>\n",
              "      <td>je</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>176000</td>\n",
              "      <td>0</td>\n",
              "      <td>suis</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>176000</td>\n",
              "      <td>0</td>\n",
              "      <td>dans</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>176000</td>\n",
              "      <td>0</td>\n",
              "      <td>rénovation</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>176000</td>\n",
              "      <td>0</td>\n",
              "      <td>notre</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    index_df  sexe            Texte  Length\n",
              "0     207653     0                        1\n",
              "1     207653     0         souhaite       1\n",
              "2     207653     0         ailleurs       1\n",
              "3     207653     0             vous       1\n",
              "4     207653     0       dorénavant       1\n",
              "5     207653     0             sous       1\n",
              "6     207653     0              des       1\n",
              "7     207653     0    sages-femmes,       1\n",
              "8     207653     0             chef       1\n",
              "9     207653     0          service       1\n",
              "10    207653     0               du       1\n",
              "11    207653     0               de       1\n",
              "12    207653     0               et       1\n",
              "13    207653     0               la       1\n",
              "14    207653     0               de       1\n",
              "15    207653     0       profession       1\n",
              "16    207653     0          assurée       1\n",
              "17    207653     0               la       1\n",
              "18    207653     0              des       1\n",
              "19    207653     0        médicales       1\n",
              "20    207653     0  l'établissement       1\n",
              "21    176000     0                        1\n",
              "22    176000     0           sujet,       1\n",
              "23    176000     0              est       1\n",
              "24    176000     0               de       1\n",
              "25    176000     0   reconstruction       1\n",
              "26    176000     0               de       1\n",
              "27    176000     0      gouvernance       1\n",
              "28    176000     0              ces       1\n",
              "29    176000     0              est       1\n",
              "30    176000     0            sujet       1\n",
              "31    176000     0             pour       1\n",
              "32    176000     0      crédibilité       1\n",
              "33    176000     0            notre       1\n",
              "34    176000     0         Mesdames       1\n",
              "35    176000     0       Messieurs,       1\n",
              "36    176000     0               le       1\n",
              "37    176000     0               je       1\n",
              "38    176000     0             suis       1\n",
              "39    176000     0             dans       1\n",
              "40    176000     0       rénovation       1\n",
              "41    176000     0            notre       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Psom5Gizsjr",
        "colab_type": "code",
        "outputId": "9a162255-985e-4023-de33-397874835622",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "dev_dataloader=dev_prepare_to_feed(words_to_analyse,max_length_value=3,batch_size_value=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Let's check for the first text indexes, attention masks and labels\n",
            " \n",
            "Original:  \n",
            "IDs: tensor([5, 6, 1])\n",
            "Attention masks: tensor([1, 1, 0])\n",
            "labels tensor(0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWOre462zer-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_pred,total_labels,total_logits =evaluation_loop(gender_model,dev_dataloader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVUVyNnnz5kr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extract the score for label 1 \n",
        "one_score = [el[1] for el in total_logits]\n",
        "max_score = np.max(total_logits,axis=1)\n",
        "# Put everything inside a dataframe\n",
        "results_dev=pd.DataFrame([total_labels,total_pred,one_score,max_score]).transpose()\n",
        "results_dev.columns=['returned_labels','model_pred','one_score','max_score']\n",
        "results_dev['WF']=pd.DataFrame([results_dev['model_pred']==results_dev['returned_labels']]).transpose()\n",
        "# Merge back with the text\n",
        "frames = [words_to_analyse[['Texte','sexe','index_df']].reset_index(), results_dev]\n",
        "result = pd.concat(frames,axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eY0huGw0z9pl",
        "colab_type": "code",
        "outputId": "816f17bd-f46b-47b3-d9b9-9a5430f50c1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "result"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Texte</th>\n",
              "      <th>sexe</th>\n",
              "      <th>index_df</th>\n",
              "      <th>returned_labels</th>\n",
              "      <th>model_pred</th>\n",
              "      <th>one_score</th>\n",
              "      <th>max_score</th>\n",
              "      <th>WF</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>207653</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.022262</td>\n",
              "      <td>-0.022262</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>souhaite</td>\n",
              "      <td>0</td>\n",
              "      <td>207653</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.022137</td>\n",
              "      <td>-0.022137</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>ailleurs</td>\n",
              "      <td>0</td>\n",
              "      <td>207653</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.021943</td>\n",
              "      <td>-0.021943</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>vous</td>\n",
              "      <td>0</td>\n",
              "      <td>207653</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.021103</td>\n",
              "      <td>-0.021103</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>dorénavant</td>\n",
              "      <td>0</td>\n",
              "      <td>207653</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.022120</td>\n",
              "      <td>-0.022120</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>sous</td>\n",
              "      <td>0</td>\n",
              "      <td>207653</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.022071</td>\n",
              "      <td>-0.022071</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>des</td>\n",
              "      <td>0</td>\n",
              "      <td>207653</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.022110</td>\n",
              "      <td>-0.022110</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>sages-femmes,</td>\n",
              "      <td>0</td>\n",
              "      <td>207653</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.022272</td>\n",
              "      <td>-0.022272</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>chef</td>\n",
              "      <td>0</td>\n",
              "      <td>207653</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.021611</td>\n",
              "      <td>-0.021611</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>service</td>\n",
              "      <td>0</td>\n",
              "      <td>207653</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.022001</td>\n",
              "      <td>-0.022001</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>du</td>\n",
              "      <td>0</td>\n",
              "      <td>207653</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.022017</td>\n",
              "      <td>-0.022017</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>de</td>\n",
              "      <td>0</td>\n",
              "      <td>207653</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.020978</td>\n",
              "      <td>-0.020978</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>et</td>\n",
              "      <td>0</td>\n",
              "      <td>207653</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.022257</td>\n",
              "      <td>-0.022257</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>la</td>\n",
              "      <td>0</td>\n",
              "      <td>207653</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.021553</td>\n",
              "      <td>-0.021553</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>de</td>\n",
              "      <td>0</td>\n",
              "      <td>207653</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.020978</td>\n",
              "      <td>-0.020978</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>profession</td>\n",
              "      <td>0</td>\n",
              "      <td>207653</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.022091</td>\n",
              "      <td>-0.022091</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>assurée</td>\n",
              "      <td>0</td>\n",
              "      <td>207653</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.022211</td>\n",
              "      <td>-0.022211</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>la</td>\n",
              "      <td>0</td>\n",
              "      <td>207653</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.021553</td>\n",
              "      <td>-0.021553</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>des</td>\n",
              "      <td>0</td>\n",
              "      <td>207653</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.022110</td>\n",
              "      <td>-0.022110</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>médicales</td>\n",
              "      <td>0</td>\n",
              "      <td>207653</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.021816</td>\n",
              "      <td>-0.021816</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20</td>\n",
              "      <td>l'établissement</td>\n",
              "      <td>0</td>\n",
              "      <td>207653</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.022146</td>\n",
              "      <td>-0.022146</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>21</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>176000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.022262</td>\n",
              "      <td>-0.022262</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>22</td>\n",
              "      <td>sujet,</td>\n",
              "      <td>0</td>\n",
              "      <td>176000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.021496</td>\n",
              "      <td>-0.021496</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>23</td>\n",
              "      <td>est</td>\n",
              "      <td>0</td>\n",
              "      <td>176000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.022119</td>\n",
              "      <td>-0.022119</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>24</td>\n",
              "      <td>de</td>\n",
              "      <td>0</td>\n",
              "      <td>176000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.020978</td>\n",
              "      <td>-0.020978</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>25</td>\n",
              "      <td>reconstruction</td>\n",
              "      <td>0</td>\n",
              "      <td>176000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.022210</td>\n",
              "      <td>-0.022210</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>26</td>\n",
              "      <td>de</td>\n",
              "      <td>0</td>\n",
              "      <td>176000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.020978</td>\n",
              "      <td>-0.020978</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>27</td>\n",
              "      <td>gouvernance</td>\n",
              "      <td>0</td>\n",
              "      <td>176000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.021977</td>\n",
              "      <td>-0.021977</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>28</td>\n",
              "      <td>ces</td>\n",
              "      <td>0</td>\n",
              "      <td>176000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.022007</td>\n",
              "      <td>-0.022007</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>29</td>\n",
              "      <td>est</td>\n",
              "      <td>0</td>\n",
              "      <td>176000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.022119</td>\n",
              "      <td>-0.022119</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>30</td>\n",
              "      <td>sujet</td>\n",
              "      <td>0</td>\n",
              "      <td>176000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.021496</td>\n",
              "      <td>-0.021496</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>31</td>\n",
              "      <td>pour</td>\n",
              "      <td>0</td>\n",
              "      <td>176000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.021750</td>\n",
              "      <td>-0.021750</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>32</td>\n",
              "      <td>crédibilité</td>\n",
              "      <td>0</td>\n",
              "      <td>176000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.022082</td>\n",
              "      <td>-0.022082</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>33</td>\n",
              "      <td>notre</td>\n",
              "      <td>0</td>\n",
              "      <td>176000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.022191</td>\n",
              "      <td>-0.022191</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>34</td>\n",
              "      <td>Mesdames</td>\n",
              "      <td>0</td>\n",
              "      <td>176000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.021963</td>\n",
              "      <td>-0.021963</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>35</td>\n",
              "      <td>Messieurs,</td>\n",
              "      <td>0</td>\n",
              "      <td>176000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.022156</td>\n",
              "      <td>-0.022156</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>36</td>\n",
              "      <td>le</td>\n",
              "      <td>0</td>\n",
              "      <td>176000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.021482</td>\n",
              "      <td>-0.021482</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>37</td>\n",
              "      <td>je</td>\n",
              "      <td>0</td>\n",
              "      <td>176000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.022094</td>\n",
              "      <td>-0.022094</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>38</td>\n",
              "      <td>suis</td>\n",
              "      <td>0</td>\n",
              "      <td>176000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.021706</td>\n",
              "      <td>-0.021706</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>39</td>\n",
              "      <td>dans</td>\n",
              "      <td>0</td>\n",
              "      <td>176000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.022218</td>\n",
              "      <td>-0.022218</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>40</td>\n",
              "      <td>rénovation</td>\n",
              "      <td>0</td>\n",
              "      <td>176000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.022238</td>\n",
              "      <td>-0.022238</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>41</td>\n",
              "      <td>notre</td>\n",
              "      <td>0</td>\n",
              "      <td>176000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.022191</td>\n",
              "      <td>-0.022191</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    index            Texte  sexe  ...  one_score  max_score     WF\n",
              "0       0                      0  ...  -0.022262  -0.022262  False\n",
              "1       1         souhaite     0  ...  -0.022137  -0.022137  False\n",
              "2       2         ailleurs     0  ...  -0.021943  -0.021943  False\n",
              "3       3             vous     0  ...  -0.021103  -0.021103  False\n",
              "4       4       dorénavant     0  ...  -0.022120  -0.022120  False\n",
              "5       5             sous     0  ...  -0.022071  -0.022071  False\n",
              "6       6              des     0  ...  -0.022110  -0.022110  False\n",
              "7       7    sages-femmes,     0  ...  -0.022272  -0.022272  False\n",
              "8       8             chef     0  ...  -0.021611  -0.021611  False\n",
              "9       9          service     0  ...  -0.022001  -0.022001  False\n",
              "10     10               du     0  ...  -0.022017  -0.022017  False\n",
              "11     11               de     0  ...  -0.020978  -0.020978  False\n",
              "12     12               et     0  ...  -0.022257  -0.022257  False\n",
              "13     13               la     0  ...  -0.021553  -0.021553  False\n",
              "14     14               de     0  ...  -0.020978  -0.020978  False\n",
              "15     15       profession     0  ...  -0.022091  -0.022091  False\n",
              "16     16          assurée     0  ...  -0.022211  -0.022211  False\n",
              "17     17               la     0  ...  -0.021553  -0.021553  False\n",
              "18     18              des     0  ...  -0.022110  -0.022110  False\n",
              "19     19        médicales     0  ...  -0.021816  -0.021816  False\n",
              "20     20  l'établissement     0  ...  -0.022146  -0.022146  False\n",
              "21     21                      0  ...  -0.022262  -0.022262  False\n",
              "22     22           sujet,     0  ...  -0.021496  -0.021496  False\n",
              "23     23              est     0  ...  -0.022119  -0.022119  False\n",
              "24     24               de     0  ...  -0.020978  -0.020978  False\n",
              "25     25   reconstruction     0  ...  -0.022210  -0.022210  False\n",
              "26     26               de     0  ...  -0.020978  -0.020978  False\n",
              "27     27      gouvernance     0  ...  -0.021977  -0.021977  False\n",
              "28     28              ces     0  ...  -0.022007  -0.022007  False\n",
              "29     29              est     0  ...  -0.022119  -0.022119  False\n",
              "30     30            sujet     0  ...  -0.021496  -0.021496  False\n",
              "31     31             pour     0  ...  -0.021750  -0.021750  False\n",
              "32     32      crédibilité     0  ...  -0.022082  -0.022082  False\n",
              "33     33            notre     0  ...  -0.022191  -0.022191  False\n",
              "34     34         Mesdames     0  ...  -0.021963  -0.021963  False\n",
              "35     35       Messieurs,     0  ...  -0.022156  -0.022156  False\n",
              "36     36               le     0  ...  -0.021482  -0.021482  False\n",
              "37     37               je     0  ...  -0.022094  -0.022094  False\n",
              "38     38             suis     0  ...  -0.021706  -0.021706  False\n",
              "39     39             dans     0  ...  -0.022218  -0.022218  False\n",
              "40     40       rénovation     0  ...  -0.022238  -0.022238  False\n",
              "41     41            notre     0  ...  -0.022191  -0.022191  False\n",
              "\n",
              "[42 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFVzNZ63jWkT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scores = [i for i in result[result.index_df==176000].one_score]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVYqMaNr0nyA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_plot=pd.DataFrame(scores).transpose()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54dbId7RmuG5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_plot.columns=list(result[result.index_df==176000].Texte)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qG46EmH31oFQ",
        "colab_type": "code",
        "outputId": "5986dddb-18c4-465a-ee75-ad80733fbda3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "source": [
        "df_plot"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>sujet,</th>\n",
              "      <th>est</th>\n",
              "      <th>de</th>\n",
              "      <th>reconstruction</th>\n",
              "      <th>de</th>\n",
              "      <th>gouvernance</th>\n",
              "      <th>ces</th>\n",
              "      <th>est</th>\n",
              "      <th>sujet</th>\n",
              "      <th>pour</th>\n",
              "      <th>crédibilité</th>\n",
              "      <th>notre</th>\n",
              "      <th>Mesdames</th>\n",
              "      <th>Messieurs,</th>\n",
              "      <th>le</th>\n",
              "      <th>je</th>\n",
              "      <th>suis</th>\n",
              "      <th>dans</th>\n",
              "      <th>rénovation</th>\n",
              "      <th>notre</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.022262</td>\n",
              "      <td>-0.021496</td>\n",
              "      <td>-0.022119</td>\n",
              "      <td>-0.020978</td>\n",
              "      <td>-0.02221</td>\n",
              "      <td>-0.020978</td>\n",
              "      <td>-0.021977</td>\n",
              "      <td>-0.022007</td>\n",
              "      <td>-0.022119</td>\n",
              "      <td>-0.021496</td>\n",
              "      <td>-0.02175</td>\n",
              "      <td>-0.022082</td>\n",
              "      <td>-0.022191</td>\n",
              "      <td>-0.021963</td>\n",
              "      <td>-0.022156</td>\n",
              "      <td>-0.021482</td>\n",
              "      <td>-0.022094</td>\n",
              "      <td>-0.021706</td>\n",
              "      <td>-0.022218</td>\n",
              "      <td>-0.022238</td>\n",
              "      <td>-0.022191</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               sujet,       est  ...      dans  rénovation     notre\n",
              "0 -0.022262 -0.021496 -0.022119  ... -0.022218   -0.022238 -0.022191\n",
              "\n",
              "[1 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 242
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilmXHJJcloMK",
        "colab_type": "code",
        "outputId": "5b827dd2-4d11-40f5-91b7-d5d46a994643",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        " \n",
        "# Default heatmap: just a visualization of this square matrix\n",
        "fig, ax = plt.subplots(figsize=(20,4)) \n",
        "sns.heatmap(df_plot)\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABEQAAAFrCAYAAADYR1xnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIZz71hoZfAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1440x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VXzb-ayoB-o",
        "colab_type": "text"
      },
      "source": [
        "Faire des annotations pour la fin du doc et nettoyer mettre en forme\n",
        "Faire des fonctions pour la fin \n",
        "Amélioer le graphique . Est ce que c'est intelligent par mot ? \n",
        "Remplacer score max par la moyenne des logits à chercher à la fin du train \n",
        "Analyser un peu et mettre au propre sur la feuille\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0y8QmbT881P",
        "colab_type": "text"
      },
      "source": [
        "# Test "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcm-GKcwhXdd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "cf5d5fad-3966-48e9-899b-0d60f40645a2"
      },
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>index_df</th>\n",
              "      <th>sexe</th>\n",
              "      <th>Texte</th>\n",
              "      <th>Length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8844</td>\n",
              "      <td>163979</td>\n",
              "      <td>0</td>\n",
              "      <td>163979</td>\n",
              "      <td>444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3971</td>\n",
              "      <td>192898</td>\n",
              "      <td>1</td>\n",
              "      <td>192898</td>\n",
              "      <td>443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1813</td>\n",
              "      <td>191962</td>\n",
              "      <td>1</td>\n",
              "      <td>191962</td>\n",
              "      <td>439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2254</td>\n",
              "      <td>147466</td>\n",
              "      <td>1</td>\n",
              "      <td>147466</td>\n",
              "      <td>403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1704</td>\n",
              "      <td>173140</td>\n",
              "      <td>1</td>\n",
              "      <td>173140</td>\n",
              "      <td>419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11192</th>\n",
              "      <td>3655</td>\n",
              "      <td>175003</td>\n",
              "      <td>1</td>\n",
              "      <td>175003</td>\n",
              "      <td>208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11193</th>\n",
              "      <td>1661</td>\n",
              "      <td>180667</td>\n",
              "      <td>1</td>\n",
              "      <td>180667</td>\n",
              "      <td>429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11194</th>\n",
              "      <td>2139</td>\n",
              "      <td>205519</td>\n",
              "      <td>1</td>\n",
              "      <td>205519</td>\n",
              "      <td>229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11195</th>\n",
              "      <td>7491</td>\n",
              "      <td>185081</td>\n",
              "      <td>0</td>\n",
              "      <td>185081</td>\n",
              "      <td>428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11196</th>\n",
              "      <td>9056</td>\n",
              "      <td>170313</td>\n",
              "      <td>0</td>\n",
              "      <td>170313</td>\n",
              "      <td>442</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11197 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       index  index_df  sexe   Texte  Length\n",
              "0       8844    163979     0  163979     444\n",
              "1       3971    192898     1  192898     443\n",
              "2       1813    191962     1  191962     439\n",
              "3       2254    147466     1  147466     403\n",
              "4       1704    173140     1  173140     419\n",
              "...      ...       ...   ...     ...     ...\n",
              "11192   3655    175003     1  175003     208\n",
              "11193   1661    180667     1  180667     429\n",
              "11194   2139    205519     1  205519     229\n",
              "11195   7491    185081     0  185081     428\n",
              "11196   9056    170313     0  170313     442\n",
              "\n",
              "[11197 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91XKOBnfBOOu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Camembert tokenizer\n",
        "from transformers import CamembertTokenizer\n",
        "# We choose a right padding side for the moment and we will test for a left padding side on a second stage\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-base', do_lower_case=False,padding_side='right') #left"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlQ0-CCQ-mPy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "d1f3cab7-0684-42b4-a451-0076a6802a3d"
      },
      "source": [
        "\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "texts = df_balanced_split.Texte.values\n",
        "labels = df_balanced_split.sexe.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "num_truncated_tokens =[]\n",
        "# Apply function to our corpus\n",
        "for text in texts:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        text,                      # text\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 500,           # We choose for now a max length of 500.\n",
        "                        pad_to_max_length = True,    # Pad text to max (marche pas en pad left ?)\n",
        "                        return_attention_mask = True,   # Construct attention masks\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                        return_overflowing_tokens =True, # return overflowing token information\n",
        "                  )\n",
        "    \n",
        "    # Map tokens to their id in the dictionnary \n",
        "    # We add this to our list    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "    #num_truncated_tokens.append(encoded_dict['num_truncated_tokens'])\n",
        "    \n",
        "    # 3. Attention masks\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# We convert all this into tensors in order to be able to make it work on GPU \n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Original text and transformed tensor print \n",
        "print(\"Let's check for the first text indexes, attention masks and labels\")\n",
        "print(\" \")\n",
        "print('Original: ', texts[0][0:100])\n",
        "print('IDs:', input_ids[0][0:100])\n",
        "print('Attention masks:', attention_masks[0][0:100])\n",
        "print('labels',labels[0])\n",
        "\n",
        "\n",
        "# Combine all above\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Let's create a 80-20 train / validation dataset \n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_set, val_set = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "\n",
        "print(\"-------------------------------------------------\")\n",
        "print(\" \")\n",
        "print(\"How many texts do we have in the train and validation sample ? \")\n",
        "print(\" \")\n",
        "print('We have {} training texts'.format(train_size))\n",
        "print('We have {} validation texts'.format(val_size))\n",
        "print(\" \")\n",
        "print(\"-------------------------------------------------\")\n",
        "\n",
        "# We set the size of the batch ( usually set around 16 or 32), we will take the lower bound because of the large text length\n",
        "batch_size = 16\n",
        "\n",
        "# We create data loaders for the train and validation dataset. \n",
        "train_dataloader = DataLoader(\n",
        "            train_set,  # The training samples.\n",
        "            sampler = RandomSampler(train_set), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "val_dataloader = DataLoader(\n",
        "            val_set, # The validation samples.\n",
        "            sampler = SequentialSampler(val_set), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n",
        "\n",
        "print('Data loaders created for train [0] and val [1]')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Let's check for the first text indexes, attention masks and labels\n",
            " \n",
            "Original:  la spécialisation des navires ; un nombre supérieur de moyens d'observation, de communication et de \n",
            "IDs: tensor([    5,    13, 20831,    20, 11013,   167,    23,   365,  2062,     8,\n",
            "         1149,    18,    11,  7064,     7,     8,  1006,    14,     8,  9888,\n",
            "          167,     8,   704,  1979,    18,    11,  7781,   167,    20,  3768,\n",
            "           18,    11,  3064, 12914, 17441, 19963,    80,    24,    98,    22,\n",
            "          586,    18,    11,  4976,  6916,    36,   731,     8, 12463,    10,\n",
            "            7,    22,    21, 14319,    17,    11,   649,    20,   592, 10424,\n",
            "           37,    19,   678, 13957,     8,  1983, 16111,   167,    13,  2966,\n",
            "            7,   743,     7,    18,    11,  2688,    13,  9157,   128,    20,\n",
            "        11013,    14,  1979,    18,    11,  7781,  4993,    14,    18,    11,\n",
            "          266,    40,  2294,     7,    66,    22, 26634,   172,    16,  1984])\n",
            "Attention masks: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1])\n",
            "labels tensor(0)\n",
            "-------------------------------------------------\n",
            " \n",
            "How many texts do we have in the train and validation sample ? \n",
            " \n",
            "We have 8984 training texts\n",
            "We have 2247 validation texts\n",
            " \n",
            "-------------------------------------------------\n",
            "Data loaders created for train [0] and val [1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRKOBglK-06f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "outputId": "f76b7748-6546-499b-d852-be591d50a93e"
      },
      "source": [
        "results_unbalanced = train_val_gendermodel(train_loader=train_dataloader, val_loader=val_dataloader, epochs_val=5,seed_val=2020,device=device,lr_value=5e-5)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===========Starting Epoch 1 / 5 ==============\n",
            "Training starts\n",
            "\n",
            "  Average training loss: 0.51\n",
            "\n",
            "Validation starts\n",
            "  Accuracy: 0.80\n",
            "  F1_score: 0.80\n",
            "  Validation Loss: 0.43\n",
            "===========Starting Epoch 2 / 5 ==============\n",
            "Training starts\n",
            "\n",
            "  Average training loss: 0.36\n",
            "\n",
            "Validation starts\n",
            "  Accuracy: 0.82\n",
            "  F1_score: 0.81\n",
            "  Validation Loss: 0.41\n",
            "===========Starting Epoch 3 / 5 ==============\n",
            "Training starts\n",
            "\n",
            "  Average training loss: 0.23\n",
            "\n",
            "Validation starts\n",
            "  Accuracy: 0.84\n",
            "  F1_score: 0.83\n",
            "  Validation Loss: 0.49\n",
            "===========Starting Epoch 4 / 5 ==============\n",
            "Training starts\n",
            "\n",
            "  Average training loss: 0.13\n",
            "\n",
            "Validation starts\n",
            "  Accuracy: 0.83\n",
            "  F1_score: 0.83\n",
            "  Validation Loss: 0.66\n",
            "===========Starting Epoch 5 / 5 ==============\n",
            "Training starts\n",
            "\n",
            "  Average training loss: 0.06\n",
            "\n",
            "Validation starts\n",
            "  Accuracy: 0.82\n",
            "  F1_score: 0.81\n",
            "  Validation Loss: 0.79\n",
            "\n",
            "Done !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BP1MLFt__WF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "outputId": "e3596c87-ff1a-4145-a4db-e8f19818a09d"
      },
      "source": [
        "report_model_1(results_unbalanced)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       Train Loss  Val Loss  Val Accur.    Val F1\n",
            "epoch                                            \n",
            "1        0.506192  0.425347    0.798632  0.800964\n",
            "2        0.359642  0.408357    0.819022  0.813722\n",
            "3        0.229572  0.491328    0.836753  0.833890\n",
            "4        0.132649  0.656070    0.827001  0.826271\n",
            "5        0.060629  0.793369    0.823582  0.813131\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuUAAAGaCAYAAACopj13AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCYyhnIiIiIhIYAzlREREREQC+/8BkrD8EctxWt8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dio-RzsWERPJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "62dee7c0-f9cf-4907-8828-dcb6b17d2861"
      },
      "source": [
        "############################  IMPORT MODEL ################################################\n",
        "from transformers import CamembertForSequenceClassification\n",
        "gender_model = CamembertForSequenceClassification.from_pretrained(\n",
        "  \"camembert-base\", \n",
        "  num_labels = 2, # We have two different labels Women = 1 and Men =0   \n",
        "  output_attentions = False, \n",
        "  output_hidden_states = False, )\n",
        "\n",
        "model = gender_model\n",
        "model.cuda()\n",
        "\n",
        "lr_value = 5e-5\n",
        "train_loader=train_dataloader\n",
        "val_loader=val_dataloader\n",
        "epochs_val=3\n",
        "seed_val=2020\n",
        "device=device\n",
        "lr_value=5e-5\n",
        "\n",
        "############################## RANDOM SEED ##################################################\n",
        "\n",
        "import random\n",
        "# Let's put a seed to make this result reproducible \n",
        "seed=seed_val\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "############################### LEARNING RATE SCHEDULER #######################################\n",
        "\n",
        "# https://huggingface.co/transformers/migration.html \n",
        "# https://pytorch.org/docs/stable/optim.html (default values)\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from transformers import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs = epochs_val # In order to fine tune our model we will first set the number of epochs to 4.\n",
        "\n",
        "# We choose Binary cross enthropy with logits loss for the loss computation. It seems to be the most adapted loss to our problem. \n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "#Implements Adam algorithm with weight decay fix.\n",
        "opti = AdamW(model.parameters(),\n",
        "                  lr =lr_value, # learning rate (default = 1e-3)\n",
        "                  eps = 1e-8 # prevents division by 0 (default = 1e-8)\n",
        "                )\n",
        "\n",
        "num_training_steps = len(train_loader) * epochs\n",
        "# Create a schedule with a learning rate that decreases linearly after linearly increasing during a warmup period (0 here)\n",
        "scheduler = get_linear_schedule_with_warmup(opti, \n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = num_training_steps)\n",
        "\n",
        "\n",
        "# We want to evaluate the training phase \n",
        "training_stats = []\n",
        "\n",
        "for ep in range(0, epochs):\n",
        "  print('===========Starting Epoch {} / {} =============='.format(ep+1,epochs))\n",
        "  print('Training starts')\n",
        "\n",
        "  ################################### TRAINING ################################\n",
        "\n",
        "  #Put the model in training mode\n",
        "  model.train()\n",
        "\n",
        "  # Set the train loss for the epoch to 0 \n",
        "  total_train_loss = 0\n",
        "\n",
        "  for step, batch in enumerate(train_loader):\n",
        "    # Clear gradients \n",
        "    model.zero_grad() # (opti.zerograd ? )\n",
        "\n",
        "    # Cpy the 3 batch to GPU \n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "    \n",
        "    #return loss and logits\n",
        "    loss, logits = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask, \n",
        "                        labels=b_labels) \n",
        "    \n",
        "    # Accumulate training loss for all batches \n",
        "    total_train_loss += loss.item()\n",
        "\n",
        "    #Backpropagating the gradients \n",
        "    loss.backward()\n",
        "\n",
        "    # Prevent exploding gradients problem  (forcing the gradients to be small, the parameter updates will not push the parameters too far from their previous values)\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "    # Update parameters \n",
        "    opti.step()\n",
        "\n",
        "    # Update learning rate schedule\n",
        "    scheduler.step()\n",
        "\n",
        "  #Calculate the average training loss over all batches  \n",
        "  avg_train_loss = total_train_loss / len(train_loader)\n",
        "  print(\"\")\n",
        "  print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "  print('')\n",
        "  print('Validation starts')\n",
        "\n",
        "  ###################### VALIDATION #############################\n",
        "\n",
        "  # Put model in evaluation mode \n",
        "  model.eval()\n",
        "\n",
        "  # Set statistics to 0\n",
        "  total_eval_accuracy = 0\n",
        "  total_eval_loss = 0\n",
        "  nb_eval_steps = 0\n",
        "  total_eval_f1=0\n",
        "  total_roc_auc = 0 \n",
        "\n",
        "  # Confusion matrix ?\n",
        "  predictions, true_labels = [], []\n",
        "\n",
        "  for batch in val_loader:\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "    \n",
        "    # We don't care about gradients for eval\n",
        "\n",
        "    with torch.no_grad(): \n",
        "      (loss, logits) = model(b_input_ids, \n",
        "                                token_type_ids=None, \n",
        "                                attention_mask=b_input_mask,\n",
        "                                labels=b_labels)\n",
        "    total_eval_loss += loss.item()\n",
        "\n",
        "      # Move logits and labels to CPU \n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    F1_score, Accuracy = create_report(label_ids,logits)\n",
        "\n",
        "    # Accumulation accuracy for all batch\n",
        "    total_eval_accuracy += Accuracy\n",
        "\n",
        "    # Accumulation f1 for all batch\n",
        "    total_eval_f1 += F1_score\n",
        "    \n",
        "    #Final accuracy on all batch\n",
        "  avg_val_accuracy = total_eval_accuracy / len(val_loader)\n",
        "  print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "\n",
        "    #Final f1 on all batch\n",
        "  avg_val_f1 = total_eval_f1 / len(val_loader)\n",
        "  print(\"  F1_score: {0:.2f}\".format(avg_val_f1))\n",
        "\n",
        "    #Final loss over all batch\n",
        "  avg_val_loss = total_eval_loss / len(val_loader)\n",
        "  print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "\n",
        "  training_stats.append(\n",
        "        {\n",
        "            'epoch': ep + 1,\n",
        "            'Train Loss': avg_train_loss,\n",
        "            'Val Loss': avg_val_loss,\n",
        "            'Val Accur.': avg_val_accuracy,\n",
        "            'Val F1' : avg_val_f1,\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Done !\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===========Starting Epoch 1 / 3 ==============\n",
            "Training starts\n",
            "\n",
            "  Average training loss: 0.51\n",
            "\n",
            "Validation starts\n",
            "  Accuracy: 0.85\n",
            "  F1_score: 0.52\n",
            "  Validation Loss: 0.43\n",
            "===========Starting Epoch 2 / 3 ==============\n",
            "Training starts\n",
            "\n",
            "  Average training loss: 0.36\n",
            "\n",
            "Validation starts\n",
            "  Accuracy: 0.86\n",
            "  F1_score: 0.62\n",
            "  Validation Loss: 0.34\n",
            "===========Starting Epoch 3 / 3 ==============\n",
            "Training starts\n",
            "\n",
            "  Average training loss: 0.27\n",
            "\n",
            "Validation starts\n",
            "  Accuracy: 0.83\n",
            "  F1_score: 0.61\n",
            "  Validation Loss: 0.40\n",
            "\n",
            "Done !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxVq-YlRE9CM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "outputId": "af7427f6-6d14-4bcc-a1c3-fb7442ee5d55"
      },
      "source": [
        "report_model_1(results_unbalanced)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       Train Loss  Val Loss  Val Accur.    Val F1  accur 2 \n",
            "epoch                                                      \n",
            "1        0.486057  0.393362      0.8500  0.502009    0.8500\n",
            "2        0.340707  0.359600      0.8525  0.507469    0.8525\n",
            "3        0.244166  0.372269      0.8650  0.637284    0.8650\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvUAAAGaCAYAAACPCLyfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce6txgQ2K_w4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "c6cb95ad-b005-403f-98a4-660882295964"
      },
      "source": [
        "results_unbalanced = train_val_gendermodel(train_loader=train_loader_unbalanced, val_loader=val_loader_unbalanced, epochs_val=3,seed_val=2020,device=device,lr_value=5e-5)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===========Starting Epoch 1 / 3 ==============\n",
            "Training starts\n",
            "\n",
            "  Average training loss: 0.65\n",
            "\n",
            "Validation starts\n",
            "  Accuracy: 0.76\n",
            "  Accuracy: 0.76\n",
            "  F1_score: 0.60\n",
            "  Validation Loss: 0.60\n",
            "===========Starting Epoch 2 / 3 ==============\n",
            "Training starts\n",
            "\n",
            "  Average training loss: 0.66\n",
            "\n",
            "Validation starts\n",
            "  Accuracy: 0.76\n",
            "  Accuracy: 0.76\n",
            "  F1_score: 0.60\n",
            "  Validation Loss: 0.65\n",
            "===========Starting Epoch 3 / 3 ==============\n",
            "Training starts\n",
            "\n",
            "  Average training loss: 0.66\n",
            "\n",
            "Validation starts\n",
            "  Accuracy: 0.76\n",
            "  Accuracy: 0.76\n",
            "  F1_score: 0.60\n",
            "  Validation Loss: 0.61\n",
            "\n",
            "Done !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qpPcQQGJEDi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PROBLEM DANS LE LOAD "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfzCuPwtS6zj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "51c498bf-1e57-41c8-c7b6-31a0f1afbb4a"
      },
      "source": [
        "\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "texts = df.Texte.values\n",
        "labels = df.sexe.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "num_truncated_tokens =[]\n",
        "# Apply function to our corpus\n",
        "for text in texts:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        text,                      # text\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = length,           # We choose for now a max length of 500.\n",
        "                        pad_to_max_length = True,    # Pad text to max (marche pas en pad left ?)\n",
        "                        return_attention_mask = True,   # Construct attention masks\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                        return_overflowing_tokens =True, # return overflowing token information\n",
        "                  )\n",
        "    \n",
        "    # Map tokens to their id in the dictionnary \n",
        "    # We add this to our list    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "    #num_truncated_tokens.append(encoded_dict['num_truncated_tokens'])\n",
        "    \n",
        "    # 3. Attention masks\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# We convert all this into tensors in order to be able to make it work on GPU \n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Original text and transformed tensor print \n",
        "print(\"Let's check for the first text indexes, attention masks and labels\")\n",
        "print(\" \")\n",
        "print('Original: ', texts[0][0:100])\n",
        "print('IDs:', input_ids[0][0:100])\n",
        "print('Attention masks:', attention_masks[0][0:100])\n",
        "print('labels',labels[0])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-e32eae3d3924>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Apply function to our corpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     encoded_dict = tokenizer.encode_plus(\n\u001b[0m\u001b[1;32m     15\u001b[0m                         \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m                      \u001b[0;31m# text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                         \u001b[0madd_special_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Add '[CLS]' and '[SEP]'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8rm-f74RAUy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Combine all above\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Let's create a 80-20 train / validation dataset \n",
        "train_size = int(length_train * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_set, val_set = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# We set the size of the batch ( usually set around 16 or 32), we will take the lower bound because of the large text length\n",
        "batch_size = batch_size_value\n",
        "\n",
        "# We create data loaders for the train and validation dataset. \n",
        "train_dataloader = DataLoader(\n",
        "            train_set,  # The training samples.\n",
        "            sampler = RandomSampler(train_set), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "val_dataloader = DataLoader(\n",
        "            val_set, # The validation samples.\n",
        "            sampler = SequentialSampler(val_set), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n",
        "\n",
        "print('Data loaders created for train [0] and val [1]')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZ98Lka2Yk25",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "8745feb9-b5ac-4727-8bc6-587c3ed1be30"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "texts = df.Texte.values\n",
        "labels = df.sexe.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "num_truncated_tokens =[]\n",
        "# Apply function to our corpus\n",
        "for text in texts:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        text,                      # text\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = length,           # We choose for now a max length of 500.\n",
        "                        pad_to_max_length = True,    # Pad text to max (marche pas en pad left ?)\n",
        "                        return_attention_mask = True,   # Construct attention masks\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                        return_overflowing_tokens =True, # return overflowing token information\n",
        "                  )\n",
        "    \n",
        "    # Map tokens to their id in the dictionnary \n",
        "    # We add this to our list    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "    #num_truncated_tokens.append(encoded_dict['num_truncated_tokens'])\n",
        "    \n",
        "    # 3. Attention masks\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-71c5979f61ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTexte\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msexe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Usyq-FsZWCz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}