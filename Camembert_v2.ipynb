{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Camembert_v2.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bfa563fb2d6443e0894ed08816d5b974": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c08f3ed0abd84de3832fadaa7e4b75b1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_039c70d812dc4b7896a553c584c96f3a",
              "IPY_MODEL_053bc6ebc758496d96e8e954ef4deaee"
            ]
          }
        },
        "c08f3ed0abd84de3832fadaa7e4b75b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "039c70d812dc4b7896a553c584c96f3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c884d616596e45d7ba711cb10766485f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 810912,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 810912,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_82abe9600920409eb04b867bec28c0ed"
          }
        },
        "053bc6ebc758496d96e8e954ef4deaee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_91651eaee8e04508897cb23d3d57d42c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 811k/811k [01:28&lt;00:00, 9.14kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7a92e992f92c4b50a40443bbac36dd95"
          }
        },
        "c884d616596e45d7ba711cb10766485f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "82abe9600920409eb04b867bec28c0ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "91651eaee8e04508897cb23d3d57d42c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7a92e992f92c4b50a40443bbac36dd95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8bb6a0e52c2047198f8a4d9c3ae19eb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_30841884dddf4ed7ad275a953866e63e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_600a4746d2b9467c97aae99648b2d9e1",
              "IPY_MODEL_e5f293761ebe4debad834b195e3b6009"
            ]
          }
        },
        "30841884dddf4ed7ad275a953866e63e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "600a4746d2b9467c97aae99648b2d9e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1b6772a63d7c484bbd5237c9872cb494",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 637,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 637,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d45421d926e842439e58771b52550e3c"
          }
        },
        "e5f293761ebe4debad834b195e3b6009": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_acabceebaa5d46bf8cf03da75107843f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 637/637 [00:00&lt;00:00, 2.01kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_08c2103c9b6947528e3124c4b27e9799"
          }
        },
        "1b6772a63d7c484bbd5237c9872cb494": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d45421d926e842439e58771b52550e3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "acabceebaa5d46bf8cf03da75107843f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "08c2103c9b6947528e3124c4b27e9799": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "522d1ae97de14f7cbe919a183b4ccdb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7a75f027dfbf40d3b563d58a757f5d0f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b8734ceb7db24503bf0d99a08f3a35af",
              "IPY_MODEL_10ed4e33740c4aa78f2f17f213986ee3"
            ]
          }
        },
        "7a75f027dfbf40d3b563d58a757f5d0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b8734ceb7db24503bf0d99a08f3a35af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_806516ece2ba41078b8dc7434c4b0b36",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 445032417,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 445032417,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a312e2a5d9124caa8311cf140640701c"
          }
        },
        "10ed4e33740c4aa78f2f17f213986ee3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6e592c8ebb864ff6bcfd4273b18468bf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 445M/445M [00:11&lt;00:00, 40.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_46e3157fa8fc4157b504b33d7b8441bc"
          }
        },
        "806516ece2ba41078b8dc7434c4b0b36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a312e2a5d9124caa8311cf140640701c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6e592c8ebb864ff6bcfd4273b18468bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "46e3157fa8fc4157b504b33d7b8441bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cerezamo/NLP_brouillon/blob/master/Camembert_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcxLW3uyHTSN",
        "colab_type": "text"
      },
      "source": [
        "# CamemBERT classification model \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bxA1IEgH-GI",
        "colab_type": "text"
      },
      "source": [
        "## Set up colab GPU and installing main packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1JD-Tb0HdvN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If you have the documents in your drive already otherwise just drag 'medium_df_desequ.csv' and 'funct.py' in the file section\n",
        "import os \n",
        "os.getcwd()\n",
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mF6Hs6yH2A5",
        "colab_type": "code",
        "outputId": "6d6f020d-d37a-441f-97c1-172033f425e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# First you should go in 'Edit' -> 'Notebook settings' -> Add device GPU\n",
        "import tensorflow as tf\n",
        "\n",
        "# GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "device_name"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ_F6NV3IaCY",
        "colab_type": "text"
      },
      "source": [
        "We now can tell torch that one GPU is available "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wr4fjemjIVoQ",
        "colab_type": "code",
        "outputId": "70bd7101-b544-4eea-e053-5a36fec88a45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9B5YK1cADhjj",
        "colab_type": "code",
        "outputId": "c1506268-71a4-4e7d-e5d3-daf5987e4c09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Apr  5 15:32:47 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    34W / 250W |    353MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_7DO-oiCZ7f",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "**Please check GPU capacity** that you were given. You might want to reduce the batch size further in the code.  Typically if you were given 8Go memory GPU (Tesla P4) you should set the batch size to 2 not more ! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGwjFzizIsMI",
        "colab_type": "text"
      },
      "source": [
        "We now install the Hugging Face library transformers. You can find all the documentation of hugging face in their Github : https://github.com/huggingface/transformers  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--g7cokfIrpT",
        "colab_type": "code",
        "outputId": "d3e5bf29-90a9-41db-8558-e6a87de3da63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "source": [
        "! pip install transformers "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/ba/dda44bbf35b071441635708a3dd568a5ca6bf29f77389f7c7c6818ae9498/transformers-2.7.0-py3-none-any.whl (544kB)\n",
            "\r\u001b[K     |▋                               | 10kB 8.7MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20kB 3.3MB/s eta 0:00:01\r\u001b[K     |█▉                              | 30kB 4.3MB/s eta 0:00:01\r\u001b[K     |██▍                             | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |███                             | 51kB 3.4MB/s eta 0:00:01\r\u001b[K     |███▋                            | 61kB 4.1MB/s eta 0:00:01\r\u001b[K     |████▏                           | 71kB 4.3MB/s eta 0:00:01\r\u001b[K     |████▉                           | 81kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 92kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████                          | 102kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 112kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 122kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 133kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 143kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████                       | 153kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 163kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 174kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 184kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 194kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 204kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 215kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 225kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 235kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 245kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 256kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 266kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 276kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 286kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 296kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 307kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 317kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 327kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 337kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 348kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 358kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 368kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 378kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 389kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 399kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 409kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 419kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 430kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 440kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 450kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 460kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 471kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 481kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 491kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 501kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 512kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 522kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 532kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 542kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 552kB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 20.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.33)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 58.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 52.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.33 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.33)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.33->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.33->boto3->transformers) (2.8.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=114e2408814933af23e29472c8afaba66c8fb999495f9563ac701107b079c06d\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4OKq8Z4JId9",
        "colab_type": "text"
      },
      "source": [
        "## Loading our corpus and preparing samples "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aGxDbDU4_BQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We keep the same seed value all along this notebook in order to be able to replicate the results \n",
        "seed_val = 42"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOCVLtje9_Rs",
        "colab_type": "code",
        "outputId": "f21b3ce7-6023-4b03-a872-e843f88a5fce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Import medium_df_desq in \"files\" (on the left) this can take some time ! \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df=pd.read_csv('medium_df_deseq.csv',encoding='utf-8')\n",
        "\n",
        "# Shuffle the date\n",
        "df=df.sample(frac=1,random_state=seed_val).reset_index(drop=True)\n",
        "\n",
        "# Some of the speeches are interviews (wrongly classified in the website) we try to delete most of them  \n",
        "df=df[~df.Texte.str.startswith(\"Q-\")]\n",
        "df=df[~df.Texte.str.startswith(\"R-\")]\n",
        "df=df[df.Id!=169898] # FOr some reason a problem on this text occured for preprocessing\n",
        "\n",
        "# Normalization of the labels [0,1] instead of [1,2] (0 = men, 1 = women)\n",
        "df.sexe=df.sexe.replace(1,0)\n",
        "df.sexe=df.sexe.replace(2,1)\n",
        "\n",
        "# We keep only variables of interest \n",
        "df=df[['Id','Titre','Theme','Prenom','Nom','Date','Tags','Texte','sexe']]\n",
        "\n",
        "# For the cleaning part we will just remove urls, parenthesis and double spacing if any \n",
        "import re\n",
        "def cleaning_stuff(text):\n",
        "    text = re.sub(r\" \\(.*?\\)\", '', text, flags=re.MULTILINE)\n",
        "    text = re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', '', text, flags=re.MULTILINE)\n",
        "    text = text.replace('(',' ')\n",
        "    text = text.replace(')',' ')\n",
        "    text = text.replace('.  ','. ')\n",
        "    text = text.replace('  ','')\n",
        "    text=text.replace(\" :'\",\"\") \n",
        "    text = text.strip()\n",
        "    text = text.replace(\"\\'\",\"'\")\n",
        "    return text \n",
        "\n",
        "df['Texte']=df.Texte.apply(cleaning_stuff)\n",
        "df=df[df.Texte!='']\n",
        "\n",
        "df = df[~df.Titre.str.startswith('Déclaration conjointe')]\n",
        "# This is a sample of our dataset\n",
        "df.head(5)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Titre</th>\n",
              "      <th>Theme</th>\n",
              "      <th>Prenom</th>\n",
              "      <th>Nom</th>\n",
              "      <th>Date</th>\n",
              "      <th>Tags</th>\n",
              "      <th>Texte</th>\n",
              "      <th>sexe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>167276</td>\n",
              "      <td>Déclaration de M. François Fillon, Premier min...</td>\n",
              "      <td>International</td>\n",
              "      <td>François</td>\n",
              "      <td>Fillon</td>\n",
              "      <td>2007-07-13T12:00:00Z</td>\n",
              "      <td>Relations internationales,Relations bilatérale...</td>\n",
              "      <td>Monsieur le président du Conseil, Mesdames et ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>177180</td>\n",
              "      <td>Déclaration de M. François Fillon, Premier min...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>François</td>\n",
              "      <td>Fillon</td>\n",
              "      <td>2009-11-12T12:00:00Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Mesdames et Messieurs les Ministres,Mesdames e...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>173356</td>\n",
              "      <td>Déclaration de M. François Fillon, Premier min...</td>\n",
              "      <td>Economie</td>\n",
              "      <td>François</td>\n",
              "      <td>Fillon</td>\n",
              "      <td>2008-12-09T12:00:00Z</td>\n",
              "      <td>Energie - Transports,Transport routier</td>\n",
              "      <td>Monsieur le Conseiller d'Etat de la République...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>170644</td>\n",
              "      <td>Déclaration de M. Bernard Kouchner, ministre d...</td>\n",
              "      <td>Société</td>\n",
              "      <td>Bernard</td>\n",
              "      <td>Kouchner</td>\n",
              "      <td>2008-05-05T12:00:00Z</td>\n",
              "      <td>Culture - Médias,Presse</td>\n",
              "      <td>A l'occasion de la 18ème journée international...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>131071</td>\n",
              "      <td>Déclaration de M. Nicolas Sarkozy, ministre de...</td>\n",
              "      <td>Société</td>\n",
              "      <td>Nicolas</td>\n",
              "      <td>Sarkozy</td>\n",
              "      <td>2002-06-25T12:00:00Z</td>\n",
              "      <td>Sécurité,Police</td>\n",
              "      <td>Mesdames et Messieurs les commissaires, Au ter...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Id  ... sexe\n",
              "0  167276  ...    0\n",
              "1  177180  ...    0\n",
              "2  173356  ...    0\n",
              "3  170644  ...    0\n",
              "4  131071  ...    0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jg5OpZdEGbbX",
        "colab_type": "code",
        "outputId": "bc563985-a61d-4158-9c57-26cdcd30bf82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(df.Texte[200])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Monsieur le président, cher Bruno Favier,Mesdames, messieurs,A l'occasion de la récente Journée mondiale de la maladie de Parkinson, je me retrouve parmi vous aujourd'hui avec satisfaction mais aussi avec gravité.Les premiers Etats généraux des personnes touchées par la maladie de Parkinson ont permis la rédaction d'un Livre Blanc, à l'initiative de l'association France-Parkinson.A vous, son président, cher Bruno Favier - dont j'ai vu avec plaisir le nom figurer dans la promotion de Pâques de la Légion d'honneur -, ainsi qu'à toutes celles et tous ceux qui oeuvrent avec vous au service des malades et de leurs familles, je veux adresser mes plus vifs remerciements.Je connais le remarquable investissement dont vous faites preuve quotidiennement pour soutenir celles et ceux qui souffrent et changer le regard de chacun sur cette maladie mal connue.L'ouvrage que vous venez de me remettre est le fruit d'un important travail de concertation, qui a su fédérer les énergies et auquel ont pris part tous les acteurs concernés : l'association France Parkinson bien entendu, mais aussi l'association des Parkinsoniens de la Loire, le comité de coordination des associations de Parkinsoniens, la fédération française des groupements de Parkinsoniens, France Comté Parkinson et Parkinsonia.A toutes et à tous, je veux dire ma considération et mon estime.En effet, vous avez fait progresser durablement la réflexion sur un sujet de santé publique majeur, qui engage notre avenir.Car, dans notre pays, ce sont 150 000 personnes qui sont atteintes de la maladie de Parkinson.Pourtant, cette maladie reste mal connue et mal comprise du grand public.Sans doute cela tient-il, en partie, à ce qu'elle est celle de tous les paradoxes.D'origine inconnue, la maladie de Parkinson introduit chez celle ou celui qui en souffre une dualité, d'abord extérieure, mais aussi plus intime.Dualité entre l'intention et le geste, qui interroge notre conception même du corps humain et de son fonctionnement.Dualité, également, entre le temps et l'espace : alors que les semaines, les mois, les années défilent, le malade est enfermé dans une rigidité subie qui contrarie et entrave ses mouvements.Dualité, enfin, entre le patient, contraint de mener un combat quotidien à chaque étape de sa vie, et son entourage, souvent démuni car mal informé sur cette maladie.C'est précisément pour rompre cette dualité et pour lutter contre l'isolement des patients que nous devons unir nos efforts.En cela, France Parkinson a accompli un chemin considérable et opéré une véritable mue, que je tiens à saluer.Vous avez fait des progrès significatifs pour vous structurer et vous organiser, progrès qui font de votre association le relais légitime auprès des pouvoirs publics de la voix des Parkinsoniens et de leurs attentes.Le Livre Blanc que vous me remettez aujourd'hui est exemplaire car il est le fruit d'un remarquable travail de concertation avec l'ensemble de vos représentants régionaux. Soyez-en remerciés.Ce Livre blanc, nourri de témoignages parfois durs, souvent émouvants émanant de patients, de proches ou de soignants, débouche sur plusieurs propositions intéressantes. Ces propositions traduisent avant tout une préoccupation récurrente : celle d'une meilleure reconnaissance de la maladie de Parkinson et de ceux qui en sont atteints.En tant que ministre de la santé, je fais mienne cette préoccupation, et je veux, avec vous, trouver les moyens d'y répondre.Pour atteindre cet objectif, le Livre blanc que vous venez de me remettre constitue à l'évidence une base de départ précieuse. Il permet de mesurer le chemin qui reste à parcourir. C'est en ce sens que j'évoquais la gravité qui m'anime aujourd'hui. Beaucoup reste à faire, je le sais.Pour faire sortir de l'ombre la maladie de Parkinson et mieux soigner ceux qui en sont atteints, des outils existent, mais ils sont sans doute insuffisamment mobilisés.Ces outils, c'est d'abord la science, qui a connu des avancées significatives sur la maladie de Parkinson.Quel chemin parcouru, en effet, depuis l'introduction de la L-DOPA dans les années 60 jusqu'au traitement chirurgical des symptômes par implantation d'électrodes de stimulation.Ces outils, c'est la recherche, et les espoirs de guérison qui y sont associés. Je rappelle que la maladie de Parkinson a fait l'objet, au cours des cinq dernières années, de plus de 16 000 publications internationales, dont près du tiers en recherche thérapeutique.Pour sa part, le ministère de la santé a financé au cours de cette période 21 projets de recherche, pour un montant de près de 4,5 millions d'euros dans le cadre du programme hospitalier de recherche clinique.Je n'oublie pas non plus le guide du patient rédigé en 2007 par la Haute autorité de santé et intitulé « Vivre avec une maladie de Parkinson ». Il a contribué, à n'en pas douter, à faire évoluer les mentalités.Ces outils, ce sont, aussi, des dispositifs efficaces pour la prise en charge et l'accompagnement des patients atteints de la maladie de Parkinson, notamment dans le cadre du plan « qualité de vie des patients atteints de maladies chroniques ».Ces outils, c'est, enfin, la loi « Hôpital, patients, santé et territoires » qui fait une large place à l'éducation thérapeutique, au rôle crucial dans le cas des maladies chroniques. Je sais que vous avez piloté des expérimentations prometteuses autour de ce thème. La mise en place du dispositif dès 2011 tiendra compte de ces expériences.La mise en place des agences régionales de santé, en permettant une meilleure articulation des secteurs hospitalier, ambulatoire et médico-social, doit permettre une amélioration de la prise en charge sanitaire et sociale et un accompagnement mieux coordonné pour les patients et pour leurs proches. J'invite vos représentants régionaux à se faire rapidement connaître des directeurs généraux des ARS.Mais sans doute faut-il aller encore plus loin, sur plusieurs des questions que soulève fort justement ce livre blanc.Je pense à la question de l'annonce du diagnostic, trop souvent traumatisante pour le malade et ses proches.Je pense à la meilleure connaissance de la maladie par les soignants, quels qu'ils soient. Je sais par exemple que trop souvent, les malades ont le sentiment que leur pathologie est insuffisamment connue de leur médecin généraliste. Sans doute est-ce parfois vrai. Nous devons progresser résolument vers une meilleure articulation des connaissances du médecin généraliste, du spécialiste qu'est le neurologue, et du malade lui-même, via l'éducation thérapeutique.J'encouragerai tout ce qui va dans le sens d'une mise en réseau de ces différentes compétences, pour une meilleure prise en charge de proximité des malades. C'est une des missions des ARS, et je la leur rappellerai avec force.Je pense également à la prise en charge des malades jeunes, avec l'enjeu que représente pour eux la poursuite d'une activité professionnelle ou l'accès à une retraite anticipée.Je pense aussi à la question fondamentale de la place de l'aidant auprès du malade : cette question du statut de l'aidant dépasse de beaucoup le seul cas de la maladie de Parkinson.Vous savez qu'elle relève également du ministre chargé des solidarités. Pour moi, ministre de la santé, elle est absolument cruciale. Je veux donc avancer rapidement sur cette question, en lien avec Nadine MORANO, secrétaire d'Etat chargée de la famille et de la solidarité. Des travaux sont en cours associant les services de nos deux ministères : je souhaite qu'ils aboutissent rapidement.Alors, je le dis très simplement : plus que des promesses illusoires, ce que je veux, c'est travailler avec vous à changer la situation concrète des personnes malades.Il n'est pas dans mon habitude de faire des annonces qui resteraient des coquilles vides. J'ai trop de respect pour les malades pour me livrer à un tel exercice.Je souhaite que la Direction générale de la santé installe dans les meilleurs délais un groupe de travail consacré à la mise en oeuvre de ces différentes préconisations : votre association a naturellement vocation à y siéger, ainsi que les sociétés savantes, les agences concernées mais aussi les représentants des autres ministères impliqués. Je souhaite que ce groupe de travail me remette un bilan d'étape dans 6 mois.Faut-il, à la lumière de ce qui vient d'être dit, envisager un Plan Parkinson pour atteindre les objectifs que nous nous sommes fixés ? Peut être, mais ce n'est pas une évidence. Ce n'est pas nécessairement à l'aune d'un plan que se mesure la mobilisation des pouvoirs publics.Que l'on ne s'y trompe pas : ce dont ont besoin nos concitoyens atteints de la maladie de Parkinson, c'est que nous soyons mieux informés sur ce qu'ils vivent.Ce dont ils ont besoin, c'est que nous fassions évoluer la vision que nous avons de leur maladie.Ce dont ils ont besoin, en un mot, c'est d'être mieux considérés.Chacun l'aura compris : c'est donc ensemble que nous relèverons les défis de demain.C'est ensemble que nous changerons l'image parfois négative de la maladie de Parkinson et que nous la ferons mieux connaître, en en retardant les symptômes, en améliorant la prise en charge et surtout la qualité du quotidien de celles et ceux qui doivent cohabiter avec et veulent « rester dans la vie », malgré la souffrance et l'isolement que trop souvent cette maladie engendre.Si nous y parvenons, comme je le souhaite ardemment, alors nous serons parvenus à « faire sortir de l'ombre » cette maladie, et plus largement, les maladies chroniques, les sujets que vous soulevez dépassant bien souvent la seule maladie de Parkinson.Du regard renouvelé que, collectivement, nous saurons porter sur les malades pour les accompagner dans la reconquête de leur identité et de leur estime, dépend l'idéal de société que nous voulons construire : celui d'une communauté de destins solidaire, plus généreuse et plus attentive aux autres, et d'abord aux plus vulnérables.Je vous remercie.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJRQHAey-0mf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "23b46ebd-5ef2-4f3e-9977-0fa4c6eaff82"
      },
      "source": [
        "# Import medium_df_desq in \"files\" (on the left) this can take some time ! \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df_balanced=pd.read_csv('medium_df_eq.csv',encoding='utf-8')\n",
        "\n",
        "# Shuffle the date\n",
        "\n",
        "# Some of the speeches are interviews (wrongly classified in the website) we try to delete most of them  \n",
        "df_balanced=df_balanced[~df_balanced.Texte.str.startswith(\"Q-\")]\n",
        "df_balanced=df_balanced[~df_balanced.Texte.str.startswith(\"R-\")]\n",
        "df_balanced=df_balanced[df_balanced.Id!=169898] # FOr some reason a problem on this text occured for preprocessing\n",
        "\n",
        "# Normalization of the labels [0,1] instead of [1,2] (0 = men, 1 = women)\n",
        "df_balanced.sexe=df_balanced.sexe.replace(1,0)\n",
        "df_balanced.sexe=df_balanced.sexe.replace(2,1)\n",
        "\n",
        "# We keep only variables of interest \n",
        "df_balanced=df_balanced[['Id','Titre','Theme','Prenom','Nom','Date','Tags','Texte','sexe']]\n",
        "\n",
        "# For the cleaning part we will just remove urls, parenthesis and double spacing if any \n",
        "import re\n",
        "def cleaning_stuff(text):\n",
        "    text = re.sub(r\" \\(.*?\\)\", '', text, flags=re.MULTILINE)\n",
        "    text = re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', '', text, flags=re.MULTILINE)\n",
        "    text = text.replace('(',' ')\n",
        "    text = text.replace(')',' ')\n",
        "    text = text.replace('.  ','. ')\n",
        "    text = text.replace('  ','')\n",
        "    text=text.replace(\" :'\",\"\") \n",
        "    text = text.strip()\n",
        "    text = text.replace(\"\\'\",\"'\")\n",
        "    return text \n",
        "\n",
        "df_balanced['Texte']=df_balanced.Texte.apply(cleaning_stuff)\n",
        "df_balanced=df_balanced[df_balanced.Texte!='']\n",
        "\n",
        "df_balanced = df_balanced[~df_balanced.Titre.str.startswith('Déclaration conjointe')]\n",
        "# This is a sample of our dataset\n",
        "df_balanced.head(5)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Titre</th>\n",
              "      <th>Theme</th>\n",
              "      <th>Prenom</th>\n",
              "      <th>Nom</th>\n",
              "      <th>Date</th>\n",
              "      <th>Tags</th>\n",
              "      <th>Texte</th>\n",
              "      <th>sexe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>133642</td>\n",
              "      <td>Déclaration de M. Hervé de Charette, ministre ...</td>\n",
              "      <td>International</td>\n",
              "      <td>Hervé</td>\n",
              "      <td>de Charette</td>\n",
              "      <td>1997-01-13T12:00:00Z</td>\n",
              "      <td>Relations internationales,Relations bilatérale...</td>\n",
              "      <td>Mesdames et Messieurs, j'ai été très heureux d...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>201364</td>\n",
              "      <td>Déclaration de M. Michel Sapin, ministre de l'...</td>\n",
              "      <td>Economie,Institutions</td>\n",
              "      <td>Michel</td>\n",
              "      <td>Sapin</td>\n",
              "      <td>2016-11-29T12:00:00Z</td>\n",
              "      <td>Vie économique,Gestion d'entreprise,Justice - ...</td>\n",
              "      <td>Monsieur le Président,Monsieur le Président de...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>272549</td>\n",
              "      <td>Déclaration de M. Emmanuel Macron, Président d...</td>\n",
              "      <td>International</td>\n",
              "      <td>Emmanuel</td>\n",
              "      <td>Macron</td>\n",
              "      <td>2019-12-21T12:00:00Z</td>\n",
              "      <td>Afrique,Côte d'Ivoire</td>\n",
              "      <td>Merci beaucoup Monsieur le Président, cher Ala...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>175752</td>\n",
              "      <td>Déclaration de M. Guy Hascoët, secrétaire d'Et...</td>\n",
              "      <td>Economie</td>\n",
              "      <td>Guy</td>\n",
              "      <td>Hascoët</td>\n",
              "      <td>2001-05-31T12:00:00Z</td>\n",
              "      <td>Vie économique,Economie sociale</td>\n",
              "      <td>En ce moment l'Europe est à l'ordre du jour. L...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>186046</td>\n",
              "      <td>Déclaration à la presse de MM. François Hollan...</td>\n",
              "      <td>International</td>\n",
              "      <td>François</td>\n",
              "      <td>Hollande</td>\n",
              "      <td>2012-10-09T12:00:00Z</td>\n",
              "      <td>Relations internationales,Relations bilatérale...</td>\n",
              "      <td>François HOLLANDE : Mesdames et Messieurs, j'a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Id  ... sexe\n",
              "0  133642  ...    0\n",
              "1  201364  ...    0\n",
              "2  272549  ...    0\n",
              "3  175752  ...    0\n",
              "4  186046  ...    0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTKQ0QnAZ_wu",
        "colab_type": "text"
      },
      "source": [
        "**We propose 3 samples to train our model :**\n",
        "\n",
        "\n",
        "**1.   Unbalanced sample**\n",
        "\n",
        "We take the raw data without any further treatment.\n",
        "\n",
        "**2.   Balanced sample**\n",
        "\n",
        "The second option consists in deleting randomly part of male speeches in order to get a balanced sample. Indeed, in the case of unbalanced sample our model could decide to classify all speakers in the male category which would lead to a 0.75 accuracy in our case study. In order to avoid this we feed the model with the same proportions of male and female speakers. Other kind of treatments exist to deal with unbalanced sample. This one is the simpliest one and we could argue that there is a possibility that the deleted sample contains important information that we therefore miss. However we believe that in our case this is not a big issue. Our unbalanced sample is quite large for both female and male.\n",
        "\n",
        "**3. Balanced and splitted sample**\n",
        "\n",
        "The third option is a response to the max length constraint of BERT models. Our text samples are big and contain much more tokens than the 512 limit. In the first two options we decide to feed the model with the 512 first tokens and thus we delete the remaining tokens. In this third option we cut the text into x parts containing 500 tokens each. All parts of the speech will serve to feed the model. Through this technique we do not loose potential important informations at the end of the text. A lot of other techniques have been employed such as hierarchical transformers (see our latex for reference). We decide to stick to this method in this project but it is an obvious improvment that could be added here. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ae8ICVGvUBLv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unbalanced_preprocess(df):\n",
        "  ''' \n",
        "  This function just takes our unbalanced dataset and prints relevant informations\n",
        "  '''\n",
        "\n",
        "  df_unbalanced=df\n",
        "\n",
        "  # Reports the number of speeches in the corpus.\n",
        "  print('Number of text in the unbalanced corpus : {0:.2f}\\n'.format(df_unbalanced.shape[0]))\n",
        "\n",
        "  # Reports the percentage of women in the sample \n",
        "  prop = (len(df_unbalanced[df_unbalanced.sexe==1])/len(df_unbalanced))*100\n",
        "  print('Percentage of women in the unbalanced corpus : {0:.2f}\\n'.format(prop))\n",
        "\n",
        "  return df_unbalanced"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IdYJSSRUdD0",
        "colab_type": "code",
        "outputId": "d5e04b0c-6ea9-4e68-8e65-89f31f51feac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "df_unbalanced = unbalanced_preprocess(df) "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of text in the unbalanced corpus : 4977.00\n",
            "\n",
            "Percentage of women in the unbalanced corpus : 25.12\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HtvqyZco_hPf",
        "colab": {}
      },
      "source": [
        "def balanced_preprocess(df,seed_val,frac_val):\n",
        "  ''' \n",
        "  This function transforms our unbalanced dataset by deleting male speeches\n",
        "\n",
        "  Input : \n",
        "          df : dataframe\n",
        "          frac_val : fraction of the sample we want (this is mainly here for testing if you want to train your model with less data)\n",
        "\n",
        "  Output : \n",
        "          df_balanced : A balanced version of our dataset with the same proportion of men and women\n",
        "  '''\n",
        "\n",
        "  # Reports the number of speeches in the corpus.\n",
        "  print('Number of text in this corpus : {0:.2f}\\n'.format(df.shape[0]))\n",
        "\n",
        "  # Reports the percentage of women in the sample \n",
        "  prop = (len(df[df.sexe==1])/len(df))*100\n",
        "  print('Percentage of women in the balanced corpus : {0:.2f}\\n'.format(prop))\n",
        "\n",
        "  return df\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeQif_N0X4uW",
        "colab_type": "code",
        "outputId": "59e17b19-816f-431b-9df4-dcf5804a4706",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "df_balanced = balanced_preprocess(df_balanced,seed_val,frac_val=1)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of text in this corpus : 4986.00\n",
            "\n",
            "Percentage of women in the balanced corpus : 50.10\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgxCphDnCiPQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "def sent_detector_mano(x):\n",
        "    \"\"\"\n",
        "        Détection de phrase à la main.\n",
        "        Input : document\n",
        "        Output : liste de phrases\n",
        "        Problème avec les phrases finissant par : entrainant souvent une liste. \n",
        "        De même avec ;. Tentative réalisée\n",
        "        \n",
        "    \"\"\"\n",
        "    lst =[]\n",
        "    phrase = []\n",
        "    i = 0\n",
        "    for caractere in x: \n",
        "        if not (caractere == ' ' and len(phrase) == 0) :\n",
        "            phrase.append(caractere)\n",
        "        if caractere in '?!.:;':\n",
        "            if caractere == ':':\n",
        "                if x[i+1].isupper() or x[i+2].isupper() or x[i+1] == '-' or x[i+2] == '-':\n",
        "                    lst.append(''.join(phrase))\n",
        "                    phrase = []\n",
        "            if caractere == ';':\n",
        "                if x[i+1].isupper() or x[i+2].isupper() or x[i+1] == '-' or x[i+2] == '-':\n",
        "                    lst.append(''.join(phrase))\n",
        "                    phrase = []\n",
        "            elif phrase != '.' or phrase != '?' or phrase != '!':\n",
        "                lst.append(''.join(phrase))\n",
        "                phrase = []\n",
        "        i+=1\n",
        "    return lst\n",
        "def split_document_to_limit(MAX_TOKENS,df):\n",
        "  lst= []\n",
        "  for index,row in df.iterrows():\n",
        "    identifiant = row.Id\n",
        "    label = row.sexe\n",
        "    phrase = []\n",
        "    for token in row.Texte.split(' '):\n",
        "      if len(phrase) < MAX_TOKENS:\n",
        "        phrase.append(token)\n",
        "      else:\n",
        "        lst += [(identifiant,label,' '.join(phrase),len(phrase))]\n",
        "        phrase = []\n",
        "    if len(phrase)>1:\n",
        "      lst += [(identifiant,label,' '.join(phrase),len(phrase))]\n",
        "  return pd.DataFrame(lst,columns=['index_df','sexe','Texte','Length'])\n",
        "def split_document_to_limit_phrases(MAX_TOKENS,df):\n",
        "  lst= []\n",
        "  for index,row in df.iterrows():\n",
        "    identifiant = row.Id\n",
        "    label = row.sexe\n",
        "    phrase = ''\n",
        "    for phrases in sent_detector_mano(row.Texte):\n",
        "      if len(phrase.split(' ')) + len(phrases.split(' ')) < MAX_TOKENS:\n",
        "        phrase+= \" \" + phrases\n",
        "      else:\n",
        "        lst += [(identifiant,label,phrase,len(phrase.split(' ')))]\n",
        "        phrase = ''\n",
        "    lst += [(identifiant,label,phrase,len(phrase.split(' ')))]\n",
        "    phrase = ''\n",
        "  return pd.DataFrame(lst,columns=['index_df','sexe','Texte','Length'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3qnfTDXCwF9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def  balanced_splitted(df,seed_val,frac_val,max_tokens):\n",
        "  \n",
        "  df=df[df.Texte!='']\n",
        "\n",
        "  df=split_document_to_limit_phrases(max_tokens,df)\n",
        " \n",
        "  df=df[df.Texte!='']\n",
        "\n",
        "\n",
        "  # Report the number of speeches in the corpus.\n",
        "  print('Number of text in this balanced splitted corpus : {:,}\\n'.format(df.shape[0]))\n",
        "  prop = (len(df[df.sexe==1])/len(df))*100\n",
        "  print('Proportions of women in the balanced splitted corpus : {}\\n'.format(prop))\n",
        "\n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEpbT1JYf5-",
        "colab_type": "code",
        "outputId": "6608d0cc-3332-4bb6-87e1-a72f1c34efb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "df_balanced_split = balanced_splitted(df_balanced,seed_val,frac_val=1,max_tokens=450)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of text in this balanced splitted corpus : 22,386\n",
            "\n",
            "Proportions of women in the balanced splitted corpus : 49.906191369606\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ressz8h6OHxn",
        "colab_type": "text"
      },
      "source": [
        "## Tokenization and preparing to feed CamemBERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntpzo9X5SSjA",
        "colab_type": "text"
      },
      "source": [
        "### Loading the Camembert Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mggkz5R9g8dD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "bfa563fb2d6443e0894ed08816d5b974",
            "c08f3ed0abd84de3832fadaa7e4b75b1",
            "039c70d812dc4b7896a553c584c96f3a",
            "053bc6ebc758496d96e8e954ef4deaee",
            "c884d616596e45d7ba711cb10766485f",
            "82abe9600920409eb04b867bec28c0ed",
            "91651eaee8e04508897cb23d3d57d42c",
            "7a92e992f92c4b50a40443bbac36dd95"
          ]
        },
        "outputId": "71888957-5f21-464c-93ca-b39eced6d117"
      },
      "source": [
        "# Import Camembert tokenizer\n",
        "from transformers import CamembertTokenizer\n",
        "# We choose a right padding side for the moment and we will test for a left padding side on a second stage\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-base', do_lower_case=False,padding_side='right') #left"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bfa563fb2d6443e0894ed08816d5b974",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=810912, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoaZUUBChM_J",
        "colab_type": "code",
        "outputId": "d8b0b2e3-6f7a-4325-8b4f-c72828fb3ef5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# Print the original text.\n",
        "print(' Original: ', df.Texte[0])\n",
        "\n",
        "# Print the text split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(df.Texte[0]))\n",
        "\n",
        "# Print the text mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(df.Texte[0])))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  Monsieur le président du Conseil, Mesdames et Messieurs les ministres, Mesdames et Messieurs les parlementaires, Mesdames et Messieurs les ambassadeurs, Mesdames et Messieurs, Et mes chers compatriotes, Permettez-moi d'abord de vous remercier, cher Romano Prodi, d'être venu ici, au palais Farnèse, pour célébrer avec nous notre Fête nationale. Votre présence aujourd'hui et celle de tant de personnalités italiennes, dans ce magnifique palais de la Renaissance que l'Italie a bien voulu nous confier pour en faire la plus belle de nos ambassades, est la marque de l'amitié forte qui unit nos deux pays et nos deux peuples. Le 14-Juillet est pour nous, Français, un anniversaire que nous sommes particulièrement heureux de célébrer en compagnie de tous les amis de la liberté et de la démocratie. Je veux donc aussi remercier chaleureusement toute la communauté diplomatique réunie ici aujourd'hui. Cher Romano Prodi, j'ai souhaité me rendre à Rome dans les plus brefs délais après ma nomination à la tête du Gouvernement français, pour témoigner au peuple italien de la place particulière, de la place exceptionnelle que votre pays tient dans le coeur des Français. La France et l'Italie partagent au plus haut point ces valeurs que nous célébrons le 14 juillet, et qui sont aussi celles des Européens. Nous les défendons dans toutes les enceintes internationales où nous siégeons côte à côte, et je pense en particulier au Conseil de sécurité des Nations unies. Nous les défendons également sur de nombreux terrains, où les peuples souffrent de la guerre et du terrorisme. Nous les défendons au Liban, en Afghanistan, dans les Balkans ou au Darfour. Nous les défendons en promouvant ensemble, avec nos partenaires européens, le dialogue entre les peuples et les civilisations, et notamment dans cet espace méditerranéen dans lequel plongent les racines de notre identité, et que nous souhaitons, Français et Italiens, mettre au centre des priorités de l'Union européenne. J'ai souhaité également venir sans tarder à Rome, parce que l'Italie est notre deuxième partenaire économique, et notre premier partenaire pour les coopérations dans le secteur de l'armement, et un partenaire majeur dans le domaine des hautes technologies et de l'espace en particulier. J'ai la volonté de consolider et d'approfondir notre relation en cherchant des solutions pragmatiques aux difficultés, et en explorant avec vous, comme nous allons le faire, monsieur le président du Conseil, dans quelques instants, toutes les pistes pour enrichir encore plus notre relation. J'ai souhaité également me rendre sans tarder à Rome, dans cette ville magnifique, où ont été célébrés en mars dernier les cinquante ans du Traité fondateur de la construction européenne, pour marquer l'importance que la France attache au renforcement du partenariat avec l'Italie, pays fondateur de l'Union européenne, pour redonner confiance à nos concitoyens dans les institutions européennes. Et je veux vous dire, que les travaux du dernier Conseil ont été accueillis en France avec soulagement. Les Français ont retrouvé la confiance en l'Europe qu'ils avaient perdue. Je sais toute la place que l'Italie, et singulièrement Romano Prodi, ont pris dans cette négociation réussie. Permettez-moi également d'adresser mes salutations les plus chaleureuses aux représentants de la communauté française qui sont ici réunis. La Fête nationale a toujours été, par-delà nos différences bien légitimes d'opinions, de religions ou même d'origines, le moment de l'année où nous nous consacrons à la célébration de notre volonté de vivre ensemble fraternellement dans la République. Permettez-moi simplement d'ajouter que cette année, notre Fête nationale prend un tour particulier, puisqu'elle coïncide avec une entreprise très ambitieuse de rénovation nationale, portée par le Gouvernement d'ouverture que j'ai l'honneur de diriger. Je veux donc vous adresser à tous et à toutes, en mon nom et en celui du président de la République française, un message d'amitié, un message de respect, pour la contribution fondamentale que vous apportez au rayonnement culturel et économique de notre pays. Le dynamisme, la jeunesse de la communauté française en Italie, enrichis par nos nombreux compatriotes binationaux, qui jouent un rôle de \"passeur\", sont des atouts fondamentaux pour la France et pour la qualité de la relation franco-italienne. Je souhaite enfin vous dire que le Gouvernement et l'ambassade de France continueront à porter votre communauté. Nous sommes à votre service, nous sommes à votre écoute. Vive l'amitié franco-italienne, Vive la République, Et vive la France !\n",
            "Tokenized:  ['▁Monsieur', '▁le', '▁président', '▁du', '▁Conseil', ',', '▁Mesdames', '▁et', '▁Messieurs', '▁les', '▁ministres', ',', '▁Mesdames', '▁et', '▁Messieurs', '▁les', '▁parlementaires', ',', '▁Mesdames', '▁et', '▁Messieurs', '▁les', '▁', 'ambassadeur', 's', ',', '▁Mesdames', '▁et', '▁Messieurs', ',', '▁Et', '▁mes', '▁chers', '▁compatriote', 's', ',', '▁Permet', 'tez', '-', 'moi', '▁d', \"'\", 'abord', '▁de', '▁vous', '▁remercier', ',', '▁cher', '▁Roman', 'o', '▁Pro', 'di', ',', '▁d', \"'\", 'être', '▁venu', '▁ici', ',', '▁au', '▁palais', '▁Far', 'nès', 'e', ',', '▁pour', '▁célébrer', '▁avec', '▁nous', '▁notre', '▁Fête', '▁nationale', '.', '▁Votre', '▁présence', '▁aujourd', \"'\", 'hui', '▁et', '▁celle', '▁de', '▁tant', '▁de', '▁personnalités', '▁italienne', 's', ',', '▁dans', '▁ce', '▁magnifique', '▁palais', '▁de', '▁la', '▁Renaissance', '▁que', '▁l', \"'\", 'Italie', '▁a', '▁bien', '▁voulu', '▁nous', '▁confier', '▁pour', '▁en', '▁faire', '▁la', '▁plus', '▁belle', '▁de', '▁nos', '▁', 'ambassade', 's', ',', '▁est', '▁la', '▁marque', '▁de', '▁l', \"'\", 'amitié', '▁forte', '▁qui', '▁un', 'it', '▁nos', '▁deux', '▁pays', '▁et', '▁nos', '▁deux', '▁peuples', '.', '▁Le', '▁14', '-', 'Ju', 'illet', '▁est', '▁pour', '▁nous', ',', '▁Français', ',', '▁un', '▁anniversaire', '▁que', '▁nous', '▁sommes', '▁', 'particulièrement', '▁heureux', '▁de', '▁célébrer', '▁en', '▁compagnie', '▁de', '▁tous', '▁les', '▁amis', '▁de', '▁la', '▁liberté', '▁et', '▁de', '▁la', '▁démocratie', '.', '▁Je', '▁veux', '▁donc', '▁aussi', '▁remercier', '▁chaleureusement', '▁toute', '▁la', '▁communauté', '▁diplomatique', '▁réuni', 'e', '▁ici', '▁aujourd', \"'\", 'hui', '.', '▁Cher', '▁Roman', 'o', '▁Pro', 'di', ',', '▁j', \"'\", 'ai', '▁souhaité', '▁me', '▁rendre', '▁à', '▁Rome', '▁dans', '▁les', '▁plus', '▁bref', 's', '▁délais', '▁après', '▁ma', '▁nomination', '▁à', '▁la', '▁tête', '▁du', '▁Gouvernement', '▁français', ',', '▁pour', '▁témoigner', '▁au', '▁peuple', '▁italien', '▁de', '▁la', '▁place', '▁particulière', ',', '▁de', '▁la', '▁place', '▁exceptionnelle', '▁que', '▁votre', '▁pays', '▁tient', '▁dans', '▁le', '▁coeur', '▁des', '▁Français', '.', '▁La', '▁France', '▁et', '▁l', \"'\", 'Italie', '▁partagent', '▁au', '▁plus', '▁haut', '▁point', '▁ces', '▁valeurs', '▁que', '▁nous', '▁célébr', 'ons', '▁le', '▁14', '▁juillet', ',', '▁et', '▁qui', '▁sont', '▁aussi', '▁celles', '▁des', '▁Européens', '.', '▁Nous', '▁les', '▁défend', 'ons', '▁dans', '▁toutes', '▁les', '▁enceintes', '▁internationales', '▁où', '▁nous', '▁siége', 'ons', '▁côte', '▁à', '▁côte', ',', '▁et', '▁je', '▁pense', '▁en', '▁particulier', '▁au', '▁Conseil', '▁de', '▁sécurité', '▁des', '▁Nations', '▁unies', '.', '▁Nous', '▁les', '▁défend', 'ons', '▁également', '▁sur', '▁de', '▁nombreux', '▁terrains', ',', '▁où', '▁les', '▁peuples', '▁souffrent', '▁de', '▁la', '▁guerre', '▁et', '▁du', '▁terrorisme', '.', '▁Nous', '▁les', '▁défend', 'ons', '▁au', '▁Liban', ',', '▁en', '▁Afghanistan', ',', '▁dans', '▁les', '▁Balkans', '▁ou', '▁au', '▁Dar', 'four', '.', '▁Nous', '▁les', '▁défend', 'ons', '▁en', '▁promo', 'uv', 'ant', '▁ensemble', ',', '▁avec', '▁nos', '▁partenaires', '▁européens', ',', '▁le', '▁dialogue', '▁entre', '▁les', '▁peuples', '▁et', '▁les', '▁civilisations', ',', '▁et', '▁notamment', '▁dans', '▁cet', '▁espace', '▁méditerranéen', '▁dans', '▁lequel', '▁plonge', 'nt', '▁les', '▁racines', '▁de', '▁notre', '▁identité', ',', '▁et', '▁que', '▁nous', '▁souhaitons', ',', '▁Français', '▁et', '▁', 'Italien', 's', ',', '▁mettre', '▁au', '▁centre', '▁des', '▁priorités', '▁de', '▁l', \"'\", 'Union', '▁européenne', '.', '▁J', \"'\", 'ai', '▁souhaité', '▁également', '▁venir', '▁sans', '▁tarder', '▁à', '▁Rome', ',', '▁parce', '▁que', '▁l', \"'\", 'Italie', '▁est', '▁notre', '▁deuxième', '▁partenaire', '▁économique', ',', '▁et', '▁notre', '▁premier', '▁partenaire', '▁pour', '▁les', '▁coopération', 's', '▁dans', '▁le', '▁secteur', '▁de', '▁l', \"'\", 'armement', ',', '▁et', '▁un', '▁partenaire', '▁majeur', '▁dans', '▁le', '▁domaine', '▁des', '▁hautes', '▁technologies', '▁et', '▁de', '▁l', \"'\", 'espace', '▁en', '▁particulier', '.', '▁J', \"'\", 'ai', '▁la', '▁volonté', '▁de', '▁consolider', '▁et', '▁d', \"'\", 'approfondir', '▁notre', '▁relation', '▁en', '▁cherchant', '▁des', '▁solutions', '▁pragmatique', 's', '▁aux', '▁difficultés', ',', '▁et', '▁en', '▁', 'explo', 'rant', '▁avec', '▁vous', ',', '▁comme', '▁nous', '▁allons', '▁le', '▁faire', ',', '▁monsieur', '▁le', '▁président', '▁du', '▁Conseil', ',', '▁dans', '▁quelques', '▁instants', ',', '▁toutes', '▁les', '▁pistes', '▁pour', '▁enrichir', '▁encore', '▁plus', '▁notre', '▁relation', '.', '▁J', \"'\", 'ai', '▁souhaité', '▁également', '▁me', '▁rendre', '▁sans', '▁tarder', '▁à', '▁Rome', ',', '▁dans', '▁cette', '▁ville', '▁magnifique', ',', '▁où', '▁ont', '▁été', '▁célébré', 's', '▁en', '▁mars', '▁dernier', '▁les', '▁cinquante', '▁ans', '▁du', '▁Traité', '▁fondateur', '▁de', '▁la', '▁construction', '▁européenne', ',', '▁pour', '▁marquer', '▁l', \"'\", 'importance', '▁que', '▁la', '▁France', '▁attache', '▁au', '▁renforcement', '▁du', '▁partenariat', '▁avec', '▁l', \"'\", 'Italie', ',', '▁pays', '▁fondateur', '▁de', '▁l', \"'\", 'Union', '▁européenne', ',', '▁pour', '▁redonner', '▁confiance', '▁à', '▁nos', '▁concitoyens', '▁dans', '▁les', '▁institutions', '▁européennes', '.', '▁Et', '▁je', '▁veux', '▁vous', '▁dire', ',', '▁que', '▁les', '▁travaux', '▁du', '▁dernier', '▁Conseil', '▁ont', '▁été', '▁accueillis', '▁en', '▁France', '▁avec', '▁soulagement', '.', '▁Les', '▁Français', '▁ont', '▁retrouvé', '▁la', '▁confiance', '▁en', '▁l', \"'\", 'Europe', '▁qu', \"'\", 'ils', '▁avaient', '▁perdue', '.', '▁Je', '▁sais', '▁toute', '▁la', '▁place', '▁que', '▁l', \"'\", 'Italie', ',', '▁et', '▁singulière', 'ment', '▁Roman', 'o', '▁Pro', 'di', ',', '▁ont', '▁pris', '▁dans', '▁cette', '▁négociation', '▁réussie', '.', '▁Permet', 'tez', '-', 'moi', '▁également', '▁d', \"'\", 'adresser', '▁mes', '▁salut', 'ations', '▁les', '▁plus', '▁chaleureuse', 's', '▁aux', '▁représentants', '▁de', '▁la', '▁communauté', '▁française', '▁qui', '▁sont', '▁ici', '▁réunis', '.', '▁La', '▁Fête', '▁nationale', '▁a', '▁toujours', '▁été', ',', '▁par', '-', 'delà', '▁nos', '▁différences', '▁bien', '▁légitimes', '▁d', \"'\", 'opinion', 's', ',', '▁de', '▁religions', '▁ou', '▁même', '▁d', \"'\", 'origine', 's', ',', '▁le', '▁moment', '▁de', '▁l', \"'\", 'année', '▁où', '▁nous', '▁nous', '▁consacr', 'ons', '▁à', '▁la', '▁célébration', '▁de', '▁notre', '▁volonté', '▁de', '▁vivre', '▁ensemble', '▁fraternel', 'lement', '▁dans', '▁la', '▁République', '.', '▁Permet', 'tez', '-', 'moi', '▁simplement', '▁d', \"'\", 'ajouter', '▁que', '▁cette', '▁année', ',', '▁notre', '▁Fête', '▁nationale', '▁prend', '▁un', '▁tour', '▁particulier', ',', '▁puisqu', \"'\", 'elle', '▁coïncide', '▁avec', '▁une', '▁entreprise', '▁très', '▁ambitieuse', '▁de', '▁rénovation', '▁nationale', ',', '▁portée', '▁par', '▁le', '▁Gouvernement', '▁d', \"'\", 'ouverture', '▁que', '▁j', \"'\", 'ai', '▁l', \"'\", 'honneur', '▁de', '▁diriger', '.', '▁Je', '▁veux', '▁donc', '▁vous', '▁adresser', '▁à', '▁tous', '▁et', '▁à', '▁toutes', ',', '▁en', '▁mon', '▁nom', '▁et', '▁en', '▁celui', '▁du', '▁président', '▁de', '▁la', '▁République', '▁française', ',', '▁un', '▁message', '▁d', \"'\", 'amitié', ',', '▁un', '▁message', '▁de', '▁respect', ',', '▁pour', '▁la', '▁contribution', '▁fondamentale', '▁que', '▁vous', '▁apporte', 'z', '▁au', '▁rayonnement', '▁culturel', '▁et', '▁économique', '▁de', '▁notre', '▁pays', '.', '▁Le', '▁dynamisme', ',', '▁la', '▁jeunesse', '▁de', '▁la', '▁communauté', '▁française', '▁en', '▁Italie', ',', '▁enrichi', 's', '▁par', '▁nos', '▁nombreux', '▁compatriote', 's', '▁bin', 'ation', 'aux', ',', '▁qui', '▁jouent', '▁un', '▁rôle', '▁de', '▁\"', 'pass', 'eur', '\",', '▁sont', '▁des', '▁atouts', '▁fondamentaux', '▁pour', '▁la', '▁France', '▁et', '▁pour', '▁la', '▁qualité', '▁de', '▁la', '▁relation', '▁franco', '-', 'italienne', '.', '▁Je', '▁souhaite', '▁enfin', '▁vous', '▁dire', '▁que', '▁le', '▁Gouvernement', '▁et', '▁l', \"'\", 'ambassade', '▁de', '▁France', '▁continuer', 'ont', '▁à', '▁porter', '▁votre', '▁communauté', '.', '▁Nous', '▁sommes', '▁à', '▁votre', '▁service', ',', '▁nous', '▁sommes', '▁à', '▁votre', '▁écoute', '.', '▁Vive', '▁l', \"'\", 'amitié', '▁franco', '-', 'italienne', ',', '▁Vive', '▁la', '▁République', ',', '▁Et', '▁vive', '▁la', '▁France', '▁!']\n",
            "Token IDs:  [2445, 16, 668, 25, 960, 7, 23605, 14, 19923, 19, 7427, 7, 23605, 14, 19923, 19, 12680, 7, 23605, 14, 19923, 19, 21, 9645, 10, 7, 23605, 14, 19923, 7, 139, 249, 6175, 16681, 10, 7, 14378, 4731, 26, 2279, 18, 11, 803, 8, 39, 5559, 7, 661, 6900, 189, 1092, 1060, 7, 18, 11, 177, 2412, 323, 7, 36, 5408, 6845, 19947, 35, 7, 24, 10003, 42, 63, 127, 7202, 945, 9, 1268, 922, 405, 11, 265, 14, 386, 8, 376, 8, 6882, 5334, 10, 7, 29, 44, 1509, 5408, 8, 13, 13460, 27, 17, 11, 5091, 33, 72, 1913, 63, 9514, 24, 22, 85, 13, 40, 455, 8, 166, 21, 14059, 10, 7, 30, 13, 587, 8, 17, 11, 6274, 1408, 31, 23, 312, 166, 116, 256, 14, 166, 116, 5073, 9, 54, 476, 26, 15660, 10663, 30, 24, 63, 7, 1455, 7, 23, 2575, 27, 63, 464, 21, 937, 1941, 8, 10003, 22, 1486, 8, 117, 19, 784, 8, 13, 1297, 14, 8, 13, 3543, 9, 100, 920, 145, 99, 5559, 22642, 194, 13, 1312, 11333, 7105, 35, 323, 405, 11, 265, 9, 3696, 6900, 189, 1092, 1060, 7, 76, 11, 73, 6267, 103, 716, 15, 3703, 29, 19, 40, 2469, 10, 3922, 182, 155, 8954, 15, 13, 450, 25, 6518, 430, 7, 24, 15461, 36, 1451, 5941, 8, 13, 218, 2628, 7, 8, 13, 218, 4110, 27, 75, 256, 1866, 29, 16, 1016, 20, 1455, 9, 61, 184, 14, 17, 11, 5091, 8604, 36, 40, 540, 299, 119, 1784, 27, 63, 19768, 273, 16, 476, 742, 7, 14, 31, 56, 99, 989, 20, 18655, 9, 170, 19, 5919, 273, 29, 208, 19, 12186, 4343, 147, 63, 24954, 273, 3444, 15, 3444, 7, 14, 50, 500, 22, 770, 36, 960, 8, 548, 20, 5542, 14784, 9, 170, 19, 5919, 273, 200, 32, 8, 490, 6403, 7, 147, 19, 5073, 13064, 8, 13, 775, 14, 25, 8429, 9, 170, 19, 5919, 273, 36, 10744, 7, 22, 23044, 7, 29, 19, 31151, 47, 36, 5913, 7452, 9, 170, 19, 5919, 273, 22, 5521, 4253, 172, 760, 7, 42, 166, 1626, 3980, 7, 16, 3036, 128, 19, 5073, 14, 19, 17843, 7, 14, 410, 29, 280, 1326, 18206, 29, 966, 5694, 113, 19, 6927, 8, 127, 4455, 7, 14, 27, 63, 8616, 7, 1455, 14, 21, 15893, 10, 7, 328, 36, 533, 20, 11626, 8, 17, 11, 1906, 1467, 9, 121, 11, 73, 6267, 200, 894, 112, 13664, 15, 3703, 7, 398, 27, 17, 11, 5091, 30, 127, 832, 2110, 919, 7, 14, 127, 246, 2110, 24, 19, 3599, 10, 29, 16, 926, 8, 17, 11, 15199, 7, 14, 23, 2110, 4329, 29, 16, 813, 20, 7919, 2608, 14, 8, 17, 11, 1179, 22, 770, 9, 121, 11, 73, 13, 1511, 8, 18403, 14, 18, 11, 20341, 127, 911, 22, 8071, 20, 1392, 19211, 10, 68, 2192, 7, 14, 22, 21, 13643, 3966, 42, 39, 7, 79, 63, 2545, 16, 85, 7, 5615, 16, 668, 25, 960, 7, 29, 193, 7812, 7, 208, 19, 4269, 24, 14891, 143, 40, 127, 911, 9, 121, 11, 73, 6267, 200, 103, 716, 112, 13664, 15, 3703, 7, 29, 78, 285, 1509, 7, 147, 96, 101, 19764, 10, 22, 697, 348, 19, 8238, 134, 25, 18218, 5988, 8, 13, 1015, 1467, 7, 24, 7205, 17, 11, 2624, 27, 13, 184, 12941, 36, 7707, 25, 2455, 42, 17, 11, 5091, 7, 256, 5988, 8, 17, 11, 1906, 1467, 7, 24, 12097, 1074, 15, 166, 22089, 29, 19, 3847, 5165, 9, 139, 50, 920, 39, 248, 7, 27, 19, 703, 25, 348, 960, 96, 101, 15145, 22, 184, 42, 16276, 9, 74, 1455, 96, 4346, 13, 1074, 22, 17, 11, 1354, 46, 11, 240, 917, 8901, 9, 100, 555, 194, 13, 218, 27, 17, 11, 5091, 7, 14, 13798, 131, 6900, 189, 1092, 1060, 7, 96, 523, 29, 78, 8776, 9713, 9, 14378, 4731, 26, 2279, 200, 18, 11, 13535, 249, 5244, 2770, 19, 40, 8887, 10, 68, 3926, 8, 13, 1312, 781, 31, 56, 323, 7686, 9, 61, 7202, 945, 33, 179, 101, 7, 37, 26, 1942, 166, 6447, 72, 21272, 18, 11, 6557, 10, 7, 8, 10642, 47, 93, 18, 11, 870, 10, 7, 16, 262, 8, 17, 11, 520, 147, 63, 63, 24209, 273, 15, 13, 10306, 8, 127, 1511, 8, 747, 760, 24447, 2918, 29, 13, 1547, 9, 14378, 4731, 26, 2279, 691, 18, 11, 4952, 27, 78, 433, 7, 127, 7202, 945, 759, 23, 508, 770, 7, 1957, 11, 144, 27923, 42, 28, 814, 95, 24747, 8, 3785, 945, 7, 2550, 37, 16, 6518, 18, 11, 1629, 27, 76, 11, 73, 17, 11, 2580, 8, 7155, 9, 100, 920, 145, 39, 11533, 15, 117, 14, 15, 208, 7, 22, 129, 373, 14, 22, 330, 25, 668, 8, 13, 1547, 781, 7, 23, 1144, 18, 11, 6274, 7, 23, 1144, 8, 1346, 7, 24, 13, 5109, 10098, 27, 39, 2767, 138, 36, 10496, 3542, 14, 919, 8, 127, 256, 9, 54, 11368, 7, 13, 2426, 8, 13, 1312, 781, 22, 4388, 7, 19667, 10, 37, 166, 490, 16681, 10, 16445, 472, 483, 7, 31, 6738, 23, 842, 8, 87, 10159, 601, 517, 56, 20, 9951, 8290, 24, 13, 184, 14, 24, 13, 335, 8, 13, 911, 7033, 26, 26102, 9, 100, 1282, 743, 39, 248, 27, 16, 6518, 14, 17, 11, 14059, 8, 184, 1760, 263, 15, 1499, 75, 1312, 9, 170, 464, 15, 75, 366, 7, 63, 464, 15, 75, 4661, 9, 10392, 17, 11, 6274, 7033, 26, 26102, 7, 10392, 13, 1547, 7, 139, 6440, 13, 184, 83]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8yAtMsdR9HB",
        "colab_type": "text"
      },
      "source": [
        "### Preparing to feed the model : adding special tokens, attention masks and transform into tensors\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXlKcUdlYetx",
        "colab_type": "text"
      },
      "source": [
        "Preprocessing steps : \n",
        "\n",
        "\n",
        "1.   **Add special tokens [CLS] [SEP]** \n",
        "\n",
        "According to the documentation we need to add special tokens to the start and end of the text Moreover, for camembert we should add a space between CLS and the first token (not sure here, we have to ask benjamin). \n",
        "\n",
        "2.   **Pad and truncate all texts to a single number**\n",
        "\n",
        "Pretrained transformes like Camembert only accept input of the same length. Our corpus contains large texts and we have to pad them in order to be able to feed Camembert. We will set the max length to a large number in order to get all information possible in the text. We choose a max length of 500 which is almost the maximum (512) \"sentence\" length  accepted. We are aware that this choice will impact a lot training speed.\n",
        "\n",
        "3.   **Construct an attention mask**\n",
        "\n",
        "Attention masks are just set to 1 when the token have to be analyzed and 0 otherwise (padded tokens). All our attention mask should be 1 with this corpus. \n",
        "\n",
        "\n",
        "\n",
        "For sake of simplicity and to avoid errors we will use the function encode_plus of the library which is really convenient. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaVIHaijS73R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "length = 500\n",
        "batch_size_value = 16\n",
        "length_train=0.8\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed_all(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkbqtyqH6V_R",
        "colab_type": "code",
        "outputId": "c8b2bf77-ca2b-4ded-cb37-335d01a11c78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "texts = df_unbalanced.Texte.values\n",
        "labels = df_unbalanced.sexe.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "num_truncated_tokens =[]\n",
        "# Apply function to our corpus\n",
        "for text in texts:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        text,                      # text\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = length,           # We choose for now a max length of 500.\n",
        "                        pad_to_max_length = True,    # Pad text to max (marche pas en pad left ?)\n",
        "                        return_attention_mask = True,   # Construct attention masks\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                        return_overflowing_tokens =True, # return overflowing token information\n",
        "                  )\n",
        "    \n",
        "    # Map tokens to their id in the dictionnary \n",
        "    # We add this to our list    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "    #num_truncated_tokens.append(encoded_dict['num_truncated_tokens'])\n",
        "    \n",
        "    # 3. Attention masks\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# We convert all this into tensors in order to be able to make it work on GPU \n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Original text and transformed tensor print \n",
        "print(\"Let's check for the first text indexes, attention masks and labels\")\n",
        "print(\" \")\n",
        "print('Original: ', texts[0][0:100])\n",
        "print('IDs:', input_ids[0][0:100])\n",
        "print('Attention masks:', attention_masks[0][0:100])\n",
        "print('labels',labels[0])\n",
        "\n",
        "\n",
        "# Combine all above\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Let's create a 80-20 train / validation dataset \n",
        "train_size = int(length_train * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_set, val_set = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "\n",
        "print(\"-------------------------------------------------\")\n",
        "print(\" \")\n",
        "print(\"How many texts do we have in the train and validation sample ? \")\n",
        "print(\" \")\n",
        "print('We have {} training texts'.format(train_size))\n",
        "print('We have {} validation texts'.format(val_size))\n",
        "print(\" \")\n",
        "print(\"-------------------------------------------------\")\n",
        "\n",
        "# We set the size of the batch ( usually set around 16 or 32), we will take the lower bound because of the large text length\n",
        "batch_size = batch_size_value\n",
        "\n",
        "# We create data loaders for the train and validation dataset. \n",
        "train_loader_unbalanced = DataLoader(\n",
        "            train_set,  # The training samples.\n",
        "            sampler = RandomSampler(train_set), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "val_loader_unbalanced = DataLoader(\n",
        "            val_set, # The validation samples.\n",
        "            sampler = SequentialSampler(val_set), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n",
        "\n",
        "print('Data loaders created for train [0] and val [1]')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Let's check for the first text indexes, attention masks and labels\n",
            " \n",
            "Original:  Monsieur le président du Conseil, Mesdames et Messieurs les ministres, Mesdames et Messieurs les par\n",
            "IDs: tensor([    5,  2445,    16,   668,    25,   960,     7, 23605,    14, 19923,\n",
            "           19,  7427,     7, 23605,    14, 19923,    19, 12680,     7, 23605,\n",
            "           14, 19923,    19,    21,  9645,    10,     7, 23605,    14, 19923,\n",
            "            7,   139,   249,  6175, 16681,    10,     7, 14378,  4731,    26,\n",
            "         2279,    18,    11,   803,     8,    39,  5559,     7,   661,  6900,\n",
            "          189,  1092,  1060,     7,    18,    11,   177,  2412,   323,     7,\n",
            "           36,  5408,  6845, 19947,    35,     7,    24, 10003,    42,    63,\n",
            "          127,  7202,   945,     9,  1268,   922,   405,    11,   265,    14,\n",
            "          386,     8,   376,     8,  6882,  5334,    10,     7,    29,    44,\n",
            "         1509,  5408,     8,    13, 13460,    27,    17,    11,  5091,    33])\n",
            "Attention masks: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1])\n",
            "labels tensor(0)\n",
            "-------------------------------------------------\n",
            " \n",
            "How many texts do we have in the train and validation sample ? \n",
            " \n",
            "We have 3981 training texts\n",
            "We have 996 validation texts\n",
            " \n",
            "-------------------------------------------------\n",
            "Data loaders created for train [0] and val [1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnLKzstr6ghY",
        "colab_type": "code",
        "outputId": "11bdd68f-c2c4-4622-daf5-fcc9f2d8bab2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "texts = df_balanced.Texte.values\n",
        "labels = df_balanced.sexe.values\n",
        "length = 500\n",
        "batch_size_value = 16\n",
        "length_train=0.8\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed_all(42)\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "num_truncated_tokens =[]\n",
        "# Apply function to our corpus\n",
        "for text in texts:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        text,                      # text\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = length,           # We choose for now a max length of 500.\n",
        "                        pad_to_max_length = True,    # Pad text to max (marche pas en pad left ?)\n",
        "                        return_attention_mask = True,   # Construct attention masks\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                        return_overflowing_tokens =True, # return overflowing token information\n",
        "                  )\n",
        "    \n",
        "    # Map tokens to their id in the dictionnary \n",
        "    # We add this to our list    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "    #num_truncated_tokens.append(encoded_dict['num_truncated_tokens'])\n",
        "    \n",
        "    # 3. Attention masks\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# We convert all this into tensors in order to be able to make it work on GPU \n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Original text and transformed tensor print \n",
        "print(\"Let's check for the first text indexes, attention masks and labels\")\n",
        "print(\" \")\n",
        "print('Original: ', texts[0][0:100])\n",
        "print('IDs:', input_ids[0][0:100])\n",
        "print('Attention masks:', attention_masks[0][0:100])\n",
        "print('labels',labels[0])\n",
        "\n",
        "\n",
        "# Combine all above\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Let's create a 80-20 train / validation dataset \n",
        "train_size = int(length_train * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_set, val_set = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "\n",
        "print(\"-------------------------------------------------\")\n",
        "print(\" \")\n",
        "print(\"How many texts do we have in the train and validation sample ? \")\n",
        "print(\" \")\n",
        "print('We have {} training texts'.format(train_size))\n",
        "print('We have {} validation texts'.format(val_size))\n",
        "print(\" \")\n",
        "print(\"-------------------------------------------------\")\n",
        "\n",
        "# We set the size of the batch ( usually set around 16 or 32), we will take the lower bound because of the large text length\n",
        "batch_size = batch_size_value\n",
        "\n",
        "# We create data loaders for the train and validation dataset. \n",
        "train_loader_balanced = DataLoader(\n",
        "            train_set,  # The training samples.\n",
        "            sampler = RandomSampler(train_set), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "val_loader_balanced = DataLoader(\n",
        "            val_set, # The validation samples.\n",
        "            sampler = SequentialSampler(val_set), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n",
        "\n",
        "print('Data loaders created for train [0] and val [1]')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Let's check for the first text indexes, attention masks and labels\n",
            " \n",
            "Original:  Mesdames et Messieurs, j'ai été très heureux de recevoir aujourd'hui Mme Pesic, responsable de l'all\n",
            "IDs: tensor([    5, 23605,    14, 19923,     7,    76,    11,    73,   101,    95,\n",
            "         1941,     8,  1653,   405,    11,   265,  2439,  2997, 12219,     7,\n",
            "         1295,     8,    17,    11, 11193, 16552,    42,   745,    63,   296,\n",
            "        12199, 12997,    13,   595,    31, 30827,   405,    11,   265,    15,\n",
            "         3845, 11602,    35,     9,  2439,  2997, 12219,   115,    11,    55,\n",
            "          804,     8,   429, 10012,     7,    17,    11,  2153,     8,    13,\n",
            "          595,     7,    16,   299,     8,   477,    14,    19,  1161,    31,\n",
            "           56,    19, 11017,    10,    14,   989,     8,    17,    11,  4244,\n",
            "           24,  1077,    13, 25389,     8,    13,  1662,   462,  4440,    29,\n",
            "          745,   109,    48,   396,     9,   100,  4318,    39,  3318,     7])\n",
            "Attention masks: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1])\n",
            "labels tensor(0)\n",
            "-------------------------------------------------\n",
            " \n",
            "How many texts do we have in the train and validation sample ? \n",
            " \n",
            "We have 3988 training texts\n",
            "We have 998 validation texts\n",
            " \n",
            "-------------------------------------------------\n",
            "Data loaders created for train [0] and val [1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FBZvaQ969S0",
        "colab_type": "code",
        "outputId": "ac237bfe-2db6-48be-82ff-96bc537b667d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "texts = df_balanced_split.Texte.values \n",
        "labels = df_balanced_split.sexe.values\n",
        "\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed_all(42)\n",
        "length = 500\n",
        "batch_size_value = 8\n",
        "length_train=0.8\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "num_truncated_tokens =[]\n",
        "# Apply function to our corpus\n",
        "for text in texts:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        text,                      # text\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = length,           # We choose for now a max length of 500.\n",
        "                        pad_to_max_length = True,    # Pad text to max (marche pas en pad left ?)\n",
        "                        return_attention_mask = True,   # Construct attention masks\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                        return_overflowing_tokens =True, # return overflowing token information\n",
        "                  )\n",
        "    \n",
        "    # Map tokens to their id in the dictionnary \n",
        "    # We add this to our list    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "    #num_truncated_tokens.append(encoded_dict['num_truncated_tokens'])\n",
        "    \n",
        "    # 3. Attention masks\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# We convert all this into tensors in order to be able to make it work on GPU \n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Original text and transformed tensor print \n",
        "print(\"Let's check for the first text indexes, attention masks and labels\")\n",
        "print(\" \")\n",
        "print('Original: ', texts[0][0:100])\n",
        "print('IDs:', input_ids[0][0:100])\n",
        "print('Attention masks:', attention_masks[0][0:100])\n",
        "print('labels',labels[0])\n",
        "\n",
        "# Combine all above\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Let's create a 80-20 train / validation dataset \n",
        "train_size = int(length_train * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_set, val_set = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "\n",
        "print(\"-------------------------------------------------\")\n",
        "print(\" \")\n",
        "print(\"How many texts do we have in the train and validation sample ? \")\n",
        "print(\" \")\n",
        "print('We have {} training texts'.format(train_size))\n",
        "print('We have {} validation texts'.format(val_size))\n",
        "print(\" \")\n",
        "print(\"-------------------------------------------------\")\n",
        "\n",
        "# We set the size of the batch ( usually set around 16 or 32), we will take the lower bound because of the large text length\n",
        "batch_size = batch_size_value\n",
        "\n",
        "# We create data loaders for the train and validation dataset. \n",
        "train_loader_balanced_split = DataLoader(\n",
        "            train_set,  # The training samples.\n",
        "            sampler = RandomSampler(train_set), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "val_loader_balanced_split = DataLoader(\n",
        "            val_set, # The validation samples.\n",
        "            sampler = SequentialSampler(val_set), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n",
        "\n",
        "print('Data loaders created for train [0] and val [1]')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Let's check for the first text indexes, attention masks and labels\n",
            " \n",
            "Original:   Mesdames et Messieurs, j'ai été très heureux de recevoir aujourd'hui Mme Pesic, responsable de l'al\n",
            "IDs: tensor([    5, 23605,    14, 19923,     7,    76,    11,    73,   101,    95,\n",
            "         1941,     8,  1653,   405,    11,   265,  2439,  2997, 12219,     7,\n",
            "         1295,     8,    17,    11, 11193, 16552,    42,   745,    63,   296,\n",
            "        12199, 12997,    13,   595,    31, 30827,   405,    11,   265,    15,\n",
            "         3845, 11602,    35,     9,  2439,  2997, 12219,   115,    11,    55,\n",
            "          804,     8,   429, 10012,     7,    17,    11,  2153,     8,    13,\n",
            "          595,     7,    16,   299,     8,   477,    14,    19,  1161,    31,\n",
            "           56,    19, 11017,    10,    14,   989,     8,    17,    11,  4244,\n",
            "           24,  1077,    13, 25389,     8,    13,  1662,   462,  4440,    29,\n",
            "          745,   109,    48,   396,     9,   100,  4318,    39,  3318,     7])\n",
            "Attention masks: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1])\n",
            "labels tensor(0)\n",
            "-------------------------------------------------\n",
            " \n",
            "How many texts do we have in the train and validation sample ? \n",
            " \n",
            "We have 17908 training texts\n",
            "We have 4478 validation texts\n",
            " \n",
            "-------------------------------------------------\n",
            "Data loaders created for train [0] and val [1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vs6YDmQsgljf",
        "colab_type": "text"
      },
      "source": [
        "5 and 6 seem to be the [CLS] and [SEP] special tokens \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poTTEJX1hoUK",
        "colab_type": "text"
      },
      "source": [
        "## CamemBERT Sequence Classification model tuning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NN1VeJI0lDwf",
        "colab_type": "text"
      },
      "source": [
        "### Loading the model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99MPOVB7iRcl",
        "colab_type": "text"
      },
      "source": [
        "We will finally build up our model. We will use the  CamemBERT model for sequence classification which includes a special top layer designed for this task. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRHhHzjKgAC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing from transformers\n",
        "from transformers import CamembertForSequenceClassification, CamembertConfig"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHMdM-QqgAAX",
        "colab_type": "code",
        "outputId": "fc914862-c632-4c9b-8e35-31aac1fbd471",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "8bb6a0e52c2047198f8a4d9c3ae19eb8",
            "30841884dddf4ed7ad275a953866e63e",
            "600a4746d2b9467c97aae99648b2d9e1",
            "e5f293761ebe4debad834b195e3b6009",
            "1b6772a63d7c484bbd5237c9872cb494",
            "d45421d926e842439e58771b52550e3c",
            "acabceebaa5d46bf8cf03da75107843f",
            "08c2103c9b6947528e3124c4b27e9799",
            "522d1ae97de14f7cbe919a183b4ccdb0",
            "7a75f027dfbf40d3b563d58a757f5d0f",
            "b8734ceb7db24503bf0d99a08f3a35af",
            "10ed4e33740c4aa78f2f17f213986ee3",
            "806516ece2ba41078b8dc7434c4b0b36",
            "a312e2a5d9124caa8311cf140640701c",
            "6e592c8ebb864ff6bcfd4273b18468bf",
            "46e3157fa8fc4157b504b33d7b8441bc"
          ]
        }
      },
      "source": [
        "# Loading the model\n",
        "gender_model = CamembertForSequenceClassification.from_pretrained(\n",
        "    \"camembert-base\", \n",
        "    num_labels = 2, # We have two different labels Women = 1 and Men =0   \n",
        "    output_attentions = False, \n",
        "    output_hidden_states = False, \n",
        ")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8bb6a0e52c2047198f8a4d9c3ae19eb8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=637, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "522d1ae97de14f7cbe919a183b4ccdb0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=445032417, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUKynoykf_9y",
        "colab_type": "code",
        "outputId": "30e3d1fd-1246-4309-e4c9-371dd36405cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# We run the model on the colab GPU \n",
        "gender_model.cuda()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CamembertForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgwmHirxnEie",
        "colab_type": "text"
      },
      "source": [
        "### Constructing the training and validation loop \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZDt2ZElwcJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import f1_score \n",
        "\n",
        "def create_report(labels,preds) : \n",
        "  pred_flat= np.argmax(preds, axis=1).flatten()\n",
        "  labels_flat = labels.flatten()\n",
        "  F1_score = f1_score(labels_flat,pred_flat,zero_division=1)\n",
        "  Accuracy = np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "  return F1_score, Accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUB8c4k_t1UJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_val_gendermodel(train_loader, val_loader, epochs_val,seed_val,device,lr_value):\n",
        "\n",
        "  ############################  IMPORT MODEL ################################################\n",
        "  from transformers import CamembertForSequenceClassification\n",
        "  gender_model = CamembertForSequenceClassification.from_pretrained(\n",
        "    \"camembert-base\", \n",
        "    num_labels = 2, # We have two different labels Women = 1 and Men =0   \n",
        "    output_attentions = False, \n",
        "    output_hidden_states = False, )\n",
        "\n",
        "  model = gender_model\n",
        "  model.cuda()\n",
        "  \n",
        "  ############################## RANDOM SEED ##################################################\n",
        "\n",
        "  import random\n",
        " # Let's put a seed to make this result reproducible \n",
        "  seed=seed_val\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "  ############################### LEARNING RATE SCHEDULER #######################################\n",
        "\n",
        "  # https://huggingface.co/transformers/migration.html \n",
        "  # https://pytorch.org/docs/stable/optim.html (default values)\n",
        "\n",
        "  import torch.nn as nn\n",
        "  import torch.optim as optim\n",
        "  from transformers import AdamW\n",
        "  from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "  epochs = epochs_val # In order to fine tune our model we will first set the number of epochs to 4.\n",
        "\n",
        "  # We choose Binary cross enthropy with logits loss for the loss computation. It seems to be the most adapted loss to our problem. \n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "  #Implements Adam algorithm with weight decay fix.\n",
        "  opti = AdamW(model.parameters(),\n",
        "                    lr =lr_value, # learning rate (default = 1e-3)\n",
        "                    eps = 1e-8 # prevents division by 0 (default = 1e-8)\n",
        "                  )\n",
        "\n",
        "  num_training_steps = len(train_loader) * epochs\n",
        "  # Create a schedule with a learning rate that decreases linearly after linearly increasing during a warmup period (0 here)\n",
        "  scheduler = get_linear_schedule_with_warmup(opti, \n",
        "                                              num_warmup_steps = 0,\n",
        "                                              num_training_steps = num_training_steps)\n",
        "  \n",
        "  \n",
        "  # We want to evaluate the training phase \n",
        "  training_stats = []\n",
        "\n",
        "  for ep in range(0, epochs):\n",
        "    print('===========Starting Epoch {} / {} =============='.format(ep+1,epochs))\n",
        "    print('Training starts')\n",
        "\n",
        "    ################################### TRAINING ################################\n",
        "\n",
        "    #Put the model in training mode\n",
        "    model.train()\n",
        "\n",
        "    # Set the train loss for the epoch to 0 \n",
        "    total_train_loss = 0\n",
        "\n",
        "    for step, batch in enumerate(train_loader):\n",
        "      # Clear gradients \n",
        "      model.zero_grad() # (opti.zerograd ? )\n",
        "\n",
        "      # Cpy the 3 batch to GPU \n",
        "      b_input_ids = batch[0].to(device)\n",
        "      b_input_mask = batch[1].to(device)\n",
        "      b_labels = batch[2].to(device)\n",
        "      \n",
        "      #return loss and logits\n",
        "      loss, logits = model(b_input_ids, \n",
        "                          token_type_ids=None, \n",
        "                          attention_mask=b_input_mask, \n",
        "                          labels=b_labels) \n",
        "      \n",
        "      # Accumulate training loss for all batches \n",
        "      total_train_loss += loss.item()\n",
        "\n",
        "      #Backpropagating the gradients \n",
        "      loss.backward()\n",
        "\n",
        "      # Prevent exploding gradients problem  (forcing the gradients to be small, the parameter updates will not push the parameters too far from their previous values)\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "      # Update parameters \n",
        "      opti.step()\n",
        "\n",
        "      # Update learning rate schedule\n",
        "      scheduler.step()\n",
        "\n",
        "    #Calculate the average training loss over all batches  \n",
        "    avg_train_loss = total_train_loss / len(train_loader)\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print('')\n",
        "    print('Validation starts')\n",
        "\n",
        "    ###################### VALIDATION #############################\n",
        "\n",
        "    # Put model in evaluation mode \n",
        "    model.eval()\n",
        "\n",
        "    # Set statistics to 0\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "    total_eval_f1=0\n",
        "    total_roc_auc = 0 \n",
        "\n",
        "    # Confusion matrix ?\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    for batch in val_loader:\n",
        "      b_input_ids = batch[0].to(device)\n",
        "      b_input_mask = batch[1].to(device)\n",
        "      b_labels = batch[2].to(device)\n",
        "      \n",
        "      # We don't care about gradients for eval\n",
        "\n",
        "      with torch.no_grad(): \n",
        "        (loss, logits) = model(b_input_ids, \n",
        "                                  token_type_ids=None, \n",
        "                                  attention_mask=b_input_mask,\n",
        "                                  labels=b_labels)\n",
        "      total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU \n",
        "      logits = logits.detach().cpu().numpy()\n",
        "      label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "      F1_score, Accuracy = create_report(label_ids,logits)\n",
        "\n",
        "      # Accumulation accuracy for all batch\n",
        "      total_eval_accuracy += Accuracy\n",
        "\n",
        "      # Accumulation f1 for all batch\n",
        "      total_eval_f1 += F1_score\n",
        "\n",
        "      \n",
        "      #Final accuracy on all batch\n",
        "    avg_val_accuracy = total_eval_accuracy / len(val_loader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "      #Final f1 on all batch\n",
        "    avg_val_f1 = total_eval_f1 / len(val_loader)\n",
        "    print(\"  F1_score: {0:.2f}\".format(avg_val_f1))\n",
        "\n",
        "      #Final loss over all batch\n",
        "    avg_val_loss = total_eval_loss / len(val_loader)\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "\n",
        "    training_stats.append(\n",
        "          {\n",
        "              'epoch': ep + 1,\n",
        "              'Train Loss': avg_train_loss,\n",
        "              'Val Loss': avg_val_loss,\n",
        "              'Val Accur.': avg_val_accuracy,\n",
        "              'Val F1' : avg_val_f1,\n",
        "          }\n",
        "      )\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"Done !\")\n",
        "\n",
        "  return  training_stats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anria4-x6FHk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def report_model_1(results):\n",
        "  '''\n",
        "  Input : statistics of the model \n",
        "  Output : training and valid loss \n",
        "  ''' \n",
        "  df_stats = pd.DataFrame(data=results)\n",
        "  df_stats = df_stats.set_index('epoch')\n",
        "  print(df_stats)\n",
        "\n",
        "  import matplotlib.pyplot as plt\n",
        "  % matplotlib inline\n",
        "  import seaborn as sns\n",
        "\n",
        "  # Increase the plot size and font size.\n",
        "  sns.set(font_scale=1.5)\n",
        "  plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "  # Plot the learning curve.\n",
        "  plt.plot(df_stats['Train Loss'], 'b-o', label=\"Training\")\n",
        "  plt.plot(df_stats['Val Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "  # Label the plot.\n",
        "  plt.title(\"Training & Validation Loss\")\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.legend()\n",
        "  plt.xticks([1, 2, 3, 4, 5])\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqNRTJME5oHs",
        "colab_type": "code",
        "outputId": "4baf22a0-2744-49ed-9077-70967450ebf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "results_unbalanced = train_val_gendermodel(train_loader=train_loader_unbalanced, val_loader=val_loader_unbalanced, epochs_val=5,seed_val=42,device=device,lr_value=5e-5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===========Starting Epoch 1 / 5 ==============\n",
            "Training starts\n",
            "\n",
            "  Average training loss: 0.42\n",
            "\n",
            "Validation starts\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKu-O0c653tX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "report_model_1(results_unbalanced)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DH9QNCMXR0zc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results_balanced = train_val_gendermodel(train_loader=train_loader_balanced, val_loader=val_loader_balanced, epochs_val=5,seed_val=42,device=device,lr_value=5e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0Pti-Dk59DT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "report_model_1(results_balanced)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hb6Ca8qmdT74",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results_balanced_split = train_val_gendermodel(train_loader=train_loader_balanced_split, val_loader=val_loader_balanced_split, epochs_val=5,seed_val=42,device=device,lr_value=5e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJSzx-x35-jW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "report_model_1(results_balanced_split)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "takjS5TPncaC",
        "colab_type": "text"
      },
      "source": [
        "**Overall Performance** : As expected we see that training on a balanced dataset avoid the model to be biased toward men. F1 score is much higher for the balanced sample. \n",
        "\n",
        "**Number of epoches** : According to the train and valid loss, 2 to 3 epochs are enough in order to train the model efficiently. More epochs would lead to an overfitting on the training sample. \n",
        "\n",
        "**Token limitation** : Let's now compare the method consisting in using only the first 500 token of the texte and the entire text. We have similar results in terms of metrics. We were not expecting such a high result for the second model to begin with but it seems that learning on the first paragraph is enough to be able to classify all them after. \n",
        "\n",
        "**Final choice** : Even if the second model is already satisfying, the second might be easier to generalized after and displays higher metrics. We will use the third one in the rest of this section. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKXUkXjfg0s2",
        "colab_type": "text"
      },
      "source": [
        "### Training the optimal model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1LLOEa3g2wL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_eval= balanced_splitted(df_balanced,seed_val,frac_val=1,max_tokens=450)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fa_3vh-698n6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We prepare another sample which will be dedicated to further qualitative analysis"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cL1SsPWU98tz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len_train = round(0.97*len(df_eval))\n",
        "df_balanced_split= df_eval[0:len_train]\n",
        "dev_balanced_split=df_eval[len_train:len(df_eval)]\n",
        "\n",
        "# Report the number of speeches in the corpus.\n",
        "print('Number of text in this balanced splitted corpus : {:,}\\n'.format(df_balanced_split.shape[0]))\n",
        "print('Number of text in the development sample : {:,}\\n'.format(dev_balanced_split.shape[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XuXBR-rgR3U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "texts = df_balanced_split.Texte.values \n",
        "labels = df_balanced_split.sexe.values\n",
        "\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed_all(42)\n",
        "length = 500\n",
        "batch_size_value = 16\n",
        "length_train=0.9\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "num_truncated_tokens =[]\n",
        "# Apply function to our corpus\n",
        "for text in texts:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        text,                      # text\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = length,           # We choose for now a max length of 500.\n",
        "                        pad_to_max_length = True,    # Pad text to max (marche pas en pad left ?)\n",
        "                        return_attention_mask = True,   # Construct attention masks\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                        return_overflowing_tokens =True, # return overflowing token information\n",
        "                  )\n",
        "    \n",
        "    # Map tokens to their id in the dictionnary \n",
        "    # We add this to our list    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "    #num_truncated_tokens.append(encoded_dict['num_truncated_tokens'])\n",
        "    \n",
        "    # 3. Attention masks\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# We convert all this into tensors in order to be able to make it work on GPU \n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Original text and transformed tensor print \n",
        "print(\"Let's check for the first text indexes, attention masks and labels\")\n",
        "print(\" \")\n",
        "print('Original: ', texts[0][0:100])\n",
        "print('IDs:', input_ids[0][0:100])\n",
        "print('Attention masks:', attention_masks[0][0:100])\n",
        "print('labels',labels[0])\n",
        "\n",
        "# Combine all above\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Let's create a 80-20 train / validation dataset \n",
        "train_size = int(length_train * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_set, val_set = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "\n",
        "print(\"-------------------------------------------------\")\n",
        "print(\" \")\n",
        "print(\"How many texts do we have in the train and validation sample ? \")\n",
        "print(\" \")\n",
        "print('We have {} training texts'.format(train_size))\n",
        "print('We have {} validation texts'.format(val_size))\n",
        "print(\" \")\n",
        "print(\"-------------------------------------------------\")\n",
        "\n",
        "# We set the size of the batch ( usually set around 16 or 32), we will take the lower bound because of the large text length\n",
        "batch_size = batch_size_value\n",
        "\n",
        "# We create data loaders for the train and validation dataset. \n",
        "train_loader_balanced_split = DataLoader(\n",
        "            train_set,  # The training samples.\n",
        "            sampler = RandomSampler(train_set), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "val_loader_balanced_split = DataLoader(\n",
        "            val_set, # The validation samples.\n",
        "            sampler = SequentialSampler(val_set), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n",
        "\n",
        "print('Data loaders created for train [0] and val [1]')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0p-TPR1CAOlh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "############################  IMPORT MODEL ################################################\n",
        "from transformers import CamembertForSequenceClassification\n",
        "gender_model = CamembertForSequenceClassification.from_pretrained(\"camembert-base\", \n",
        "                                                                  num_labels = 2, \n",
        "                                                                  output_attentions = False, \n",
        "                                                                  output_hidden_states = False, )\n",
        "\n",
        "gender_model.cuda()\n",
        "############################## RANDOM SEED ##################################################\n",
        "\n",
        "import random\n",
        "seed=seed_val\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "############################### LEARNING RATE SCHEDULER #######################################\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from transformers import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs = 3 \n",
        "\n",
        "#Implements Adam algorithm with weight decay fix.\n",
        "opti = AdamW(gender_model.parameters(),\n",
        "              lr =5e-5, # learning rate (default = 1e-3)\n",
        "              eps = 1e-8 # prevents division by 0 (default = 1e-8)\n",
        "            )\n",
        "\n",
        "num_training_steps = len(train_loader_balanced_split) * epochs\n",
        "\n",
        "# Create a schedule with a learning rate that decreases linearly after linearly increasing during a warmup period (0 here)\n",
        "scheduler = get_linear_schedule_with_warmup(opti, \n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = num_training_steps)\n",
        "\n",
        "\n",
        "for ep in range(0, epochs):\n",
        "  print('===========Starting Epoch {} / {} =============='.format(ep+1,epochs))\n",
        "  print('Training starts')\n",
        "\n",
        "  ################################### TRAINING ################################\n",
        "\n",
        "  #Put the model in training mode\n",
        "  gender_model.train()\n",
        "\n",
        "  # Set the train loss for the epoch to 0 \n",
        "  total_train_loss = 0\n",
        "\n",
        "  for step, batch in enumerate(train_loader_balanced_split):\n",
        "    # Clear gradients \n",
        "    gender_model.zero_grad() # \n",
        "\n",
        "    # Cpy the 3 batch to GPU \n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "    \n",
        "    #return loss and logits\n",
        "    loss, logits = gender_model(b_input_ids, \n",
        "                                token_type_ids=None, \n",
        "                                attention_mask=b_input_mask, \n",
        "                                labels=b_labels) \n",
        "    \n",
        "    # Accumulate training loss for all batches \n",
        "    total_train_loss += loss.item()\n",
        "\n",
        "    #Backpropagating the gradients \n",
        "    loss.backward()\n",
        "\n",
        "    # Prevent exploding gradients problem  (forcing the gradients to be small, the parameter updates will not push the parameters too far from their previous values)\n",
        "    torch.nn.utils.clip_grad_norm_(gender_model.parameters(), 1.0)\n",
        "\n",
        "    # Update parameters \n",
        "    opti.step()\n",
        "\n",
        "    # Update learning rate schedule\n",
        "    scheduler.step()\n",
        "\n",
        "  #Calculate the average training loss over all batches  \n",
        "  avg_train_loss = total_train_loss / len(train_loader_balanced_split)\n",
        "  print(\"\")\n",
        "  print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZK0OHVGupkew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save( gender_model, 'gender_model_train.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0no-TfXp8a2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gender_model = torch.load('gender_model_train.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60t946KwdjJh",
        "colab_type": "text"
      },
      "source": [
        "## Quantitative evaluation and qualitative analysis "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYx9mKhWvsHA",
        "colab_type": "text"
      },
      "source": [
        "### Quantitative analysis of the final model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMAECbOYC_Rv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def evaluation_loop(model,eval_loader): \n",
        "  # Put model in evaluation mode \n",
        "  model.eval()\n",
        "  total_eval_loss,total_pred,total_label,total_logits=[],[],[],[]\n",
        "\n",
        "  for batch in eval_loader:\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "\n",
        "    with torch.no_grad(): \n",
        "      loss, logits = model(b_input_ids, \n",
        "                                token_type_ids=None, \n",
        "                                attention_mask=b_input_mask,\n",
        "                                labels=b_labels)\n",
        "    #total_eval_loss += loss.item()\n",
        "\n",
        "      # Move logits and labels to CPU \n",
        "      logits = logits.detach().cpu().numpy()\n",
        "      label_ids = b_labels.to('cpu').numpy()\n",
        "      pred= np.argmax(logits, axis=1).flatten()\n",
        "      labels_flat = label_ids.flatten()\n",
        "\n",
        "    # Accumulation accuracy for all batch\n",
        "      total_pred += pred.tolist()\n",
        "\n",
        "    # Accumulation f1 for all batch\n",
        "      total_label += labels_flat.tolist()\n",
        "\n",
        "      # Logits score on positive \n",
        "      total_logits += logits.tolist()\n",
        "\n",
        "  return total_pred,total_label,total_logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLPLUSq6mWgc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_pred,total_label,total_logits =evaluation_loop(gender_model,val_loader_balanced_split)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Of_IfZYuEyJG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_report(pred,label,logits):\n",
        "    \"\"\"\n",
        "        Input :\n",
        "            pred : model prediction\n",
        "        Output : \n",
        "            Classification_report + Confusion_matrix + ROC_curve\n",
        "    \"\"\"\n",
        "    #from sklearn\n",
        "    import seaborn as sns\n",
        "    import matplotlib.pyplot as plt\n",
        "    from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_auc_score, roc_curve\n",
        "    logits = [el[1] for el in total_logits]\n",
        "    pred = [i for i in total_pred]\n",
        "    label = [i for i in total_label]\n",
        "    print (\"Classification report :\")\n",
        "    print(classification_report(label,pred))\n",
        "    print (\"Accuracy : \",accuracy_score(label,pred))\n",
        "    cm = confusion_matrix(label,pred)\n",
        "    ROC = roc_auc_score(label,pred) \n",
        "    print (\"AUC : \",ROC)\n",
        "    fpr,tpr,thresholds = roc_curve(label,logits)\n",
        "    plt.figure(figsize=(12,10))\n",
        "    plt.subplot(221)\n",
        "    sns.heatmap(cm/np.sum(cm), annot=True, \n",
        "            fmt='.2%', cmap='Blues').set_title('Matrice de confusion')\n",
        "    plt.subplot(222)\n",
        "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % ROC)\n",
        "    plt.plot([0,1],[0,1],color='red')\n",
        "    plt.title('Courbe ROC')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOvGlNbxOSPq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_report(total_pred,total_label,logits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqkoWqvuv0AL",
        "colab_type": "text"
      },
      "source": [
        "The model seem to be slightly more performant at predicting female speakers than male speakers. We reach good metrics for both accuracy and F1 score. More than 80 % of our predictions are correct. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syd2rBrsSLro",
        "colab_type": "text"
      },
      "source": [
        "### Qualitative analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9-lOx5RR-6B",
        "colab_type": "text"
      },
      "source": [
        "We will use our development set prepared earlier "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35VdN-qmuDwu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We prepare again the development sample for analysis \n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import CamembertTokenizer\n",
        "\n",
        "texts = dev_balanced_split.Texte.values\n",
        "labels = dev_balanced_split.sexe.values\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-base', do_lower_case=False,padding_side='right')\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "num_truncated_tokens =[]\n",
        "\n",
        "for text in texts:\n",
        "  encoded_dict = tokenizer.encode_plus(\n",
        "                        text,                      # text\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 500,           # We choose for now a max length of 500.\n",
        "                        pad_to_max_length = True,    # Pad text to max \n",
        "                        return_attention_mask = True,   # Construct attention masks\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                        return_overflowing_tokens =True, # return overflowing token information\n",
        "                  )\n",
        "    \n",
        "    # Map tokens to their id in the dictionnary \n",
        "    # We add this to our list    \n",
        "  input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "    #num_truncated_tokens.append(encoded_dict['num_truncated_tokens'])\n",
        "    \n",
        "    # 3. Attention masks\n",
        "  attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# We convert all this into tensors in order to be able to make it work on GPU \n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Original text and transformed tensor print \n",
        "print(\"Let's check for the first text indexes, attention masks and labels\")\n",
        "print(\" \")\n",
        "print('Original: ', texts[0][0:100])\n",
        "print('IDs:', input_ids[0][0:100])\n",
        "print('Attention masks:', attention_masks[0][0:100])\n",
        "print('labels',labels[0])\n",
        "\n",
        "# Combine all above\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "# We create data loaders for the train and validation dataset. \n",
        "dev_dataloader = DataLoader(\n",
        "            dataset,  # The training samples.\n",
        "            batch_size = 16, # Trains with this batch size.\n",
        "            shuffle=False\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXVKl1flXbkz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We make this development sample pass into the evaluation loop \n",
        "total_pred,total_labels,total_logits=evaluation_loop(gender_model,dev_dataloader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUXJqxup1gF0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dev_treatment(total_pred,total_labels,total_logits,dev_balanced_split,df):\n",
        "  ''' \n",
        "  This function takes as input the results of the models, compute some statistics and merges the results\n",
        "  with our first dataset\n",
        "\n",
        " Input : \n",
        "        model predictions, model labels, model scores, development sample and original data\n",
        " Output : \n",
        "        merged dataset\n",
        "  '''\n",
        "  # Extract the score for label 1 and the maximum score \n",
        "  one_score = [el[1] for el in total_logits]\n",
        "  max_score = np.max(total_logits,axis=1)\n",
        "\n",
        "  # Put everything inside a dataframe\n",
        "  results_dev=pd.DataFrame([total_labels,total_pred,one_score,max_score]).transpose()\n",
        "  results_dev.columns=['returned_labels','model_pred','one_score','max_score']\n",
        "  results_dev['WF']=pd.DataFrame([results_dev['model_pred']==results_dev['returned_labels']]).transpose()\n",
        "  results_dev['model_pred'] = results_dev['model_pred'].astype(int)\n",
        "  results_dev['returned_labels'] = results_dev['returned_labels'].astype(int)\n",
        "\n",
        "  # Merge back with the text\n",
        "  frames = [dev_balanced_split[['Texte','sexe','index_df']].reset_index(), results_dev]\n",
        "  result = pd.concat(frames,axis=1)\n",
        "\n",
        "  # We merge this dataframe to the information we had at the beginning\n",
        "  merged_results=result[['index','index_df','Texte','returned_labels','model_pred','one_score','max_score','WF']].merge(df[['Titre','Id','Theme','Prenom','Nom','Date','Tags','sexe']],how='left',left_on='index_df',right_on='Id')\n",
        "\n",
        "  return merged_results\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCwaMpvL2Ly2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result =  dev_treatment(total_pred,total_labels,total_logits,dev_balanced_split,df_balanced)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TA883RZ42uh8",
        "colab_type": "code",
        "outputId": "84e138ca-1ced-4316-f889-ef2d342a9980",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "source": [
        "result.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>index_df</th>\n",
              "      <th>Texte</th>\n",
              "      <th>returned_labels</th>\n",
              "      <th>model_pred</th>\n",
              "      <th>one_score</th>\n",
              "      <th>max_score</th>\n",
              "      <th>WF</th>\n",
              "      <th>Titre</th>\n",
              "      <th>Id</th>\n",
              "      <th>Theme</th>\n",
              "      <th>Prenom</th>\n",
              "      <th>Nom</th>\n",
              "      <th>Date</th>\n",
              "      <th>Tags</th>\n",
              "      <th>sexe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10826</td>\n",
              "      <td>134631</td>\n",
              "      <td>Et c'est bien là que se noue la question esse...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.427388</td>\n",
              "      <td>1.427388</td>\n",
              "      <td>True</td>\n",
              "      <td>Déclaration de Mme Catherine Trautmann, minist...</td>\n",
              "      <td>134631</td>\n",
              "      <td>Institutions</td>\n",
              "      <td>Catherine</td>\n",
              "      <td>Trautmann</td>\n",
              "      <td>1998-01-11T12:00:00Z</td>\n",
              "      <td>Justice - Droits fondamentaux,Antisémitisme</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10827</td>\n",
              "      <td>170264</td>\n",
              "      <td>C'est un bonheur que de constater la richesse...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2.155089</td>\n",
              "      <td>2.155089</td>\n",
              "      <td>True</td>\n",
              "      <td>Déclaration de Mme Roselyne Bachelot, ministre...</td>\n",
              "      <td>170264</td>\n",
              "      <td>Société</td>\n",
              "      <td>Roselyne</td>\n",
              "      <td>Bachelot-Narquin</td>\n",
              "      <td>2007-12-11T12:00:00Z</td>\n",
              "      <td>Société - Population,Personne âgée</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10828</td>\n",
              "      <td>192891</td>\n",
              "      <td>M. Roland Courteau. Très bien ! Mme Carole De...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2.370206</td>\n",
              "      <td>2.370206</td>\n",
              "      <td>True</td>\n",
              "      <td>Déclaration de MMe Carole Delga, secrétaire d'...</td>\n",
              "      <td>192891</td>\n",
              "      <td>Economie</td>\n",
              "      <td>Carole</td>\n",
              "      <td>Delga</td>\n",
              "      <td>2014-10-21T12:00:00Z</td>\n",
              "      <td>Vie économique,Politique économique</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10829</td>\n",
              "      <td>177095</td>\n",
              "      <td>Mais la crise a bouleversé tous les repères. ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.766086</td>\n",
              "      <td>0.766086</td>\n",
              "      <td>True</td>\n",
              "      <td>Déclaration de Mme Christine Lagarde, ministre...</td>\n",
              "      <td>177095</td>\n",
              "      <td>Economie</td>\n",
              "      <td>Christine</td>\n",
              "      <td>Lagarde</td>\n",
              "      <td>2009-10-20T12:00:00Z</td>\n",
              "      <td>Finances publiques,Budget de l'Etat</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10830</td>\n",
              "      <td>144772</td>\n",
              "      <td>Mesdames, Messieurs, j'ai souhaité, vous le s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.947491</td>\n",
              "      <td>1.946521</td>\n",
              "      <td>True</td>\n",
              "      <td>Déclaration de M. Jean-François Mattei, minist...</td>\n",
              "      <td>144772</td>\n",
              "      <td>Société</td>\n",
              "      <td>Jean-François</td>\n",
              "      <td>Mattei</td>\n",
              "      <td>2003-12-10T12:00:00Z</td>\n",
              "      <td>Santé - Protection sociale,Santé publique</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  index_df  ...                                         Tags  sexe\n",
              "0  10826    134631  ...  Justice - Droits fondamentaux,Antisémitisme     1\n",
              "1  10827    170264  ...           Société - Population,Personne âgée     1\n",
              "2  10828    192891  ...          Vie économique,Politique économique     1\n",
              "3  10829    177095  ...          Finances publiques,Budget de l'Etat     1\n",
              "4  10830    144772  ...    Santé - Protection sociale,Santé publique     0\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 417
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLF9aS31dH7M",
        "colab_type": "code",
        "outputId": "ba53b317-7b75-49b6-e75e-b3a8fca4f2ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Which texts failed ? \n",
        "print('{0:.2f} percent of the development texts were not well classified by our model'.format(result[result.WF==False].WF.count()*100/len(result)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12.54 percent of the development texts were not well classified by our model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtVSBuEp02VL",
        "colab_type": "text"
      },
      "source": [
        "For the next step let's take some texts that were well classified and other that do not. We will take examples for all possible options : badly predicted a woman, badly predicted a man, well predicted a woman and well predicted a man. We also try to take the ones the model was really sure about. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gy9_53i23Y2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "top_texts_true_m=result[(result.WF==1) & (result.model_pred==0)].nlargest(10,'max_score')\n",
        "top_texts_true_f=result[(result.WF==1) & (result.model_pred==1)].nlargest(10,'max_score')\n",
        "top_texts_false_m=result[(result.WF==0) & (result.model_pred==0)].nlargest(10,'max_score')\n",
        "top_texts_false_f=result[(result.WF==0) & (result.model_pred==1)].nlargest(10,'max_score')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mR8fnne6KHQH",
        "colab_type": "code",
        "outputId": "97b426a4-5bd3-4d05-ea16-5782bbe34c6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Texts that were well classified as men \n",
        "top_texts_true_m.head(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>index_df</th>\n",
              "      <th>Texte</th>\n",
              "      <th>returned_labels</th>\n",
              "      <th>model_pred</th>\n",
              "      <th>one_score</th>\n",
              "      <th>max_score</th>\n",
              "      <th>WF</th>\n",
              "      <th>Titre</th>\n",
              "      <th>Id</th>\n",
              "      <th>Theme</th>\n",
              "      <th>Prenom</th>\n",
              "      <th>Nom</th>\n",
              "      <th>Date</th>\n",
              "      <th>Tags</th>\n",
              "      <th>sexe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>10973</td>\n",
              "      <td>140199</td>\n",
              "      <td>Je ne suis pas toujours d'accord avec monsieu...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-2.588010</td>\n",
              "      <td>2.579525</td>\n",
              "      <td>True</td>\n",
              "      <td>Déclaration de M. Jean-Pierre Raffarin, Premie...</td>\n",
              "      <td>140199</td>\n",
              "      <td>International</td>\n",
              "      <td>Jean-Pierre</td>\n",
              "      <td>Raffarin</td>\n",
              "      <td>2003-10-06T12:00:00Z</td>\n",
              "      <td>Relations internationales,Relations bilatérale...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>10870</td>\n",
              "      <td>134262</td>\n",
              "      <td>J'ai confiance, car je connais la vitalité et...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-2.591268</td>\n",
              "      <td>2.575959</td>\n",
              "      <td>True</td>\n",
              "      <td>Discours de M. Jacques Chirac, Président de la...</td>\n",
              "      <td>134262</td>\n",
              "      <td>International,Société</td>\n",
              "      <td>Jacques</td>\n",
              "      <td>Chirac</td>\n",
              "      <td>1997-03-17T12:00:00Z</td>\n",
              "      <td>Relations internationales,Relations bilatérale...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>240</th>\n",
              "      <td>11066</td>\n",
              "      <td>142205</td>\n",
              "      <td>La première de ces pistes concerne les perspe...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-2.577943</td>\n",
              "      <td>2.570937</td>\n",
              "      <td>True</td>\n",
              "      <td>Déclaration de M. Jean-Pierre Raffarin, Premie...</td>\n",
              "      <td>142205</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Jean-Pierre</td>\n",
              "      <td>Raffarin</td>\n",
              "      <td>2003-12-01T12:00:00Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>281</th>\n",
              "      <td>11107</td>\n",
              "      <td>127710</td>\n",
              "      <td>De ce point de vue, notre conception est diff...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-2.563087</td>\n",
              "      <td>2.570248</td>\n",
              "      <td>True</td>\n",
              "      <td>Déclaration de M. Lionel Jospin, Premier minis...</td>\n",
              "      <td>127710</td>\n",
              "      <td>Institutions</td>\n",
              "      <td>Lionel</td>\n",
              "      <td>Jospin</td>\n",
              "      <td>2002-03-20T12:00:00Z</td>\n",
              "      <td>Citoyenneté - Elections,Personnalité politique</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321</th>\n",
              "      <td>11147</td>\n",
              "      <td>186309</td>\n",
              "      <td>Mesdames, Messieurs,Dans une assemblée qui es...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-2.585277</td>\n",
              "      <td>2.564062</td>\n",
              "      <td>True</td>\n",
              "      <td>Déclaration de M. Pascal Canfin, ministre du d...</td>\n",
              "      <td>186309</td>\n",
              "      <td>International</td>\n",
              "      <td>Pascal</td>\n",
              "      <td>Canfin</td>\n",
              "      <td>2012-11-05T12:00:00Z</td>\n",
              "      <td>Relations internationales,Aide internationale</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>239</th>\n",
              "      <td>11065</td>\n",
              "      <td>133642</td>\n",
              "      <td>Mesdames et Messieurs, j'ai été très heureux ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-2.569544</td>\n",
              "      <td>2.558361</td>\n",
              "      <td>True</td>\n",
              "      <td>Déclaration de M. Hervé de Charette, ministre ...</td>\n",
              "      <td>133642</td>\n",
              "      <td>International</td>\n",
              "      <td>Hervé</td>\n",
              "      <td>de Charette</td>\n",
              "      <td>1997-01-13T12:00:00Z</td>\n",
              "      <td>Relations internationales,Relations bilatérale...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>10837</td>\n",
              "      <td>187341</td>\n",
              "      <td>Et, s'agissant des jeunes les moins qualifiés...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-2.562876</td>\n",
              "      <td>2.556654</td>\n",
              "      <td>True</td>\n",
              "      <td>Déclaration de M. Jean-Marc Ayrault, Premier m...</td>\n",
              "      <td>187341</td>\n",
              "      <td>Société</td>\n",
              "      <td>Jean-Marc</td>\n",
              "      <td>Ayrault</td>\n",
              "      <td>2013-02-28T12:00:00Z</td>\n",
              "      <td>Sciences - Numérique - I. A.,Internet</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>10880</td>\n",
              "      <td>146246</td>\n",
              "      <td>Monsieur le Président,Messieurs les Rapporteu...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-2.581499</td>\n",
              "      <td>2.555746</td>\n",
              "      <td>True</td>\n",
              "      <td>Déclaration de M. Galouzeau de Villepin, minis...</td>\n",
              "      <td>146246</td>\n",
              "      <td>Economie</td>\n",
              "      <td>Dominique</td>\n",
              "      <td>de Villepin</td>\n",
              "      <td>2004-11-16T12:00:00Z</td>\n",
              "      <td>Finances publiques,Budget de l'Etat</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>10911</td>\n",
              "      <td>144410</td>\n",
              "      <td>Monsieur le Président,Mesdames et Messieurs l...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-2.563626</td>\n",
              "      <td>2.554979</td>\n",
              "      <td>True</td>\n",
              "      <td>Déclaration de M. Michel Barnier, ministre des...</td>\n",
              "      <td>144410</td>\n",
              "      <td>International</td>\n",
              "      <td>Michel</td>\n",
              "      <td>Barnier</td>\n",
              "      <td>2004-10-19T12:00:00Z</td>\n",
              "      <td>Relations internationales,Relations bilatérale...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223</th>\n",
              "      <td>11049</td>\n",
              "      <td>183629</td>\n",
              "      <td>Ces devoirs, cette exigence, chacun d'entre v...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-2.565979</td>\n",
              "      <td>2.553955</td>\n",
              "      <td>True</td>\n",
              "      <td>Déclaration de M. Nicolas Sarkozy, Président d...</td>\n",
              "      <td>183629</td>\n",
              "      <td>Institutions</td>\n",
              "      <td>Nicolas</td>\n",
              "      <td>Sarkozy</td>\n",
              "      <td>2011-11-23T12:00:00Z</td>\n",
              "      <td>Institutions de l'Etat,Politique gouvernementale</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     index  index_df  ...                                               Tags  sexe\n",
              "147  10973    140199  ...  Relations internationales,Relations bilatérale...     0\n",
              "44   10870    134262  ...  Relations internationales,Relations bilatérale...     0\n",
              "240  11066    142205  ...                                                NaN     0\n",
              "281  11107    127710  ...     Citoyenneté - Elections,Personnalité politique     0\n",
              "321  11147    186309  ...      Relations internationales,Aide internationale     0\n",
              "239  11065    133642  ...  Relations internationales,Relations bilatérale...     0\n",
              "11   10837    187341  ...              Sciences - Numérique - I. A.,Internet     0\n",
              "54   10880    146246  ...                Finances publiques,Budget de l'Etat     0\n",
              "85   10911    144410  ...  Relations internationales,Relations bilatérale...     0\n",
              "223  11049    183629  ...   Institutions de l'Etat,Politique gouvernementale     0\n",
              "\n",
              "[10 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 420
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4MGbB9j3koA",
        "colab_type": "code",
        "outputId": "92dd88ef-3a42-415a-ff8d-03ae42331535",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Texts that were well classified as women \n",
        "top_texts_true_f.head(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>index_df</th>\n",
              "      <th>Texte</th>\n",
              "      <th>returned_labels</th>\n",
              "      <th>model_pred</th>\n",
              "      <th>one_score</th>\n",
              "      <th>max_score</th>\n",
              "      <th>WF</th>\n",
              "      <th>Titre</th>\n",
              "      <th>Id</th>\n",
              "      <th>Theme</th>\n",
              "      <th>Prenom</th>\n",
              "      <th>Nom</th>\n",
              "      <th>Date</th>\n",
              "      <th>Tags</th>\n",
              "      <th>sexe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>11085</td>\n",
              "      <td>207242</td>\n",
              "      <td>pourquoi baisser le budget de l'inspection du...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2.427634</td>\n",
              "      <td>2.427634</td>\n",
              "      <td>True</td>\n",
              "      <td>Déclaration de Mme Muriel Pénicaud, ministre d...</td>\n",
              "      <td>207242</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Muriel</td>\n",
              "      <td>Penicaud</td>\n",
              "      <td>2018-11-09T12:00:00Z</td>\n",
              "      <td>Loi</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262</th>\n",
              "      <td>11088</td>\n",
              "      <td>272410</td>\n",
              "      <td>Il s'agit d'une réponse concrète et d'une pol...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2.411540</td>\n",
              "      <td>2.411540</td>\n",
              "      <td>True</td>\n",
              "      <td>Déclaration de Mme Élisabeth Borne, ministre d...</td>\n",
              "      <td>272410</td>\n",
              "      <td>Société</td>\n",
              "      <td>Elisabeth</td>\n",
              "      <td>Borne</td>\n",
              "      <td>2019-10-03T12:00:00Z</td>\n",
              "      <td>Environnement,Politique de l'environnement,Climat</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>11030</td>\n",
              "      <td>272410</td>\n",
              "      <td>En période de canicule, comme en période de v...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2.402071</td>\n",
              "      <td>2.402071</td>\n",
              "      <td>True</td>\n",
              "      <td>Déclaration de Mme Élisabeth Borne, ministre d...</td>\n",
              "      <td>272410</td>\n",
              "      <td>Société</td>\n",
              "      <td>Elisabeth</td>\n",
              "      <td>Borne</td>\n",
              "      <td>2019-10-03T12:00:00Z</td>\n",
              "      <td>Environnement,Politique de l'environnement,Climat</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>212</th>\n",
              "      <td>11038</td>\n",
              "      <td>269666</td>\n",
              "      <td>Jeux Olympiques et Paralympiques de 2024 Adop...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2.385171</td>\n",
              "      <td>2.385171</td>\n",
              "      <td>True</td>\n",
              "      <td>Déclaration de Mme Roxana Maracineanu, ministr...</td>\n",
              "      <td>269666</td>\n",
              "      <td>Société</td>\n",
              "      <td>Roxana</td>\n",
              "      <td>Maracineanu</td>\n",
              "      <td>2019-07-24T12:00:00Z</td>\n",
              "      <td>Société - Population,Sport</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168</th>\n",
              "      <td>10994</td>\n",
              "      <td>141170</td>\n",
              "      <td>Il lui appartient donc d'affirmer sa spécific...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2.382982</td>\n",
              "      <td>2.382982</td>\n",
              "      <td>True</td>\n",
              "      <td>Déclaration de Mme Marie-George Buffet, minist...</td>\n",
              "      <td>141170</td>\n",
              "      <td>Société</td>\n",
              "      <td>Marie-George</td>\n",
              "      <td>Buffet</td>\n",
              "      <td>2000-02-01T12:00:00Z</td>\n",
              "      <td>Société - Population,Sport</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>10840</td>\n",
              "      <td>194307</td>\n",
              "      <td>Cette Charte qui favorise la confiance dans l...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2.382407</td>\n",
              "      <td>2.382407</td>\n",
              "      <td>True</td>\n",
              "      <td>Déclaration de Mme Fleur Pellerin, ministre de...</td>\n",
              "      <td>194307</td>\n",
              "      <td>Economie</td>\n",
              "      <td>Fleur</td>\n",
              "      <td>Pellerin</td>\n",
              "      <td>2015-03-23T12:00:00Z</td>\n",
              "      <td>Vie économique,Consommation</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>10932</td>\n",
              "      <td>269377</td>\n",
              "      <td>Mme la présidente. L'ordre du jour appelle la...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2.377258</td>\n",
              "      <td>2.377258</td>\n",
              "      <td>True</td>\n",
              "      <td>Déclaration de Mme Amélie de Montchalin, secré...</td>\n",
              "      <td>269377</td>\n",
              "      <td>International</td>\n",
              "      <td>Amélie</td>\n",
              "      <td>de Montchalin</td>\n",
              "      <td>2019-07-08T12:00:00Z</td>\n",
              "      <td>Europe,Luxembourg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>170</th>\n",
              "      <td>10996</td>\n",
              "      <td>165099</td>\n",
              "      <td>Le rapport va de 1 à 5 pour les moins mal lot...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2.375841</td>\n",
              "      <td>2.375841</td>\n",
              "      <td>True</td>\n",
              "      <td>Déclaration de Mme Arlette Laguiller, porte-pa...</td>\n",
              "      <td>165099</td>\n",
              "      <td>Institutions</td>\n",
              "      <td>Arlette</td>\n",
              "      <td>Laguiller</td>\n",
              "      <td>2007-01-19T12:00:00Z</td>\n",
              "      <td>Citoyenneté - Elections,Parti politique,Electi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>10888</td>\n",
              "      <td>166255</td>\n",
              "      <td>Tous les deux procèdent pourtant à la suppres...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2.372942</td>\n",
              "      <td>2.372942</td>\n",
              "      <td>True</td>\n",
              "      <td>Déclaration de Mme Arlette Laguiller, porte-pa...</td>\n",
              "      <td>166255</td>\n",
              "      <td>Institutions</td>\n",
              "      <td>Arlette</td>\n",
              "      <td>Laguiller</td>\n",
              "      <td>2007-04-03T12:00:00Z</td>\n",
              "      <td>Citoyenneté - Elections,Election présidentiell...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>10873</td>\n",
              "      <td>180222</td>\n",
              "      <td>Et si et seulement si, à l'issue de cette dém...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2.371567</td>\n",
              "      <td>2.371567</td>\n",
              "      <td>True</td>\n",
              "      <td>Déclaration de Mme Chantal Jouanno, secrétaire...</td>\n",
              "      <td>180222</td>\n",
              "      <td>Société</td>\n",
              "      <td>Chantal</td>\n",
              "      <td>Jouanno</td>\n",
              "      <td>2010-10-19T12:00:00Z</td>\n",
              "      <td>Environnement,Politique de l'environnement,Pro...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     index  index_df  ...                                               Tags  sexe\n",
              "259  11085    207242  ...                                                Loi     1\n",
              "262  11088    272410  ...  Environnement,Politique de l'environnement,Climat     1\n",
              "204  11030    272410  ...  Environnement,Politique de l'environnement,Climat     1\n",
              "212  11038    269666  ...                         Société - Population,Sport     1\n",
              "168  10994    141170  ...                         Société - Population,Sport     1\n",
              "14   10840    194307  ...                        Vie économique,Consommation     1\n",
              "106  10932    269377  ...                                  Europe,Luxembourg     1\n",
              "170  10996    165099  ...  Citoyenneté - Elections,Parti politique,Electi...     1\n",
              "62   10888    166255  ...  Citoyenneté - Elections,Election présidentiell...     1\n",
              "47   10873    180222  ...  Environnement,Politique de l'environnement,Pro...     1\n",
              "\n",
              "[10 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 421
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjUtMELhzVrO",
        "colab_type": "code",
        "outputId": "3828e260-65c0-406e-966a-c9be259b2556",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Texts that were wrongly classified as men \n",
        "top_texts_false_m.head(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>index_df</th>\n",
              "      <th>Texte</th>\n",
              "      <th>returned_labels</th>\n",
              "      <th>model_pred</th>\n",
              "      <th>one_score</th>\n",
              "      <th>max_score</th>\n",
              "      <th>WF</th>\n",
              "      <th>Titre</th>\n",
              "      <th>Id</th>\n",
              "      <th>Theme</th>\n",
              "      <th>Prenom</th>\n",
              "      <th>Nom</th>\n",
              "      <th>Date</th>\n",
              "      <th>Tags</th>\n",
              "      <th>sexe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>186</th>\n",
              "      <td>11012</td>\n",
              "      <td>180950</td>\n",
              "      <td>Messieurs les ministres,Madame la présidente,...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-2.295846</td>\n",
              "      <td>2.318840</td>\n",
              "      <td>False</td>\n",
              "      <td>Déclaration de Mme Christine Lagarde, ministre...</td>\n",
              "      <td>180950</td>\n",
              "      <td>Economie</td>\n",
              "      <td>Christine</td>\n",
              "      <td>Lagarde</td>\n",
              "      <td>2011-01-14T12:00:00Z</td>\n",
              "      <td>Vie économique,Politique économique</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>10997</td>\n",
              "      <td>167570</td>\n",
              "      <td>Je viens d'apprendre avec soulagement que le ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-2.191277</td>\n",
              "      <td>2.169469</td>\n",
              "      <td>False</td>\n",
              "      <td>Déclaration de Mme Rama Yade, secrétaire d'Eta...</td>\n",
              "      <td>167570</td>\n",
              "      <td>Institutions</td>\n",
              "      <td>Rama</td>\n",
              "      <td>Yade</td>\n",
              "      <td>2007-08-30T12:00:00Z</td>\n",
              "      <td>Justice - Droits fondamentaux,Peine</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>10946</td>\n",
              "      <td>144150</td>\n",
              "      <td>Ensuite il s'étonne : \" Pourtant, écrit-il, i...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-2.057754</td>\n",
              "      <td>2.138344</td>\n",
              "      <td>False</td>\n",
              "      <td>Déclaration de Mme Marine Le Pen, vice-préside...</td>\n",
              "      <td>144150</td>\n",
              "      <td>Institutions</td>\n",
              "      <td>Marine</td>\n",
              "      <td>Le Pen</td>\n",
              "      <td>2003-11-08T12:00:00Z</td>\n",
              "      <td>Citoyenneté - Elections,Parti politique</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>10853</td>\n",
              "      <td>189103</td>\n",
              "      <td>Merci pour la qualité du travail que vous ave...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-2.003781</td>\n",
              "      <td>2.037219</td>\n",
              "      <td>False</td>\n",
              "      <td>Déclaration de Mme Christiane Taubira, garde d...</td>\n",
              "      <td>189103</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Christiane</td>\n",
              "      <td>Taubira</td>\n",
              "      <td>2013-09-17T12:00:00Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>10942</td>\n",
              "      <td>270297</td>\n",
              "      <td>C'est donc dans cet équilibre que nous devons...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.931948</td>\n",
              "      <td>2.007101</td>\n",
              "      <td>False</td>\n",
              "      <td>Déclaration de Mme Nicole Belloubet, garde des...</td>\n",
              "      <td>270297</td>\n",
              "      <td>Institutions</td>\n",
              "      <td>Nicole</td>\n",
              "      <td>Belloubet</td>\n",
              "      <td>2019-03-05T12:00:00Z</td>\n",
              "      <td>Justice - Droits fondamentaux,Droit</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>10998</td>\n",
              "      <td>130641</td>\n",
              "      <td>Ces Assises veulent mettre en valeur des mili...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.930106</td>\n",
              "      <td>1.963277</td>\n",
              "      <td>False</td>\n",
              "      <td>Déclaration de Mme Michèle Alliot-Marie, prési...</td>\n",
              "      <td>130641</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Michèle</td>\n",
              "      <td>Alliot-Marie</td>\n",
              "      <td>2000-06-17T12:00:00Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>160</th>\n",
              "      <td>10986</td>\n",
              "      <td>147261</td>\n",
              "      <td>Au-delà de la compensation financière proprem...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.813977</td>\n",
              "      <td>1.875399</td>\n",
              "      <td>False</td>\n",
              "      <td>Déclaration de Mme Marie-José Roig, ministre d...</td>\n",
              "      <td>147261</td>\n",
              "      <td>Institutions</td>\n",
              "      <td>Marie-Josée</td>\n",
              "      <td>Roig</td>\n",
              "      <td>2005-04-05T12:00:00Z</td>\n",
              "      <td>Administration - Réforme de l'Etat,Décentralis...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>10861</td>\n",
              "      <td>149424</td>\n",
              "      <td>la promotion des Droits de l'Homme, la démocr...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.625877</td>\n",
              "      <td>1.701874</td>\n",
              "      <td>False</td>\n",
              "      <td>Déclaration de Mme Catherine Colonna, ministre...</td>\n",
              "      <td>149424</td>\n",
              "      <td>International</td>\n",
              "      <td>Catherine</td>\n",
              "      <td>Colonna</td>\n",
              "      <td>2005-10-10T12:00:00Z</td>\n",
              "      <td>Union européenne,Politique européenne de sécur...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>10913</td>\n",
              "      <td>195136</td>\n",
              "      <td>Je souhaite à cet égard donner quelques exemp...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.643578</td>\n",
              "      <td>1.677818</td>\n",
              "      <td>False</td>\n",
              "      <td>Déclaration de Mme Myriam El Khomri, secrétair...</td>\n",
              "      <td>195136</td>\n",
              "      <td>Société</td>\n",
              "      <td>Myriam</td>\n",
              "      <td>El Khomri</td>\n",
              "      <td>2015-05-26T12:00:00Z</td>\n",
              "      <td>Ville - Territoires,Urbanisme</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>10845</td>\n",
              "      <td>197523</td>\n",
              "      <td>Monsieur le Secrétaire général,Madame la Dire...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.676022</td>\n",
              "      <td>1.665086</td>\n",
              "      <td>False</td>\n",
              "      <td>Déclaration de Mme Annick Girardin, secrétaire...</td>\n",
              "      <td>197523</td>\n",
              "      <td>International</td>\n",
              "      <td>Annick</td>\n",
              "      <td>Girardin</td>\n",
              "      <td>2016-01-07T12:00:00Z</td>\n",
              "      <td>Relations internationales,Aide internationale</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     index  index_df  ...                                               Tags  sexe\n",
              "186  11012    180950  ...                Vie économique,Politique économique     1\n",
              "171  10997    167570  ...                Justice - Droits fondamentaux,Peine     1\n",
              "120  10946    144150  ...            Citoyenneté - Elections,Parti politique     1\n",
              "27   10853    189103  ...                                                NaN     1\n",
              "116  10942    270297  ...                Justice - Droits fondamentaux,Droit     1\n",
              "172  10998    130641  ...                                                NaN     1\n",
              "160  10986    147261  ...  Administration - Réforme de l'Etat,Décentralis...     1\n",
              "35   10861    149424  ...  Union européenne,Politique européenne de sécur...     1\n",
              "87   10913    195136  ...                      Ville - Territoires,Urbanisme     1\n",
              "19   10845    197523  ...      Relations internationales,Aide internationale     1\n",
              "\n",
              "[10 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 422
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmd8NwXRzXCA",
        "colab_type": "code",
        "outputId": "81cbef70-d0cc-4a09-9568-9a2da20391a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Texts that were wrongly classified as women\n",
        "top_texts_false_f.head(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>index_df</th>\n",
              "      <th>Texte</th>\n",
              "      <th>returned_labels</th>\n",
              "      <th>model_pred</th>\n",
              "      <th>one_score</th>\n",
              "      <th>max_score</th>\n",
              "      <th>WF</th>\n",
              "      <th>Titre</th>\n",
              "      <th>Id</th>\n",
              "      <th>Theme</th>\n",
              "      <th>Prenom</th>\n",
              "      <th>Nom</th>\n",
              "      <th>Date</th>\n",
              "      <th>Tags</th>\n",
              "      <th>sexe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>333</th>\n",
              "      <td>11159</td>\n",
              "      <td>143412</td>\n",
              "      <td>Pourquoi ? Parce qu'il est de la plus haute i...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2.085198</td>\n",
              "      <td>2.085198</td>\n",
              "      <td>False</td>\n",
              "      <td>Déclaration de M. Christian Poncelet, présiden...</td>\n",
              "      <td>143412</td>\n",
              "      <td>Institutions</td>\n",
              "      <td>Christian</td>\n",
              "      <td>Poncelet</td>\n",
              "      <td>2004-06-15T12:00:00Z</td>\n",
              "      <td>Administration - Réforme de l'Etat,Organisme p...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>10936</td>\n",
              "      <td>179305</td>\n",
              "      <td>il est en effet nécessaire qu'ils s'approprie...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2.071807</td>\n",
              "      <td>2.071807</td>\n",
              "      <td>False</td>\n",
              "      <td>Déclaration de M. Bernard Kouchner, ministre d...</td>\n",
              "      <td>179305</td>\n",
              "      <td>International</td>\n",
              "      <td>Bernard</td>\n",
              "      <td>Kouchner</td>\n",
              "      <td>2010-06-16T12:00:00Z</td>\n",
              "      <td>Union européenne,Institutions européennes</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>269</th>\n",
              "      <td>11095</td>\n",
              "      <td>192416</td>\n",
              "      <td>Mesdames et messieurs,Je vous remercie pour c...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2.065740</td>\n",
              "      <td>2.065740</td>\n",
              "      <td>False</td>\n",
              "      <td>Déclaration de M. François Rebsamen, ministre ...</td>\n",
              "      <td>192416</td>\n",
              "      <td>Economie</td>\n",
              "      <td>François</td>\n",
              "      <td>Rebsamen</td>\n",
              "      <td>2014-09-10T12:00:00Z</td>\n",
              "      <td>Vie économique,Secteur industriel</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>11029</td>\n",
              "      <td>201326</td>\n",
              "      <td>Je n'en prendrai qu'un exemple : le divorce p...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2.003410</td>\n",
              "      <td>2.003410</td>\n",
              "      <td>False</td>\n",
              "      <td>Déclaration de M. Jean-Jacques Urvoas, garde d...</td>\n",
              "      <td>201326</td>\n",
              "      <td>Institutions</td>\n",
              "      <td>Jean-Jacques</td>\n",
              "      <td>Urvoas</td>\n",
              "      <td>2016-11-25T12:00:00Z</td>\n",
              "      <td>Justice - Droits fondamentaux,Profession judic...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>252</th>\n",
              "      <td>11078</td>\n",
              "      <td>179340</td>\n",
              "      <td>Monsieur le Député,Je vous prie d'excuser l'a...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.923732</td>\n",
              "      <td>1.923732</td>\n",
              "      <td>False</td>\n",
              "      <td>Déclaration de M. Hervé Novelli, secrétaire d'...</td>\n",
              "      <td>179340</td>\n",
              "      <td>Economie</td>\n",
              "      <td>Hervé</td>\n",
              "      <td>Novelli</td>\n",
              "      <td>2010-06-22T12:00:00Z</td>\n",
              "      <td>Banque - Finance,Marché financier</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>10968</td>\n",
              "      <td>188428</td>\n",
              "      <td>La place de l'enfant et le rapport entre enfa...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.808683</td>\n",
              "      <td>1.808683</td>\n",
              "      <td>False</td>\n",
              "      <td>Déclaration de Mme Dominique Bertinotti, minis...</td>\n",
              "      <td>188428</td>\n",
              "      <td>Société</td>\n",
              "      <td>Dominique</td>\n",
              "      <td>Bertinotti</td>\n",
              "      <td>2013-06-14T12:00:00Z</td>\n",
              "      <td>Sécurité,Maltraitance</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211</th>\n",
              "      <td>11037</td>\n",
              "      <td>170519</td>\n",
              "      <td>C'est un établissement convivial, très appréc...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.801611</td>\n",
              "      <td>1.801611</td>\n",
              "      <td>False</td>\n",
              "      <td>Déclaration de M. Lionel Jospin, Premier minis...</td>\n",
              "      <td>170519</td>\n",
              "      <td>International</td>\n",
              "      <td>Lionel</td>\n",
              "      <td>Jospin</td>\n",
              "      <td>2001-04-06T12:00:00Z</td>\n",
              "      <td>Relations internationales,Relations bilatérale...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>10915</td>\n",
              "      <td>186717</td>\n",
              "      <td>- tout d'abord, celui de l'accessibilité des...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.748953</td>\n",
              "      <td>1.748953</td>\n",
              "      <td>False</td>\n",
              "      <td>Déclaration de Mme George Pau-Langevin, minist...</td>\n",
              "      <td>186717</td>\n",
              "      <td>Société</td>\n",
              "      <td>George</td>\n",
              "      <td>Pau-Langevin</td>\n",
              "      <td>2012-11-13T12:00:00Z</td>\n",
              "      <td>Santé - Protection sociale,Soin médical</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>313</th>\n",
              "      <td>11139</td>\n",
              "      <td>181728</td>\n",
              "      <td>Mesdames et Messieurs les présidents,Mesdames...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.485748</td>\n",
              "      <td>1.485748</td>\n",
              "      <td>False</td>\n",
              "      <td>Déclaration de M. Eric Besson ministre de l'in...</td>\n",
              "      <td>181728</td>\n",
              "      <td>Economie</td>\n",
              "      <td>Eric</td>\n",
              "      <td>Besson</td>\n",
              "      <td>2011-03-29T12:00:00Z</td>\n",
              "      <td>Energie - Transports,Politique de l'énergie</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205</th>\n",
              "      <td>11031</td>\n",
              "      <td>144820</td>\n",
              "      <td>- un service d'inspection générale de l'envir...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.068702</td>\n",
              "      <td>1.068702</td>\n",
              "      <td>False</td>\n",
              "      <td>Déclaration de Mme Dominique Voynet, ministre ...</td>\n",
              "      <td>144820</td>\n",
              "      <td>Société</td>\n",
              "      <td>Dominique</td>\n",
              "      <td>Voynet</td>\n",
              "      <td>2000-09-20T12:00:00Z</td>\n",
              "      <td>Ville - Territoires,Aménagement du territoire</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     index  index_df  ...                                               Tags  sexe\n",
              "333  11159    143412  ...  Administration - Réforme de l'Etat,Organisme p...     0\n",
              "110  10936    179305  ...          Union européenne,Institutions européennes     0\n",
              "269  11095    192416  ...                  Vie économique,Secteur industriel     0\n",
              "203  11029    201326  ...  Justice - Droits fondamentaux,Profession judic...     0\n",
              "252  11078    179340  ...                  Banque - Finance,Marché financier     0\n",
              "142  10968    188428  ...                              Sécurité,Maltraitance     0\n",
              "211  11037    170519  ...  Relations internationales,Relations bilatérale...     0\n",
              "89   10915    186717  ...            Santé - Protection sociale,Soin médical     0\n",
              "313  11139    181728  ...        Energie - Transports,Politique de l'énergie     0\n",
              "205  11031    144820  ...      Ville - Territoires,Aménagement du territoire     0\n",
              "\n",
              "[10 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 423
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjJlGCVmhlsW",
        "colab_type": "text"
      },
      "source": [
        "We want to dive a bit into the model and see how it makes a choice and why it fails to recognize the gender of the speaker on these sentences . Let's take some of them. We will redo point 4 of TD4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQWuNom8MMcA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def split_document_to_limit_phrases(MAX_TOKENS,df):\n",
        "  lst= []\n",
        "  for index,row in df.iterrows():\n",
        "    identifiant = row.Id\n",
        "    label = row.sexe\n",
        "    phrase = ''\n",
        "    for phrases in sent_detector_mano(row.Texte):\n",
        "      if len(phrase.split(' ')) + len(phrases.split(' ')) < MAX_TOKENS:\n",
        "        phrase+= \" \" + phrases\n",
        "      else:\n",
        "        lst += [(identifiant,label,phrase,len(phrase.split(' ')))]\n",
        "        phrase = ''\n",
        "    lst += [(identifiant,label,phrase,len(phrase.split(' ')))]\n",
        "    phrase = ''\n",
        "  return pd.DataFrame(lst,columns=['index_df','sexe','Texte','Length'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XKOwjLLh7u4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We split those texts into pieces of 50 tokens\n",
        "sentence_to_analyse = pd.concat([top_texts_false_m,top_texts_true_m,top_texts_true_f,top_texts_true_f]).reset_index(drop=True)\n",
        "sentence_to_analyse=split_document_to_limit_phrases(60,sentence_to_analyse)\n",
        "sentence_to_analyse=sentence_to_analyse[sentence_to_analyse.Texte!='']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZLxjL043Zqv",
        "colab_type": "code",
        "outputId": "9a1b49fa-33fa-468a-a25d-a1cb2935818f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# Sentences we will analyze\n",
        "sentence_to_analyse.Texte"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       Messieurs les ministres,Madame la présidente,...\n",
              "1       Or, moi que l'on accuse parfois de pêcher par...\n",
              "2       Ce n'est donc pas le moment de fléchir et c'e...\n",
              "3       Je continuerai donc à promouvoir l'assainisse...\n",
              "4       une raison morale. C'est une question de just...\n",
              "                             ...                        \n",
              "244     Entre 1998 et 2008, la dépense nationale liée...\n",
              "245     Le Ministère de l'Ecologie, depuis 2009, a mi...\n",
              "246     - un site internet, véritable plateforme du m...\n",
              "247     donner une valeur à la biodiversité. Faire pr...\n",
              "248     Plus de 70% des cultures dépendent de la poll...\n",
              "Name: Texte, Length: 238, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 426
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhu2c2MSkOmD",
        "colab_type": "code",
        "outputId": "c685d661-6306-493a-b53b-ed5a76779878",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# We prepare the sentences\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import CamembertTokenizer\n",
        "\n",
        "texts = sentence_to_analyse.Texte.values\n",
        "labels = sentence_to_analyse.sexe.values\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-base', do_lower_case=False,padding_side='right')\n",
        "\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "num_truncated_tokens =[]\n",
        "\n",
        "for text in texts:\n",
        "  encoded_dict = tokenizer.encode_plus(\n",
        "                        text,                      # text\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 60,           # We choose for now a max length of 500.\n",
        "                        pad_to_max_length = True,    # Pad text to max \n",
        "                        return_attention_mask = True,   # Construct attention masks\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                        return_overflowing_tokens =True, # return overflowing token information\n",
        "                  )\n",
        "  \n",
        "  input_ids.append(encoded_dict['input_ids'])\n",
        "  attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "print(\"Let's check for the first text indexes, attention masks and labels\")\n",
        "print(\" \")\n",
        "print('Original: ', texts[1][0:100])\n",
        "print('IDs:', input_ids[1][0:100])\n",
        "print('Attention masks:', attention_masks[1][0:100])\n",
        "print('labels',labels[1])\n",
        "\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "dev_dataloader = DataLoader(\n",
        "            dataset,  # The training samples.\n",
        "            batch_size = 1, # Trains with this batch size.\n",
        "            shuffle=False\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Let's check for the first text indexes, attention masks and labels\n",
            " \n",
            "Original:   Or, moi que l'on accuse parfois de pêcher par excès d'optimisme, je crois pourtant, qu'en ce début \n",
            "IDs: tensor([    5,  1051,     7,   202,    27,    17,    11,    88, 12342,   610,\n",
            "            8,  2529,    81,    37, 10887,    18,    11, 24865,     7,    50,\n",
            "         1115,   997,     7,    46,    11,    90,    44,   479,    18,    11,\n",
            "          520,  5371,    63,   296,   193,  1819,    18,    11, 26739,    43,\n",
            "            6,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1])\n",
            "Attention masks: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "labels tensor(1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzsoooGrlpdC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_pred,total_labels,total_logits =evaluation_loop(gender_model,dev_dataloader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX2fdfkm89C_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result_sentence =  dev_treatment(total_pred,total_labels,total_logits,sentence_to_analyse,df_balanced)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTK50qJZngQW",
        "colab_type": "code",
        "outputId": "d3610877-08e8-454a-ded0-be6063db5af8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "source": [
        "result_sentence.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>index_df</th>\n",
              "      <th>Texte</th>\n",
              "      <th>returned_labels</th>\n",
              "      <th>model_pred</th>\n",
              "      <th>one_score</th>\n",
              "      <th>max_score</th>\n",
              "      <th>WF</th>\n",
              "      <th>Titre</th>\n",
              "      <th>Id</th>\n",
              "      <th>Theme</th>\n",
              "      <th>Prenom</th>\n",
              "      <th>Nom</th>\n",
              "      <th>Date</th>\n",
              "      <th>Tags</th>\n",
              "      <th>sexe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>180950</td>\n",
              "      <td>Messieurs les ministres,Madame la présidente,...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.700761</td>\n",
              "      <td>1.743103</td>\n",
              "      <td>False</td>\n",
              "      <td>Déclaration de Mme Christine Lagarde, ministre...</td>\n",
              "      <td>180950</td>\n",
              "      <td>Economie</td>\n",
              "      <td>Christine</td>\n",
              "      <td>Lagarde</td>\n",
              "      <td>2011-01-14T12:00:00Z</td>\n",
              "      <td>Vie économique,Politique économique</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>180950</td>\n",
              "      <td>Or, moi que l'on accuse parfois de pêcher par...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.385811</td>\n",
              "      <td>1.385811</td>\n",
              "      <td>True</td>\n",
              "      <td>Déclaration de Mme Christine Lagarde, ministre...</td>\n",
              "      <td>180950</td>\n",
              "      <td>Economie</td>\n",
              "      <td>Christine</td>\n",
              "      <td>Lagarde</td>\n",
              "      <td>2011-01-14T12:00:00Z</td>\n",
              "      <td>Vie économique,Politique économique</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>180950</td>\n",
              "      <td>Ce n'est donc pas le moment de fléchir et c'e...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.869216</td>\n",
              "      <td>0.869216</td>\n",
              "      <td>True</td>\n",
              "      <td>Déclaration de Mme Christine Lagarde, ministre...</td>\n",
              "      <td>180950</td>\n",
              "      <td>Economie</td>\n",
              "      <td>Christine</td>\n",
              "      <td>Lagarde</td>\n",
              "      <td>2011-01-14T12:00:00Z</td>\n",
              "      <td>Vie économique,Politique économique</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>180950</td>\n",
              "      <td>Je continuerai donc à promouvoir l'assainisse...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.501634</td>\n",
              "      <td>0.596974</td>\n",
              "      <td>False</td>\n",
              "      <td>Déclaration de Mme Christine Lagarde, ministre...</td>\n",
              "      <td>180950</td>\n",
              "      <td>Economie</td>\n",
              "      <td>Christine</td>\n",
              "      <td>Lagarde</td>\n",
              "      <td>2011-01-14T12:00:00Z</td>\n",
              "      <td>Vie économique,Politique économique</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>180950</td>\n",
              "      <td>une raison morale. C'est une question de just...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.503998</td>\n",
              "      <td>0.593478</td>\n",
              "      <td>False</td>\n",
              "      <td>Déclaration de Mme Christine Lagarde, ministre...</td>\n",
              "      <td>180950</td>\n",
              "      <td>Economie</td>\n",
              "      <td>Christine</td>\n",
              "      <td>Lagarde</td>\n",
              "      <td>2011-01-14T12:00:00Z</td>\n",
              "      <td>Vie économique,Politique économique</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  index_df  ...                                 Tags  sexe\n",
              "0      0    180950  ...  Vie économique,Politique économique     1\n",
              "1      1    180950  ...  Vie économique,Politique économique     1\n",
              "2      2    180950  ...  Vie économique,Politique économique     1\n",
              "3      3    180950  ...  Vie économique,Politique économique     1\n",
              "4      4    180950  ...  Vie économique,Politique économique     1\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 430
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKNslucdok9J",
        "colab_type": "code",
        "outputId": "fd38b253-14db-4efa-aa15-2ec9417cd0c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#How many sentences were not well classified ? \n",
        "print('{0:.2f} percent of the development texts were not well classified by our model'.format(result[result.WF==False].WF.count()*100/len(result)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12.54 percent of the development texts were not well classified by our model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUX0w67j5J1t",
        "colab_type": "text"
      },
      "source": [
        "We redo the same exercice as before. Here with our pieces of text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4z2lKZyoYf4",
        "colab_type": "code",
        "outputId": "251e2ffc-e7fd-4a89-fca8-b9e618e16e73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        }
      },
      "source": [
        "top_sentence_true_m=result_sentence[(result_sentence.WF==1) & (result_sentence.model_pred==0)].nlargest(1,'max_score')\n",
        "top_sentence_true_f=result_sentence[(result_sentence.WF==1) & (result_sentence.model_pred==1)].nlargest(1,'max_score')\n",
        "top_sentence_false_m=result_sentence[(result_sentence.WF==0) & (result_sentence.model_pred==0)].nlargest(1,'max_score')\n",
        "top_sentence_false_f=result_sentence[(result_sentence.WF==0) & (result_sentence.model_pred==1)].nlargest(1,'max_score')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-464-da6357c1a1e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtop_sentence_true_m\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult_sentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_sentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWF\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresult_sentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_pred\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtop_sentence_true_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult_sentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_sentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWF\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresult_sentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_pred\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlargest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'max_score'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtop_sentence_false_m\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult_sentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_sentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWF\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresult_sentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_pred\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlargest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'max_score'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtop_sentence_false_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult_sentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_sentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWF\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresult_sentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_pred\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlargest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'max_score'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1762\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1272\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1273\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_lowerdim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_label_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0msection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0;31m# we have yielded a scalar ?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1963\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1964\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1965\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"no slices here, handle elsewhere\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mxs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   3535\u001b[0m             \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3536\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3537\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3539\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpMkyg35qUnF",
        "colab_type": "code",
        "outputId": "819ef91c-4048-439d-868d-11bf95292c90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "top_sentence_false_m"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>index_df</th>\n",
              "      <th>Texte</th>\n",
              "      <th>returned_labels</th>\n",
              "      <th>model_pred</th>\n",
              "      <th>one_score</th>\n",
              "      <th>max_score</th>\n",
              "      <th>WF</th>\n",
              "      <th>Titre</th>\n",
              "      <th>Id</th>\n",
              "      <th>Theme</th>\n",
              "      <th>Prenom</th>\n",
              "      <th>Nom</th>\n",
              "      <th>Date</th>\n",
              "      <th>Tags</th>\n",
              "      <th>sexe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>44</td>\n",
              "      <td>149424</td>\n",
              "      <td>Cela dit, chacun sait bien que nous ne sommes...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-2.367369</td>\n",
              "      <td>2.386559</td>\n",
              "      <td>False</td>\n",
              "      <td>Déclaration de Mme Catherine Colonna, ministre...</td>\n",
              "      <td>149424</td>\n",
              "      <td>International</td>\n",
              "      <td>Catherine</td>\n",
              "      <td>Colonna</td>\n",
              "      <td>2005-10-10T12:00:00Z</td>\n",
              "      <td>Union européenne,Politique européenne de sécur...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    index  index_df  ...                                               Tags  sexe\n",
              "43     44    149424  ...  Union européenne,Politique européenne de sécur...     1\n",
              "\n",
              "[1 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 433
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDqBRQHAqTog",
        "colab_type": "code",
        "outputId": "590be693-1975-4b30-c809-d58d4c99e804",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "top_sentence_false_f"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>index_df</th>\n",
              "      <th>Texte</th>\n",
              "      <th>returned_labels</th>\n",
              "      <th>model_pred</th>\n",
              "      <th>one_score</th>\n",
              "      <th>max_score</th>\n",
              "      <th>WF</th>\n",
              "      <th>Titre</th>\n",
              "      <th>Id</th>\n",
              "      <th>Theme</th>\n",
              "      <th>Prenom</th>\n",
              "      <th>Nom</th>\n",
              "      <th>Date</th>\n",
              "      <th>Tags</th>\n",
              "      <th>sexe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>73</td>\n",
              "      <td>134262</td>\n",
              "      <td>\"être passé de langue d'enfance à celle de li...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.581131</td>\n",
              "      <td>1.581131</td>\n",
              "      <td>False</td>\n",
              "      <td>Discours de M. Jacques Chirac, Président de la...</td>\n",
              "      <td>134262</td>\n",
              "      <td>International,Société</td>\n",
              "      <td>Jacques</td>\n",
              "      <td>Chirac</td>\n",
              "      <td>1997-03-17T12:00:00Z</td>\n",
              "      <td>Relations internationales,Relations bilatérale...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    index  index_df  ...                                               Tags  sexe\n",
              "69     73    134262  ...  Relations internationales,Relations bilatérale...     0\n",
              "\n",
              "[1 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 434
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJMWoOkh0ZqM",
        "colab_type": "code",
        "outputId": "b225a9d4-48fc-41d6-e2f6-50a4f499f323",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "top_sentence_true_m"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>index_df</th>\n",
              "      <th>Texte</th>\n",
              "      <th>returned_labels</th>\n",
              "      <th>model_pred</th>\n",
              "      <th>one_score</th>\n",
              "      <th>max_score</th>\n",
              "      <th>WF</th>\n",
              "      <th>Titre</th>\n",
              "      <th>Id</th>\n",
              "      <th>Theme</th>\n",
              "      <th>Prenom</th>\n",
              "      <th>Nom</th>\n",
              "      <th>Date</th>\n",
              "      <th>Tags</th>\n",
              "      <th>sexe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>92</td>\n",
              "      <td>133642</td>\n",
              "      <td>Mesdames et Messieurs, j'ai été très heureux ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-2.577547</td>\n",
              "      <td>2.557751</td>\n",
              "      <td>True</td>\n",
              "      <td>Déclaration de M. Hervé de Charette, ministre ...</td>\n",
              "      <td>133642</td>\n",
              "      <td>International</td>\n",
              "      <td>Hervé</td>\n",
              "      <td>de Charette</td>\n",
              "      <td>1997-01-13T12:00:00Z</td>\n",
              "      <td>Relations internationales,Relations bilatérale...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    index  index_df  ...                                               Tags  sexe\n",
              "87     92    133642  ...  Relations internationales,Relations bilatérale...     0\n",
              "\n",
              "[1 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 435
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewrV4UeJ0br2",
        "colab_type": "code",
        "outputId": "98ef143a-5aa2-43b8-8a4c-a362e3d11ba5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "top_sentence_true_f"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>index_df</th>\n",
              "      <th>Texte</th>\n",
              "      <th>returned_labels</th>\n",
              "      <th>model_pred</th>\n",
              "      <th>one_score</th>\n",
              "      <th>max_score</th>\n",
              "      <th>WF</th>\n",
              "      <th>Titre</th>\n",
              "      <th>Id</th>\n",
              "      <th>Theme</th>\n",
              "      <th>Prenom</th>\n",
              "      <th>Nom</th>\n",
              "      <th>Date</th>\n",
              "      <th>Tags</th>\n",
              "      <th>sexe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>134</th>\n",
              "      <td>141</td>\n",
              "      <td>272410</td>\n",
              "      <td>Mme Marie-Noëlle Lienemann. À 10 000 euros le...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2.420278</td>\n",
              "      <td>2.420278</td>\n",
              "      <td>True</td>\n",
              "      <td>Déclaration de Mme Élisabeth Borne, ministre d...</td>\n",
              "      <td>272410</td>\n",
              "      <td>Société</td>\n",
              "      <td>Elisabeth</td>\n",
              "      <td>Borne</td>\n",
              "      <td>2019-10-03T12:00:00Z</td>\n",
              "      <td>Environnement,Politique de l'environnement,Climat</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     index  index_df  ...                                               Tags  sexe\n",
              "134    141    272410  ...  Environnement,Politique de l'environnement,Climat     1\n",
              "\n",
              "[1 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 436
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqDo-uLY7R_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words_to_analyse = pd.concat([top_sentence_false_m,top_sentence_true_m,top_sentence_false_f,top_sentence_true_f]).reset_index(drop=True)\n",
        "words_to_analyse.insert(2, \"type_fail\", ['false_m','true_m','false_f','true_f'], True) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "la04asKH6Tqj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We split those sentences into words\n",
        "lst= []\n",
        "for index,row in words_to_analyse.iterrows():\n",
        "  identifiant = row.index_df\n",
        "  label = row.sexe\n",
        "  type_fail = row.type_fail\n",
        "  phrase = []\n",
        "  for token in row.Texte.split(' '):\n",
        "      lst += [(identifiant,label,token,type_fail)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "969R9ae06iAZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words_to_analyse=pd.DataFrame(lst,columns=['index_df','sexe','Texte','type_fail'])\n",
        "words_to_analyse=words_to_analyse[words_to_analyse.Texte!='']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUyDuca0fRlL",
        "colab_type": "code",
        "outputId": "498a82d0-8604-4a37-fef1-f4315e7529d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "words_to_analyse=words_to_analyse[words_to_analyse.Texte!='']\n",
        "words_to_analyse.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index_df</th>\n",
              "      <th>sexe</th>\n",
              "      <th>Texte</th>\n",
              "      <th>type_fail</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>149424</td>\n",
              "      <td>1</td>\n",
              "      <td>Cela</td>\n",
              "      <td>false_m</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>149424</td>\n",
              "      <td>1</td>\n",
              "      <td>dit,</td>\n",
              "      <td>false_m</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>149424</td>\n",
              "      <td>1</td>\n",
              "      <td>chacun</td>\n",
              "      <td>false_m</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>149424</td>\n",
              "      <td>1</td>\n",
              "      <td>sait</td>\n",
              "      <td>false_m</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>149424</td>\n",
              "      <td>1</td>\n",
              "      <td>bien</td>\n",
              "      <td>false_m</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index_df  sexe   Texte type_fail\n",
              "1    149424     1    Cela   false_m\n",
              "2    149424     1    dit,   false_m\n",
              "3    149424     1  chacun   false_m\n",
              "4    149424     1    sait   false_m\n",
              "5    149424     1    bien   false_m"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 440
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Psom5Gizsjr",
        "colab_type": "code",
        "outputId": "b8a33f76-25a7-47d6-b9ef-c73050ec0d42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# We prepare again the development sample for analysis \n",
        "\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import CamembertTokenizer\n",
        "\n",
        "texts = words_to_analyse.Texte.values\n",
        "labels = words_to_analyse.sexe.values\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-base', do_lower_case=False,padding_side='right')\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "num_truncated_tokens =[]\n",
        "\n",
        "for text in texts:\n",
        "  encoded_dict = tokenizer.encode_plus(\n",
        "                        text,                      # text\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 5,           # We choose for now a max length of 500.\n",
        "                        pad_to_max_length = True,    # Pad text to max \n",
        "                        return_attention_mask = True,   # Construct attention masks\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                        return_overflowing_tokens =True, # return overflowing token information\n",
        "                  )\n",
        "    \n",
        "    # Map tokens to their id in the dictionnary \n",
        "    # We add this to our list    \n",
        "  input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "    #num_truncated_tokens.append(encoded_dict['num_truncated_tokens'])\n",
        "    \n",
        "    # 3. Attention masks\n",
        "  attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# We convert all this into tensors in order to be able to make it work on GPU \n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Original text and transformed tensor print \n",
        "print(\"Let's check for the first text indexes, attention masks and labels\")\n",
        "print(\" \")\n",
        "print('Original: ', texts[0][0:100])\n",
        "print('IDs:', input_ids[0][0:100])\n",
        "print('Attention masks:', attention_masks[0][0:100])\n",
        "print('labels',labels[0])\n",
        "\n",
        "# Combine all above\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "# We create data loaders for the train and validation dataset. \n",
        "dev_dataloader = DataLoader(\n",
        "            dataset,  # The training samples.\n",
        "            batch_size = 1, # Trains with this batch size.\n",
        "            shuffle=False\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Let's check for the first text indexes, attention masks and labels\n",
            " \n",
            "Original:  Cela\n",
            "IDs: tensor([  5, 683,   6,   1,   1])\n",
            "Attention masks: tensor([1, 1, 1, 0, 0])\n",
            "labels tensor(1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWOre462zer-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_pred,total_labels,total_logits =evaluation_loop(gender_model,dev_dataloader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkFcDyDx59EF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result_words =  dev_treatment(total_pred,total_labels,total_logits,words_to_analyse,df_balanced)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5U82xvk6EKE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "type_fail = ['top_sentence_false_m','top_sentence_true_m','top_sentence_false_f','top_sentence_true_f']\n",
        "identifier = list(result_words.Id.unique())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4_4pfWu_CBi",
        "colab_type": "code",
        "outputId": "457aa0bc-010b-4ffb-fe38-52be8c56144c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "source": [
        "df_plot_false_m"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cela</th>\n",
              "      <th>dit,</th>\n",
              "      <th>chacun</th>\n",
              "      <th>sait</th>\n",
              "      <th>bien</th>\n",
              "      <th>que</th>\n",
              "      <th>nous</th>\n",
              "      <th>ne</th>\n",
              "      <th>sommes</th>\n",
              "      <th>pas</th>\n",
              "      <th>unis</th>\n",
              "      <th>sur</th>\n",
              "      <th>tout.</th>\n",
              "      <th>Il</th>\n",
              "      <th>suffit</th>\n",
              "      <th>d'évoquer</th>\n",
              "      <th>la</th>\n",
              "      <th>crise</th>\n",
              "      <th>irakienne,</th>\n",
              "      <th>mais</th>\n",
              "      <th>il</th>\n",
              "      <th>y</th>\n",
              "      <th>a</th>\n",
              "      <th>d'autres</th>\n",
              "      <th>exemples</th>\n",
              "      <th>où,</th>\n",
              "      <th>comme</th>\n",
              "      <th>il</th>\n",
              "      <th>convient</th>\n",
              "      <th>de</th>\n",
              "      <th>dire</th>\n",
              "      <th>diplomatiquement,</th>\n",
              "      <th>d'importantes</th>\n",
              "      <th>marges</th>\n",
              "      <th>de</th>\n",
              "      <th>progression</th>\n",
              "      <th>existent</th>\n",
              "      <th>en</th>\n",
              "      <th>la</th>\n",
              "      <th>matière.</th>\n",
              "      <th>Alors</th>\n",
              "      <th>comment</th>\n",
              "      <th>mieux</th>\n",
              "      <th>faire</th>\n",
              "      <th>?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.405006</td>\n",
              "      <td>-1.526898</td>\n",
              "      <td>0.311913</td>\n",
              "      <td>-0.338041</td>\n",
              "      <td>-0.478967</td>\n",
              "      <td>-1.101015</td>\n",
              "      <td>-0.615979</td>\n",
              "      <td>-0.426278</td>\n",
              "      <td>-0.088669</td>\n",
              "      <td>-0.77648</td>\n",
              "      <td>-0.227197</td>\n",
              "      <td>-0.521295</td>\n",
              "      <td>-1.554681</td>\n",
              "      <td>-0.704478</td>\n",
              "      <td>-0.511919</td>\n",
              "      <td>-0.765688</td>\n",
              "      <td>-0.492656</td>\n",
              "      <td>-0.166948</td>\n",
              "      <td>-0.293516</td>\n",
              "      <td>-0.327148</td>\n",
              "      <td>-0.999759</td>\n",
              "      <td>-1.14732</td>\n",
              "      <td>-0.728116</td>\n",
              "      <td>-0.244898</td>\n",
              "      <td>-0.769444</td>\n",
              "      <td>-0.731526</td>\n",
              "      <td>-0.693956</td>\n",
              "      <td>-0.999759</td>\n",
              "      <td>-0.35636</td>\n",
              "      <td>-0.424134</td>\n",
              "      <td>-0.753398</td>\n",
              "      <td>-1.482193</td>\n",
              "      <td>-0.299123</td>\n",
              "      <td>-0.28762</td>\n",
              "      <td>-0.424134</td>\n",
              "      <td>-0.26853</td>\n",
              "      <td>-0.253697</td>\n",
              "      <td>-0.670108</td>\n",
              "      <td>-0.492656</td>\n",
              "      <td>0.200327</td>\n",
              "      <td>-0.261424</td>\n",
              "      <td>-0.593099</td>\n",
              "      <td>0.085607</td>\n",
              "      <td>-1.165817</td>\n",
              "      <td>-1.072028</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Cela      dit,    chacun  ...     mieux     faire         ?\n",
              "0 -1.405006 -1.526898  0.311913  ...  0.085607 -1.165817 -1.072028\n",
              "\n",
              "[1 rows x 45 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 445
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7pykpuA--9-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scores = [i for i in result_words[result_words.index_df==identifier[0]].one_score]\n",
        "df_plot_false_m=pd.DataFrame(scores).transpose()\n",
        "df_plot_false_m.columns=list(result_words[result_words.index_df==identifier[0]].Texte)\n",
        "scores = [i for i in result_words[result_words.index_df==identifier[1]].one_score]\n",
        "df_plot_true_m=pd.DataFrame(scores).transpose()\n",
        "df_plot_true_m.columns=list(result_words[result_words.index_df==identifier[1]].Texte)\n",
        "scores = [i for i in result_words[result_words.index_df==identifier[2]].one_score]\n",
        "df_plot_false_f=pd.DataFrame(scores).transpose()\n",
        "df_plot_false_f.columns=list(result_words[result_words.index_df==identifier[2]].Texte)\n",
        "scores = [i for i in result_words[result_words.index_df==identifier[3]].one_score]\n",
        "df_plot_true_f=pd.DataFrame(scores).transpose()\n",
        "df_plot_true_f.columns=list(result_words[result_words.index_df==identifier[3]].Texte)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "An5aj7P01dCD",
        "colab_type": "code",
        "outputId": "7b11ddf7-3749-49ed-9dae-a8cb02e870b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 898
        }
      },
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize=(26,15))\n",
        "\n",
        "#  heatmap - female subplot\n",
        "fig.add_subplot(411)\n",
        "plt.title('Well predict a female speaker', fontsize=14)\n",
        "sns.heatmap(df_plot_true_f, annot=False, fmt='.2f',vmin=-3,vmax=1)\n",
        "\n",
        "#  heatmap - male subplot\n",
        "fig.add_subplot(412)\n",
        "plt.title('Wrongly predicted male speaker', fontsize=14)\n",
        "sns.heatmap(df_plot_false_m, annot=False, fmt='.2f',vmin=-3,vmax=1 )\n",
        "\n",
        "#  heatmap - male subplot\n",
        "fig.add_subplot(413)\n",
        "plt.title('Wrongly predict a female speaker', fontsize=14)\n",
        "sns.heatmap(df_plot_false_f, annot=False, fmt='.2f',vmin=-3,vmax=1 )\n",
        "\n",
        "#  heatmap - male subplot\n",
        "fig.add_subplot(414)\n",
        "plt.title('Well predict a male speaker', fontsize=14)\n",
        "sns.heatmap(df_plot_true_m, annot=False, fmt='.2f',vmin=-3,vmax=1 )\n",
        "\n",
        "plt.subplots_adjust(hspace=1)\n",
        "#fig.tight_layout(pad=3.0)\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABQwAAAOSCAYAAAAxpp0LAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nut8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1872x1080 with 8 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}